{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (8, 6)\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "tf.random.set_seed(13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading data\n",
    "evo_data = pd.read_csv('data/demand_datasets/evo_demand.csv', index_col=0)\n",
    "modo_data = pd.read_csv('data/demand_datasets/modo_demand.csv', index_col=0)\n",
    "c2g_data = pd.read_csv('data/demand_datasets/c2g_demand.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evo_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evo_data.drop(columns = ['hour_0', 'hour_1', 'hour_2', 'hour_3',\n",
    "       'hour_4', 'hour_5', 'hour_6', 'hour_7', 'hour_8', 'hour_9', 'hour_10',\n",
    "       'hour_11', 'hour_12', 'hour_13', 'hour_14', 'hour_15', 'hour_16',\n",
    "       'hour_17', 'hour_18', 'hour_19', 'hour_20', 'hour_21', 'hour_22',\n",
    "       'hour_23'])\n",
    "modo_data.drop(columns = ['hour_0', 'hour_1', 'hour_2', 'hour_3',\n",
    "       'hour_4', 'hour_5', 'hour_6', 'hour_7', 'hour_8', 'hour_9', 'hour_10',\n",
    "       'hour_11', 'hour_12', 'hour_13', 'hour_14', 'hour_15', 'hour_16',\n",
    "       'hour_17', 'hour_18', 'hour_19', 'hour_20', 'hour_21', 'hour_22',\n",
    "       'hour_23'])\n",
    "c2g_data.drop(columns = ['hour_0', 'hour_1', 'hour_2', 'hour_3',\n",
    "       'hour_4', 'hour_5', 'hour_6', 'hour_7', 'hour_8', 'hour_9', 'hour_10',\n",
    "       'hour_11', 'hour_12', 'hour_13', 'hour_14', 'hour_15', 'hour_16',\n",
    "       'hour_17', 'hour_18', 'hour_19', 'hour_20', 'hour_21', 'hour_22',\n",
    "       'hour_23'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_period = '06-23'\n",
    "end_period = '07-12'\n",
    "\n",
    "evo_data = evo_data[(evo_data.index >= '2018-'+init_period) & (evo_data.index <= '2018-'+end_period)]\n",
    "modo_data = modo_data[(modo_data.index >= '2018-'+init_period) & (modo_data.index <= '2018-'+end_period)]\n",
    "c2g_data = c2g_data[(c2g_data.index >= '2017-'+init_period) & (c2g_data.index <= '2017-'+end_period)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_size(data, size=0.7):\n",
    "    # 70% of the data to use as train set\n",
    "    train_split = int(len(data) * size)\n",
    "    return train_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_data(features, train_split):\n",
    "    dataset = features.values\n",
    "    data_max = dataset[:train_split].max()\n",
    "    data_min = dataset[:train_split].min()\n",
    "    data_std = dataset[:train_split].std(axis=0)\n",
    "\n",
    "    dataset = (dataset-data_min)/(data_max - data_min)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modo_norm = norm_data(modo_data, train_size(modo_data))\n",
    "evo_norm = norm_data(evo_data, train_size(evo_data))\n",
    "c2g_norm = norm_data(c2g_data, train_size(c2g_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this analysis the aim is to predict the number of travels using a multivariate LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multivariate_data(dataset, target, start_index, end_index, history_size,\n",
    "                      target_size, step, single_step=False):\n",
    "    \"\"\"\n",
    "    Reshape the data to usual representation of train and target sets\n",
    "    \n",
    "    single_step - In a single step setup (True), the model learns to predict a single point in the future \n",
    "                  based on some history provided. Else (False), the model needs to learn to predict a range \n",
    "                  of future values.\n",
    "    \n",
    "    target_size - Is how far in the future does the model need to learn to predict.\n",
    "                  The target_size is from the label that needs to be predicted\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    start_index = start_index + history_size # determining the real start since it has a history size\n",
    "    if end_index is None:\n",
    "        end_index = len(dataset) - target_size\n",
    "\n",
    "    for i in range(start_index, end_index): # creating the data 'chuncks' with size of history size\n",
    "        indices = range(i-history_size, i, step)\n",
    "        data.append(dataset[indices])\n",
    "\n",
    "        if single_step: # selecting the point or interval to be predicted\n",
    "            labels.append(target[i+target_size])\n",
    "        else:\n",
    "            labels.append(target[i:i+target_size])\n",
    "\n",
    "    return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_split(data, train_split, history_length=72, future_target=1, \n",
    "                    step=1, single_step=False, batch_size=256, buffer_size=10000):\n",
    "\n",
    "    # splitting the train and evaluate sets\n",
    "    x_train, y_train = multivariate_data(data, data[:, 0], 0, train_split, history_length, future_target, step, single_step)\n",
    "    x_val, y_val = multivariate_data(data, data[:, 0], train_split, None, history_length, future_target, step, single_step)\n",
    "\n",
    "    print ('\\nSingle window of past history : {}'.format(x_train[0].shape))\n",
    "    print ('Target feature to predict : {}'.format(y_train[0].shape))\n",
    "    \n",
    "    # slice and shuffle the train and evaluate sets based on the batch size\n",
    "    train = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "    train = train.cache().shuffle(buffer_size).batch(batch_size).repeat()\n",
    "\n",
    "    val = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "    val = val.batch(batch_size).repeat()\n",
    "    \n",
    "    shape = x_train.shape[-2:]\n",
    "    \n",
    "    return train, val, shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_model(train_data, validation_data, shape, epochs=10, evaluation_interval=200, node_number=50):\n",
    "\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.LSTM(node_number, return_sequences=True,\n",
    "                                  input_shape=shape))\n",
    "    model.add(tf.keras.layers.Dropout(0.2))\n",
    "    model.add(tf.keras.layers.LSTM(node_number, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(12))\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.RMSprop(clipvalue=1.0), \n",
    "                  loss='mae', metrics=['mse','mae'])\n",
    "    \n",
    "    for x, y in validation_data.take(1):\n",
    "        print(model.predict(x).shape)\n",
    "    \n",
    "    history = model.fit(train_data, epochs=epochs,\n",
    "                      steps_per_epoch=evaluation_interval,\n",
    "                      validation_data=validation_data,\n",
    "                      validation_steps=50)\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# split data on train and validate sets\n",
    "evo_train, evo_val, evo_shape = train_val_split(data=evo_norm, train_split=train_size(evo_norm), history_length=24, future_target=12)\n",
    "modo_train, modo_val, modo_shape = train_val_split(data=modo_norm, train_split=train_size(modo_norm), history_length=24, future_target=12)\n",
    "c2g_train, c2g_val, c2g_shape = train_val_split(data=c2g_norm, train_split=train_size(c2g_norm), history_length=24, future_target=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([0, 1, 2, 3, 4][:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_representation_plot(hour_skip, data_val, data_model, data_regular_max, data_regular_min, title,\n",
    "                                    title_in_plot=True, save_file=False, print_plot=True, upper_border=True, legend_font_size=\"medium\"):\n",
    "    data_predictions_array = []\n",
    "    data_truth_array =  []\n",
    "    \n",
    "    \n",
    "    for x, y in data_val.take(1):\n",
    "        result = data_model.predict(x)\n",
    "        blocks = len(result)//hour_skip\n",
    "        for n in range(blocks):\n",
    "            for prediction, truth in zip(result[n*hour_skip][:hour_skip], y[n*hour_skip][:hour_skip]):\n",
    "                data_predictions_array.append(prediction)\n",
    "                data_truth_array.append(float(truth))\n",
    "\n",
    "    data_predictions_array = np.array(data_predictions_array)\n",
    "    data_truth_array = np.array(data_truth_array)\n",
    "    data_predictions_array *= data_regular_max\n",
    "    data_predictions_array += data_regular_min\n",
    "    data_truth_array *= data_regular_max\n",
    "    data_truth_array += data_regular_min\n",
    "    \n",
    "    fig = plt.figure(figsize=(20,10))\n",
    "    plt.xlabel(\"Hours\")\n",
    "    plt.title(title + \" (Hours Skiped = \" + str(hour_skip) + \")\") if title_in_plot else print(title + \" (Hours Skiped = \" + str(hour_skip) + \")\")\n",
    "    plt.ylabel(\"Travels Requested Per Hour\")\n",
    "    plt.plot(data_truth_array, marker=\"o\", label=\"True Values\")\n",
    "    plt.plot(data_predictions_array, marker=\"D\", label=\"Predicted Values\")\n",
    "    if(not upper_border):\n",
    "        ax = plt.gca()\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "    plt.legend(fontsize=legend_font_size)\n",
    "    plt.savefig(\"plots\\\\\" + title.replace(\" \", \"_\") + \"_\" + str(hour_skip) + \"_HrsBetweenPredictions.png\", bbox_inches='tight') if save_file else print()\n",
    "    plt.show() if print_plot else print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_step_plot(history, true_future, prediction):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    num_in = range(len(history))\n",
    "    num_out = len(true_future)\n",
    "\n",
    "    plt.plot(num_in, np.array(history[:, 0]), label='History')\n",
    "    plt.plot(np.arange(len(history),num_out+len(history)), np.array(true_future), 'bo',\n",
    "           label='True Future')\n",
    "    if prediction.any():\n",
    "        plt.plot(np.arange(len(history),num_out+len(history)), np.array(prediction), 'rX-',\n",
    "                 label='Predicted Future')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_history(history, title, save_file=False):\n",
    "    pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "    plt.grid(True)\n",
    "    plt.savefig(\"plots\\\\\" + title.replace(\" \", \"_\") + \".png\", bbox_inches='tight') if save_file else print()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, will be generated the model for each dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evo Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Evo Model')\n",
    "evo_model, evo_history = lstm_model(evo_train, evo_val, evo_shape, epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_train_history(evo_history,\n",
    "                   'Training and validation loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in evo_val.take(1):\n",
    "    multi_step_plot(x[0], y[0], evo_model.predict(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_representation_plot(12 ,evo_val, evo_model, evo_data.travels.max(), evo_data.travels.min(), \"Evo Performance\",\n",
    "                                upper_border=False, title_in_plot=False, legend_font_size=\"x-large\", save_file=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = \"\"\"\n",
    "histories = []\n",
    "\n",
    "for n_epochs in range(20, 51, 10):\n",
    "    evo_model, evo_history = lstm_model(evo_train, evo_val, evo_shape, epochs=n_epochs)\n",
    "    histories.append(evo_history)\n",
    "    performance_representation_plot(12 ,evo_val, evo_model, evo_data.travels.max(), evo_data.travels.min(),\n",
    "                                    \"Epoch_Tests\\\\Evo\\\\Evo Performance \" + str(n_epochs) + \"epochs\",\n",
    "                                    upper_border=False, title_in_plot=False, legend_font_size=\"x-large\", save_file=True, print_plot=False)\n",
    "\n",
    "for history , n_epochs in zip(histories, list(range(20, 51, 10))):\n",
    "    plot_train_history(history, 'Epoch_Tests\\\\Evo\\\\Training and validation loss Evo - (' + str(n_epochs) + \" Epochs )\", save_file=True)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modo model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Modo Model')\n",
    "modo_model, modo_history = lstm_model(modo_train, modo_val, modo_shape, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_train_history(modo_history,\n",
    "                   'Training and validation loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in modo_val.take(1):\n",
    "    multi_step_plot(x[0], y[0], modo_model.predict(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_representation_plot(12, modo_val, modo_model, modo_data.travels.max(), modo_data.travels.min(), \"Modo Performance\",\n",
    "                                upper_border=False, title_in_plot=False, legend_font_size=\"x-large\", save_file=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = \"\"\"histories = []\n",
    "\n",
    "for n_epochs in range(20, 51, 10):\n",
    "    modo_model, modo_history = lstm_model(modo_train, modo_val, modo_shape, epochs=n_epochs)\n",
    "    histories.append(modo_history)\n",
    "    performance_representation_plot(12 ,modo_val, modo_model, modo_data.travels.max(), modo_data.travels.min(),\n",
    "                                    \"Epoch_Tests\\\\Modo\\\\Modo Performance \" + str(n_epochs) + \"epochs\",\n",
    "                                    upper_border=False, title_in_plot=False, legend_font_size=\"x-large\", save_file=True, print_plot=False)\n",
    "\n",
    "for history , n_epochs in zip(histories, list(range(20, 51, 10))):\n",
    "    plot_train_history(history, 'Epoch_Tests\\\\Modo\\\\Training and validation loss modo - (' + str(n_epochs) + \" Epochs )\", save_file=True)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Car2Go Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Car2Go Model')\n",
    "c2g_model, c2g_history = lstm_model(c2g_train, c2g_val, c2g_shape, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_train_history(c2g_history,\n",
    "                   'Training and validation loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in c2g_val.take(1):\n",
    "    multi_step_plot(x[0], y[0],c2g_model.predict(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_representation_plot(12, c2g_val, c2g_model, c2g_data.travels.max(), c2g_data.travels.min(), \"Car2Go Performance\",\n",
    "                                upper_border=False, title_in_plot=False, legend_font_size=\"x-large\", save_file=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = \"\"\"histories = []\n",
    "\n",
    "for n_epochs in range(20, 51, 10):\n",
    "    c2g_model, c2g_history = lstm_model(c2g_train, c2g_val, c2g_shape, epochs=n_epochs)\n",
    "    histories.append(c2g_history)\n",
    "    performance_representation_plot(12 ,c2g_val, c2g_model, c2g_data.travels.max(), c2g_data.travels.min(),\n",
    "                                    \"Epoch_Tests\\\\Car2Go\\\\c2g Performance \" + str(n_epochs) + \"epochs\",\n",
    "                                    upper_border=False, title_in_plot=False, legend_font_size=\"x-large\", save_file=True, print_plot=False)\n",
    "\n",
    "for history , n_epochs in zip(histories, list(range(20, 51, 10))):\n",
    "    plot_train_history(history, 'Epoch_Tests\\\\Car2Go\\\\Training and validation loss modo - (' + str(n_epochs) + \" Epochs )\", save_file=True)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "performance_representation_plotrences\n",
    "\n",
    "* https://www.tensorflow.org/tutorials/structured_data/time_series#part_2_forecast_a_multivariate_time_series\n",
    "* http://netlab.ice.ufjf.br/index.php/carsharingdata/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
