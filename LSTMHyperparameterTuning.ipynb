{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import json\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (8, 6)\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "tf.random.set_seed(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.now().strftime(\"%m-%d-%Y_%Hh%Mmin%Ss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_epoch_number = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading data\n",
    "evo_data = pd.read_csv('data/interpol/evo_interpol_demand.csv', index_col=0)\n",
    "modo_data = pd.read_csv('data/interpol/modo_interpol_demand.csv', index_col=0)\n",
    "c2g_data = pd.read_csv('data/interpol/c2g_interpol_demand.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evo_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evo_data.drop(columns = ['hour_0', 'hour_1', 'hour_2', 'hour_3',\n",
    "       'hour_4', 'hour_5', 'hour_6', 'hour_7', 'hour_8', 'hour_9', 'hour_10',\n",
    "       'hour_11', 'hour_12', 'hour_13', 'hour_14', 'hour_15', 'hour_16',\n",
    "       'hour_17', 'hour_18', 'hour_19', 'hour_20', 'hour_21', 'hour_22',\n",
    "       'hour_23', \"interpolate\"], inplace=True)\n",
    "modo_data.drop(columns = ['hour_0', 'hour_1', 'hour_2', 'hour_3',\n",
    "       'hour_4', 'hour_5', 'hour_6', 'hour_7', 'hour_8', 'hour_9', 'hour_10',\n",
    "       'hour_11', 'hour_12', 'hour_13', 'hour_14', 'hour_15', 'hour_16',\n",
    "       'hour_17', 'hour_18', 'hour_19', 'hour_20', 'hour_21', 'hour_22',\n",
    "       'hour_23', \"interpolate\"], inplace=True)\n",
    "c2g_data.drop(columns = ['hour_0', 'hour_1', 'hour_2', 'hour_3',\n",
    "       'hour_4', 'hour_5', 'hour_6', 'hour_7', 'hour_8', 'hour_9', 'hour_10',\n",
    "       'hour_11', 'hour_12', 'hour_13', 'hour_14', 'hour_15', 'hour_16',\n",
    "       'hour_17', 'hour_18', 'hour_19', 'hour_20', 'hour_21', 'hour_22',\n",
    "       'hour_23', \"interpolate\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unievo_data = pd.DataFrame(evo_data.travels)\n",
    "unimodo_data = pd.DataFrame(modo_data.travels)\n",
    "unic2g_data = pd.DataFrame(c2g_data.travels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the Canada Day Holiday\n",
    "evo_data.index = pd.to_datetime(evo_data.index)\n",
    "modo_data.index = pd.to_datetime(modo_data.index)\n",
    "c2g_data.index = pd.to_datetime(c2g_data.index)\n",
    "\n",
    "evo_data[\"holidays\"] = pd.Series()\n",
    "modo_data[\"holidays\"] = pd.Series()\n",
    "c2g_data[\"holidays\"] = pd.Series()\n",
    "\n",
    "evo_data[\"holidays\"] = evo_data[\"holidays\"].fillna(0)\n",
    "modo_data[\"holidays\"] = modo_data[\"holidays\"].fillna(0)\n",
    "c2g_data[\"holidays\"] = c2g_data[\"holidays\"].fillna(0)\n",
    "\n",
    "canada_day = datetime(2018, 7, 1)\n",
    "end_canada_day = datetime(2018,7 ,3)\n",
    "\n",
    "evo_data.loc[((evo_data.index > canada_day) & (evo_data.index <= end_canada_day))][\"holidays\"] = 1\n",
    "modo_data.loc[((modo_data.index > canada_day) & (modo_data.index <= end_canada_day))][\"holidays\"] = 1\n",
    "c2g_data.loc[((c2g_data.index > canada_day) & (c2g_data.index <= end_canada_day))][\"holidays\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_period = '06-23'\n",
    "end_period = '07-12'\n",
    "\n",
    "evo_data = evo_data[(evo_data.index >= '2018-'+init_period) & (evo_data.index <= '2018-'+end_period)]\n",
    "modo_data = modo_data[(modo_data.index >= '2018-'+init_period) & (modo_data.index <= '2018-'+end_period)]\n",
    "c2g_data = c2g_data.loc[\"2016-12-13 15:00:00\":\"2017-02-25 17:00:00\"]\n",
    "\n",
    "unievo_data = unievo_data[(unievo_data.index >= '2018-'+init_period) & (unievo_data.index <= '2018-'+end_period)]\n",
    "unimodo_data = unimodo_data[(unimodo_data.index >= '2018-'+init_period) & (unimodo_data.index <= '2018-'+end_period)]\n",
    "unic2g_data = unic2g_data.loc[\"2016-12-13 15:00:00\":\"2017-02-25 17:00:00\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sup_learning_formatter(data, past_lags, future_steps, future_steps_skipped, train_split, all_parameters_predicted):\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    norm_data = data.values\n",
    "    travels_data = data.travels.values\n",
    "    \n",
    "    if(all_parameters_predicted):\n",
    "        for n in range(len(data) - past_lags - future_steps):\n",
    "            X.append(norm_data[n : n + past_lags])\n",
    "            y.append(norm_data[n + past_lags : n + past_lags + 1])\n",
    "        return np.array(X), np.squeeze(np.array(y))\n",
    "    \n",
    "    else:\n",
    "        for n in range(len(data) - past_lags - future_steps - future_steps_skipped):\n",
    "            X.append(norm_data[n : n + past_lags])\n",
    "            y.append(travels_data[n + past_lags  + future_steps_skipped: n + past_lags + future_steps + future_steps_skipped])\n",
    "            \n",
    "        return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_splitter(data, splits):\n",
    "    locs = [int(len(data)*n) for n in splits]\n",
    "    return data[:locs[0]], data[locs[0]:locs[1]], data[locs[1]:], data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(y, y_hat):\n",
    "    evaluation = {}\n",
    "    evaluation[\"RMSE\"] = np.sqrt(mean_squared_error(y, y_hat))\n",
    "    evaluation[\"MAE\"] = mean_absolute_error(y, y_hat)\n",
    "    evaluation[\"R2\"] = r2_score(y, y_hat)\n",
    "\n",
    "    return evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def persistance_model(X, timesteps):\n",
    "    y_hat = []\n",
    "    for x in X:\n",
    "        y_hat.append(np.array([x[-1][0] for _ in range(timesteps)]))\n",
    "\n",
    "    return np.array(y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_history(history, title, save_file=False):\n",
    "    history = pd.DataFrame(history.history)\n",
    "\n",
    "    history.plot(figsize=(8, 5))\n",
    "    plt.grid(True)\n",
    "    plt.savefig(\"plots\\\\\" + title.replace(\" \", \"_\") + \".png\", bbox_inches='tight') if save_file else print()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, will be generated the model for each dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridSearchLSTM:\n",
    "    def __init__(self):\n",
    "        self.evaluations = pd.DataFrame()\n",
    "        self.best_estimator = None\n",
    "\n",
    "    def search(self, feature_dict, data, verbose=1, windows=1, splits = (0.6, 0.8), past_lags=24, future_steps=12, future_steps_skipped=0):\n",
    "    # Essa função faz igual a do sklearn, eu só adaptei pro lstm\n",
    "    # Eu não tenho certeza se pra mais de uma window tá funcionando perfeitamente\n",
    "        \n",
    "        def average_evaluations(validation_eval, key=\"val_loss\"):\n",
    "            # Essa função é usada para ordenar a lista\n",
    "            acc_value = 0\n",
    "            for split, evaluation in validation_eval:\n",
    "                acc_value += evaluation[key]\n",
    "            return acc_value/len(validation_eval)\n",
    "        \n",
    "        # Aqui em baixo ele só gera os dicionarios com os casos de teste e em seguida percorre todos testando e salvando a performance\n",
    "        possibilities_list = self._create_feature_dict(feature_dict)\n",
    "        current_evaluations = []\n",
    "        if(windows == 1):\n",
    "            for test in tqdm(possibilities_list):\n",
    "                model, hist, test_data, evaluation = self.run_lstm(data, past_lags, future_steps, future_steps_skipped, splits, verbose=verbose, **test)\n",
    "                validation_eval = {key:value[-1] for key, value in hist.history.items()}\n",
    "                current_evaluations.append([test, validation_eval])\n",
    "        \n",
    "        else:\n",
    "            increase = splits[1]/(windows + 1)\n",
    "            for test in tqdm(possibilities_list):\n",
    "                validation_eval = []\n",
    "                for i in tqdm(range(windows)):\n",
    "                    cur_split = (increase*(i + 1), increase*(i + 2))\n",
    "                    model, hist, test_data, evaluation = self.run_lstm(data, past_lags, future_steps, future_steps_skipped, cur_split, verbose=verbose, **test)\n",
    "                    cur_validation_eval = {key:value[-1] for key, value in hist.history.items()}\n",
    "                    validation_eval.append([cur_split, cur_validation_eval])\n",
    "                    print(cur_split)\n",
    "                current_evaluations.append([test, validation_eval])\n",
    "        \n",
    "        if(windows == 1):\n",
    "            current_evaluations.sort(key=lambda x: x[1][\"val_loss\"])\n",
    "        else:\n",
    "            current_evaluations.sort(key=lambda x: average_evaluations(x[1]))   \n",
    "        \n",
    "        print(current_evaluations[0][1])\n",
    "        self.evaluations = pd.DataFrame(map(lambda x: {**x[0], **x[1]}, current_evaluations))\n",
    "        self.best_estimator = current_evaluations[0][0]\n",
    "            \n",
    "\n",
    "    def _create_feature_dict(self, feature_dict):\n",
    "        return self._create_feature_dict_recurse({}, feature_dict, list(feature_dict.keys()))\n",
    "\n",
    "    def _create_feature_dict_recurse(self, start_dict, feature_dict, remaining_keys):\n",
    "        if len(remaining_keys) == 0:\n",
    "            return [start_dict]\n",
    "        new_feature_dict = feature_dict.copy()\n",
    "        returned_list = []\n",
    "        del new_feature_dict[remaining_keys[0]]\n",
    "        for item in feature_dict[remaining_keys[0]]:\n",
    "            new_start_dict = start_dict.copy()\n",
    "            new_start_dict[remaining_keys[0]] = item\n",
    "            returned_list += self._create_feature_dict_recurse(new_start_dict, new_feature_dict, remaining_keys[1:])\n",
    "        return returned_list\n",
    "\n",
    "\n",
    "    def run_lstm(self, data, past_lags, future_steps, future_steps_skipped, splits, all_parameters_predicted=False, node_number=50,\n",
    "                 epochs=10, batch_size=64, loss='mae', dropout=0.5, layer_count=2, verbose=1):\n",
    "        \n",
    "        X, y = sup_learning_formatter(data, past_lags, future_steps, future_steps_skipped, splits[0], all_parameters_predicted)\n",
    "        X_train, X_val, X_test, X_shape = train_val_test_splitter(X, splits)\n",
    "        y_train, y_val, y_test, y_shape = train_val_test_splitter(y, splits)\n",
    "\n",
    "\n",
    "        train = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "        train = train.cache().shuffle(batch_size).batch(batch_size).repeat()\n",
    "\n",
    "        val = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
    "        val = val.batch(batch_size).repeat()\n",
    "\n",
    "        model = tf.keras.models.Sequential()\n",
    "\n",
    "        if(layer_count == 1):\n",
    "            model.add(tf.keras.layers.LSTM(node_number,\n",
    "                                    input_shape=X_shape))\n",
    "            model.add(tf.keras.layers.Dropout(dropout))\n",
    "        else:\n",
    "            model.add(tf.keras.layers.LSTM(node_number, return_sequences=True,\n",
    "                                    input_shape=X_shape))\n",
    "            model.add(tf.keras.layers.Dropout(dropout))\n",
    "\n",
    "            for _ in range(layer_count - 2):\n",
    "                model.add(tf.keras.layers.LSTM(node_number, return_sequences=True, activation='relu'))\n",
    "\n",
    "            model.add(tf.keras.layers.LSTM(node_number, activation='relu'))\n",
    "        \n",
    "        model.add(tf.keras.layers.Dense(y_shape[0]))\n",
    "        \n",
    "        def rmse(y_true, y_pred):\n",
    "            return tf.sqrt(tf.reduce_mean((y_true - y_pred)**2))\n",
    "\n",
    "        model.compile(optimizer=tf.keras.optimizers.RMSprop(clipvalue=1.0), loss=loss, metrics=[rmse])\n",
    "        \n",
    "        \n",
    "        print(X.shape, y.shape)\n",
    "        history = model.fit(train, epochs=epochs, steps_per_epoch=50,\n",
    "                            validation_data=val, validation_steps=50, verbose=verbose\n",
    "                            )\n",
    "        y_hat_test = model.predict(X_test)\n",
    "        evaluation = eval_model(y_test, y_hat_test)\n",
    "\n",
    "        return model, history, (X_test, y_test), evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchLSTM()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_dict = {\"epochs\":[25],\n",
    "                \"layer_count\":[2, 3], \n",
    "                \"node_number\":[140, 160, 180], \n",
    "                \"dropout\":[0.3, 0.5, 0.7], \n",
    "                \"all_parameters_predicted\":[False]\n",
    "}\n",
    "\n",
    "grid_search.search(feature_dict, unic2g_data, windows=1, future_steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator(x):\n",
    "    return sum([splits[-1]*values['val_loss'] for (splits, values) in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.evaluations.to_csv(f'results\\\\GridSearch_Results\\\\future_12hrs_unic2g_grid_search_{datetime.now().strftime(\"%m-%d-%Y_%Hh%Mmin%Ss\")}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('CarSharingEnv': conda)",
   "language": "python",
   "name": "python37664bitcarsharingenvcondaf61cd503e3274ce6bd69d58b01a97e08"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
