{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (8, 6)\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "tf.random.set_seed(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_epoch_number = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading data\n",
    "evo_data = pd.read_csv('data/interpol/evo_interpol_demand.csv', index_col=0)\n",
    "modo_data = pd.read_csv('data/interpol/modo_interpol_demand.csv', index_col=0)\n",
    "c2g_data = pd.read_csv('data/interpol/c2g_interpol_demand.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tempC', 'precipMM', 'FeelsLikeC', 'uvIndex', 'visibility',\n",
       "       'windspeedMiles', 'Blizzard', 'Clear', 'Cloudy', 'Fog', 'Heavy rain',\n",
       "       'Heavy rain at times', 'Heavy snow', 'Light drizzle', 'Light rain',\n",
       "       'Light rain shower', 'Light sleet', 'Light sleet showers', 'Light snow',\n",
       "       'Mist', 'Moderate or heavy freezing rain',\n",
       "       'Moderate or heavy rain shower', 'Moderate or heavy rain with thunder',\n",
       "       'Moderate or heavy sleet', 'Moderate or heavy snow showers',\n",
       "       'Moderate or heavy snow with thunder', 'Moderate rain',\n",
       "       'Moderate rain at times', 'Moderate snow', 'Overcast', 'Partly cloudy',\n",
       "       'Patchy heavy snow', 'Patchy light drizzle', 'Patchy light rain',\n",
       "       'Patchy light rain with thunder', 'Patchy light snow',\n",
       "       'Patchy moderate snow', 'Patchy rain possible', 'Patchy sleet possible',\n",
       "       'Patchy snow possible', 'Sunny', 'Thundery outbreaks possible',\n",
       "       'Torrential rain shower', 'Monday', 'Tuesday', 'Wednesday', 'Thursday',\n",
       "       'Friday', 'Saturday', 'Sunday', 'hour_0', 'hour_1', 'hour_2', 'hour_3',\n",
       "       'hour_4', 'hour_5', 'hour_6', 'hour_7', 'hour_8', 'hour_9', 'hour_10',\n",
       "       'hour_11', 'hour_12', 'hour_13', 'hour_14', 'hour_15', 'hour_16',\n",
       "       'hour_17', 'hour_18', 'hour_19', 'hour_20', 'hour_21', 'hour_22',\n",
       "       'hour_23', 'travels'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evo_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "evo_data.drop(columns = ['hour_0', 'hour_1', 'hour_2', 'hour_3',\n",
    "       'hour_4', 'hour_5', 'hour_6', 'hour_7', 'hour_8', 'hour_9', 'hour_10',\n",
    "       'hour_11', 'hour_12', 'hour_13', 'hour_14', 'hour_15', 'hour_16',\n",
    "       'hour_17', 'hour_18', 'hour_19', 'hour_20', 'hour_21', 'hour_22',\n",
    "       'hour_23'], inplace=True)\n",
    "modo_data.drop(columns = ['hour_0', 'hour_1', 'hour_2', 'hour_3',\n",
    "       'hour_4', 'hour_5', 'hour_6', 'hour_7', 'hour_8', 'hour_9', 'hour_10',\n",
    "       'hour_11', 'hour_12', 'hour_13', 'hour_14', 'hour_15', 'hour_16',\n",
    "       'hour_17', 'hour_18', 'hour_19', 'hour_20', 'hour_21', 'hour_22',\n",
    "       'hour_23'], inplace=True)\n",
    "c2g_data.drop(columns = ['hour_0', 'hour_1', 'hour_2', 'hour_3',\n",
    "       'hour_4', 'hour_5', 'hour_6', 'hour_7', 'hour_8', 'hour_9', 'hour_10',\n",
    "       'hour_11', 'hour_12', 'hour_13', 'hour_14', 'hour_15', 'hour_16',\n",
    "       'hour_17', 'hour_18', 'hour_19', 'hour_20', 'hour_21', 'hour_22',\n",
    "       'hour_23'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "unievo_data = pd.DataFrame(evo_data.travels)\n",
    "unimodo_data = pd.DataFrame(modo_data.travels)\n",
    "unic2g_data = pd.DataFrame(c2g_data.travels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_period = '06-23'\n",
    "end_period = '07-12'\n",
    "\n",
    "evo_data = evo_data[(evo_data.index >= '2018-'+init_period) & (evo_data.index <= '2018-'+end_period)]\n",
    "modo_data = modo_data[(modo_data.index >= '2018-'+init_period) & (modo_data.index <= '2018-'+end_period)]\n",
    "c2g_data = c2g_data[(c2g_data.index >= '2017-'+init_period) & (c2g_data.index <= '2017-'+end_period)]\n",
    "\n",
    "unievo_data = unievo_data[(unievo_data.index >= '2018-'+init_period) & (unievo_data.index <= '2018-'+end_period)]\n",
    "unimodo_data = unimodo_data[(unimodo_data.index >= '2018-'+init_period) & (unimodo_data.index <= '2018-'+end_period)]\n",
    "unic2g_data = unic2g_data[(unic2g_data.index >= '2017-'+init_period) & (unic2g_data.index <= '2017-'+end_period)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the Canada Day Holiday\n",
    "evo_data.index = pd.to_datetime(evo_data.index)\n",
    "modo_data.index = pd.to_datetime(modo_data.index)\n",
    "c2g_data.index = pd.to_datetime(c2g_data.index)\n",
    "\n",
    "evo_data[\"holidays\"] = pd.Series()\n",
    "modo_data[\"holidays\"] = pd.Series()\n",
    "c2g_data[\"holidays\"] = pd.Series()\n",
    "\n",
    "evo_data[\"holidays\"] = evo_data[\"holidays\"].fillna(0)\n",
    "modo_data[\"holidays\"] = modo_data[\"holidays\"].fillna(0)\n",
    "c2g_data[\"holidays\"] = c2g_data[\"holidays\"].fillna(0)\n",
    "\n",
    "canada_day = datetime(2018, 7, 1)\n",
    "end_canada_day = datetime(2018,7 ,3)\n",
    "\n",
    "evo_data.loc[((evo_data.index > canada_day) & (evo_data.index <= end_canada_day))][\"holidays\"] = 1\n",
    "modo_data.loc[((modo_data.index > canada_day) & (modo_data.index <= end_canada_day))][\"holidays\"] = 1\n",
    "c2g_data.loc[((c2g_data.index > canada_day) & (c2g_data.index <= end_canada_day))][\"holidays\"] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sup_learning_formatter(data, past_lags, future_steps, train_split):\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    norm_data  = data.values\n",
    "\n",
    "    for n in range(len(data) - past_lags - future_steps):\n",
    "        X.append(norm_data[n : n + past_lags])\n",
    "        y.append(data.travels.values[n + past_lags : n + past_lags + future_steps])\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_splitter(data, splits):\n",
    "    locs = [int(len(data)*n) for n in splits]\n",
    "    return data[:locs[0]], data[locs[0]:locs[1]], data[locs[1]:], data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(y, y_hat):\n",
    "    evaluation = {}\n",
    "    evaluation[\"RMSE\"] = np.sqrt(mean_squared_error(y, y_hat))\n",
    "    evaluation[\"MAE\"] = mean_absolute_error(y, y_hat)\n",
    "    evaluation[\"R2\"] = r2_score(y, y_hat)\n",
    "\n",
    "    return evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def persistance_model(X, timesteps):\n",
    "    y_hat = []\n",
    "    for x in X:\n",
    "        y_hat.append(np.array([x[-1][0] for _ in range(timesteps)]))\n",
    "\n",
    "    return np.array(y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_history(history, title, save_file=False):\n",
    "    history = pd.DataFrame(history.history)\n",
    "\n",
    "    history.plot(figsize=(8, 5))\n",
    "    plt.grid(True)\n",
    "    plt.savefig(\"plots\\\\\" + title.replace(\" \", \"_\") + \".png\", bbox_inches='tight') if save_file else print()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, will be generated the model for each dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridSearchLSTM:\n",
    "    def __init__(self):\n",
    "        self.evaluations = {}\n",
    "        self.best_estimator = None\n",
    "\n",
    "    def search(self, feature_dict, data, verbose=1, windows=1, splits = (0.6, 0.8)):\n",
    "        \n",
    "        def average_evaluations(validation_eval, key=\"val_loss\"):\n",
    "            acc_value = 0\n",
    "            for split, evaluation in validation_eval:\n",
    "                acc_value += evaluation[key]\n",
    "            return acc_value/len(validation_eval)\n",
    "        \n",
    "        possibilities_list = self._create_feature_dict(feature_dict)\n",
    "        current_evaluations = []\n",
    "        if(windows == 1):\n",
    "            for test in tqdm(possibilities_list):\n",
    "                model, hist, test_data, evaluation = self.run_lstm(data, 24, 12, splits, verbose=verbose, **test)\n",
    "                validation_eval = {key:value[-1] for key, value in hist.history.items()}\n",
    "                current_evaluations.append([test, validation_eval])\n",
    "        \n",
    "        else:\n",
    "            increase = splits[1]/(windows + 1)\n",
    "            for test in tqdm(possibilities_list):\n",
    "                validation_eval = []\n",
    "                for i in tqdm(range(windows)):\n",
    "                    cur_split = (increase*(i + 1), increase*(i + 2))\n",
    "                    model, hist, test_data, evaluation = self.run_lstm(data, 24, 12, cur_split, verbose=verbose, **test)\n",
    "                    cur_validation_eval = {key:value[-1] for key, value in hist.history.items()}\n",
    "                    validation_eval.append([cur_split, cur_validation_eval])\n",
    "                    print(cur_split)\n",
    "                current_evaluations.append([test, validation_eval])\n",
    "        \n",
    "        if(windows == 1):\n",
    "            current_evaluations.sort(key=lambda x: x[1][\"val_loss\"])\n",
    "        else:\n",
    "            current_evaluations.sort(key=lambda x: average_evaluations(x[1]))   \n",
    "        \n",
    "        self.evaluations = current_evaluations\n",
    "        self.best_estimator = current_evaluations[0][0]\n",
    "            \n",
    "\n",
    "    def _create_feature_dict(self, feature_dict):\n",
    "        return self._create_feature_dict_recurse({}, feature_dict, list(feature_dict.keys()))\n",
    "\n",
    "    def _create_feature_dict_recurse(self, start_dict, feature_dict, remaining_keys):\n",
    "        if len(remaining_keys) == 0:\n",
    "            return [start_dict]\n",
    "        new_feature_dict = feature_dict.copy()\n",
    "        returned_list = []\n",
    "        del new_feature_dict[remaining_keys[0]]\n",
    "        for item in feature_dict[remaining_keys[0]]:\n",
    "            new_start_dict = start_dict.copy()\n",
    "            new_start_dict[remaining_keys[0]] = item\n",
    "            returned_list += self._create_feature_dict_recurse(new_start_dict, new_feature_dict, remaining_keys[1:])\n",
    "        return returned_list\n",
    "\n",
    "\n",
    "    def run_lstm(self, data, past_lags, future_steps, splits, node_number=50,\n",
    "                 epochs=10, batch_size=10000, loss='mae', dropout=0.5, layer_count=2, verbose=1):\n",
    "        \n",
    "        X, y = sup_learning_formatter(data, past_lags, future_steps, splits[0])\n",
    "        X_train, X_val, X_test, X_shape = train_val_test_splitter(X, splits)\n",
    "        y_train, y_val, y_test, y_shape = train_val_test_splitter(y, splits)\n",
    "\n",
    "\n",
    "        train = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "        train = train.cache().shuffle(batch_size).batch(batch_size).repeat()\n",
    "\n",
    "        val = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
    "        val = val.batch(batch_size).repeat()\n",
    "\n",
    "        model = tf.keras.models.Sequential()\n",
    "\n",
    "        if(layer_count == 1):\n",
    "            model.add(tf.keras.layers.LSTM(node_number,\n",
    "                                    input_shape=X_shape))\n",
    "            model.add(tf.keras.layers.Dropout(dropout))\n",
    "        else:\n",
    "            model.add(tf.keras.layers.LSTM(node_number, return_sequences=True,\n",
    "                                    input_shape=X_shape))\n",
    "            model.add(tf.keras.layers.Dropout(dropout))\n",
    "\n",
    "            for _ in range(layer_count - 2):\n",
    "                model.add(tf.keras.layers.LSTM(node_number, return_sequences=True, activation='relu'))\n",
    "\n",
    "            model.add(tf.keras.layers.LSTM(node_number, activation='relu'))\n",
    "        \n",
    "        model.add(tf.keras.layers.Dense(12))\n",
    "        \n",
    "        def rmse(y_true, y_pred):\n",
    "            return tf.sqrt(tf.reduce_mean((y_true - y_pred)**2))\n",
    "\n",
    "        model.compile(optimizer=tf.keras.optimizers.RMSprop(clipvalue=1.0), loss=loss, metrics=[rmse])\n",
    "        \n",
    "        history = model.fit(train, epochs=epochs, steps_per_epoch=50,\n",
    "                            validation_data=val, validation_steps=50, verbose=verbose\n",
    "                            )\n",
    "        y_hat_test = model.predict(X_test)\n",
    "        evaluation = eval_model(y_test, y_hat_test)\n",
    "\n",
    "        return model, history, (X_test, y_test), evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchLSTM()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1ca9e76cfb246dfba9fea772cf79d18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37602d915258407e82bb88ef90c30b12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Train for 50 steps, validate for 50 steps\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "50/50 [==============================] - 12s 245ms/step - loss: 28.5294 - rmse: 36.4201 - val_loss: 31.7608 - val_rmse: 40.5342\n",
      "Epoch 2/25\n",
      "50/50 [==============================] - 5s 103ms/step - loss: 16.7143 - rmse: 21.4995 - val_loss: 24.5648 - val_rmse: 32.0105\n",
      "Epoch 3/25\n",
      "50/50 [==============================] - 5s 110ms/step - loss: 12.6173 - rmse: 16.9347 - val_loss: 22.0145 - val_rmse: 29.0612\n",
      "Epoch 4/25\n",
      "50/50 [==============================] - 5s 107ms/step - loss: 10.6354 - rmse: 14.5317 - val_loss: 26.3970 - val_rmse: 34.0070\n",
      "Epoch 5/25\n",
      "50/50 [==============================] - 5s 109ms/step - loss: 9.4263 - rmse: 13.0071 - val_loss: 22.8315 - val_rmse: 30.0719\n",
      "Epoch 6/25\n",
      "50/50 [==============================] - 5s 104ms/step - loss: 8.6712 - rmse: 11.9905 - val_loss: 16.0557 - val_rmse: 22.1583\n",
      "Epoch 7/25\n",
      "50/50 [==============================] - 5s 103ms/step - loss: 8.0341 - rmse: 11.1814 - val_loss: 17.7622 - val_rmse: 24.3391\n",
      "Epoch 8/25\n",
      "50/50 [==============================] - 5s 100ms/step - loss: 7.7476 - rmse: 10.8153 - val_loss: 16.0918 - val_rmse: 22.4003\n",
      "Epoch 9/25\n",
      "50/50 [==============================] - 6s 110ms/step - loss: 7.2805 - rmse: 10.2153 - val_loss: 10.6536 - val_rmse: 15.3634\n",
      "Epoch 10/25\n",
      "50/50 [==============================] - 5s 96ms/step - loss: 7.0291 - rmse: 9.9049 - val_loss: 10.5789 - val_rmse: 15.4502\n",
      "Epoch 11/25\n",
      "50/50 [==============================] - 5s 90ms/step - loss: 6.8079 - rmse: 9.6015 - val_loss: 13.8409 - val_rmse: 20.0748\n",
      "Epoch 12/25\n",
      "50/50 [==============================] - 4s 89ms/step - loss: 6.6690 - rmse: 9.4117 - val_loss: 15.0407 - val_rmse: 21.3777\n",
      "Epoch 13/25\n",
      "50/50 [==============================] - 5s 94ms/step - loss: 6.4519 - rmse: 9.1340 - val_loss: 11.4526 - val_rmse: 16.5255\n",
      "Epoch 14/25\n",
      "50/50 [==============================] - 4s 89ms/step - loss: 6.2674 - rmse: 8.8936 - val_loss: 11.3401 - val_rmse: 16.2565\n",
      "Epoch 15/25\n",
      "50/50 [==============================] - 4s 89ms/step - loss: 6.1684 - rmse: 8.7868 - val_loss: 10.6885 - val_rmse: 15.5468\n",
      "Epoch 16/25\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 6.0456 - rmse: 8.6319 - val_loss: 14.4711 - val_rmse: 20.3637\n",
      "Epoch 17/25\n",
      "50/50 [==============================] - 5s 91ms/step - loss: 5.9518 - rmse: 8.5338 - val_loss: 10.5823 - val_rmse: 15.3054\n",
      "Epoch 18/25\n",
      "50/50 [==============================] - 4s 90ms/step - loss: 5.8214 - rmse: 8.3740 - val_loss: 9.8184 - val_rmse: 14.1592\n",
      "Epoch 19/25\n",
      "50/50 [==============================] - 5s 90ms/step - loss: 5.7165 - rmse: 8.2397 - val_loss: 10.6181 - val_rmse: 15.2515\n",
      "Epoch 20/25\n",
      "50/50 [==============================] - 5s 95ms/step - loss: 5.6472 - rmse: 8.1518 - val_loss: 12.2458 - val_rmse: 17.7900\n",
      "Epoch 21/25\n",
      "50/50 [==============================] - 4s 89ms/step - loss: 5.5229 - rmse: 8.0143 - val_loss: 11.8942 - val_rmse: 17.3431\n",
      "Epoch 22/25\n",
      "50/50 [==============================] - 4s 90ms/step - loss: 5.4313 - rmse: 7.9280 - val_loss: 9.2023 - val_rmse: 13.4909\n",
      "Epoch 23/25\n",
      "50/50 [==============================] - 5s 94ms/step - loss: 5.4042 - rmse: 7.9109 - val_loss: 10.7571 - val_rmse: 15.6906\n",
      "Epoch 24/25\n",
      "50/50 [==============================] - 5s 91ms/step - loss: 5.3101 - rmse: 7.8297 - val_loss: 8.8634 - val_rmse: 12.9462\n",
      "Epoch 25/25\n",
      "50/50 [==============================] - 5s 91ms/step - loss: 5.1621 - rmse: 7.6353 - val_loss: 9.7895 - val_rmse: 14.2908\n",
      "(0.2, 0.4)\n",
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Train for 50 steps, validate for 50 steps\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "50/50 [==============================] - 13s 255ms/step - loss: 25.9850 - rmse: 33.0966 - val_loss: 79.7690 - val_rmse: 118.6955\n",
      "Epoch 2/25\n",
      "50/50 [==============================] - 7s 131ms/step - loss: 16.8702 - rmse: 22.3707 - val_loss: 72.7436 - val_rmse: 112.5171\n",
      "Epoch 3/25\n",
      "50/50 [==============================] - 7s 133ms/step - loss: 13.0231 - rmse: 17.8385 - val_loss: 73.7726 - val_rmse: 112.7742\n",
      "Epoch 4/25\n",
      "50/50 [==============================] - 6s 129ms/step - loss: 10.9158 - rmse: 15.2498 - val_loss: 70.5932 - val_rmse: 110.3829\n",
      "Epoch 5/25\n",
      "50/50 [==============================] - 7s 133ms/step - loss: 10.0134 - rmse: 14.0563 - val_loss: 72.1938 - val_rmse: 111.4554\n",
      "Epoch 6/25\n",
      "50/50 [==============================] - 6s 126ms/step - loss: 9.1028 - rmse: 12.8734 - val_loss: 74.3488 - val_rmse: 113.5750\n",
      "Epoch 7/25\n",
      "50/50 [==============================] - 6s 127ms/step - loss: 8.5525 - rmse: 12.1633 - val_loss: 70.2235 - val_rmse: 110.2530\n",
      "Epoch 8/25\n",
      "50/50 [==============================] - 7s 130ms/step - loss: 8.1839 - rmse: 11.6505 - val_loss: 70.4931 - val_rmse: 110.7767\n",
      "Epoch 9/25\n",
      "50/50 [==============================] - 6s 127ms/step - loss: 7.8320 - rmse: 11.1788 - val_loss: 71.1354 - val_rmse: 111.9077\n",
      "Epoch 10/25\n",
      "50/50 [==============================] - 7s 131ms/step - loss: 7.5986 - rmse: 10.9322 - val_loss: 71.0017 - val_rmse: 112.0296\n",
      "Epoch 11/25\n",
      "50/50 [==============================] - 6s 125ms/step - loss: 7.3802 - rmse: 10.5772 - val_loss: 72.1152 - val_rmse: 112.8095\n",
      "Epoch 12/25\n",
      "50/50 [==============================] - 6s 125ms/step - loss: 7.2135 - rmse: 10.3686 - val_loss: 71.9317 - val_rmse: 112.6781\n",
      "Epoch 13/25\n",
      "50/50 [==============================] - 7s 130ms/step - loss: 7.1096 - rmse: 10.2145 - val_loss: 70.3613 - val_rmse: 111.3374\n",
      "Epoch 14/25\n",
      "50/50 [==============================] - 6s 125ms/step - loss: 6.9761 - rmse: 10.0334 - val_loss: 70.5437 - val_rmse: 112.0986\n",
      "Epoch 15/25\n",
      "50/50 [==============================] - 6s 129ms/step - loss: 6.8115 - rmse: 9.8203 - val_loss: 70.3236 - val_rmse: 111.7285\n",
      "Epoch 16/25\n",
      "50/50 [==============================] - 6s 126ms/step - loss: 6.7006 - rmse: 9.6628 - val_loss: 70.1765 - val_rmse: 111.9034\n",
      "Epoch 17/25\n",
      "50/50 [==============================] - 6s 128ms/step - loss: 6.6733 - rmse: 9.6346 - val_loss: 70.5008 - val_rmse: 112.1400\n",
      "Epoch 18/25\n",
      "50/50 [==============================] - 7s 131ms/step - loss: 6.4635 - rmse: 9.3371 - val_loss: 69.5913 - val_rmse: 111.5166\n",
      "Epoch 19/25\n",
      "50/50 [==============================] - 6s 126ms/step - loss: 6.4234 - rmse: 9.2593 - val_loss: 72.4458 - val_rmse: 113.5518\n",
      "Epoch 20/25\n",
      "50/50 [==============================] - 6s 129ms/step - loss: 6.3167 - rmse: 9.1356 - val_loss: 71.1037 - val_rmse: 112.6447\n",
      "Epoch 21/25\n",
      "50/50 [==============================] - 6s 125ms/step - loss: 6.2467 - rmse: 9.0159 - val_loss: 69.0876 - val_rmse: 110.7576\n",
      "Epoch 22/25\n",
      "50/50 [==============================] - 7s 137ms/step - loss: 6.1454 - rmse: 8.8798 - val_loss: 69.2721 - val_rmse: 110.9715\n",
      "Epoch 23/25\n",
      "50/50 [==============================] - 7s 133ms/step - loss: 6.0627 - rmse: 8.7644 - val_loss: 70.8952 - val_rmse: 112.5472\n",
      "Epoch 24/25\n",
      "50/50 [==============================] - 6s 126ms/step - loss: 5.9606 - rmse: 8.6254 - val_loss: 68.0947 - val_rmse: 109.6056\n",
      "Epoch 25/25\n",
      "50/50 [==============================] - 7s 133ms/step - loss: 5.8631 - rmse: 8.4841 - val_loss: 71.5934 - val_rmse: 112.7279\n",
      "(0.4, 0.6000000000000001)\n",
      "Train for 50 steps, validate for 50 steps\n",
      "Epoch 1/25\n",
      "50/50 [==============================] - 17s 340ms/step - loss: 46.6005 - rmse: 75.5985 - val_loss: 27.1954 - val_rmse: 35.4592\n",
      "Epoch 2/25\n",
      "50/50 [==============================] - 10s 196ms/step - loss: 34.3692 - rmse: 62.2007 - val_loss: 29.1206 - val_rmse: 37.4706\n",
      "Epoch 3/25\n",
      "50/50 [==============================] - 10s 203ms/step - loss: 31.0398 - rmse: 60.6073 - val_loss: 25.6377 - val_rmse: 33.2424\n",
      "Epoch 4/25\n",
      "50/50 [==============================] - 10s 205ms/step - loss: 28.9687 - rmse: 59.8343 - val_loss: 14.5104 - val_rmse: 20.5321\n",
      "Epoch 5/25\n",
      "50/50 [==============================] - 10s 202ms/step - loss: 27.5266 - rmse: 59.1134 - val_loss: 12.4062 - val_rmse: 17.1330\n",
      "Epoch 6/25\n",
      "50/50 [==============================] - 10s 208ms/step - loss: 26.3674 - rmse: 58.2238 - val_loss: 13.6758 - val_rmse: 19.4867\n",
      "Epoch 7/25\n",
      "50/50 [==============================] - 10s 208ms/step - loss: 26.1827 - rmse: 58.1998 - val_loss: 12.7128 - val_rmse: 18.0454\n",
      "Epoch 8/25\n",
      "50/50 [==============================] - 10s 205ms/step - loss: 22.8202 - rmse: 49.7371 - val_loss: 17.2051 - val_rmse: 24.3134\n",
      "Epoch 9/25\n",
      "50/50 [==============================] - 11s 211ms/step - loss: 18.9046 - rmse: 38.6104 - val_loss: 10.9229 - val_rmse: 15.9160\n",
      "Epoch 10/25\n",
      "50/50 [==============================] - 11s 215ms/step - loss: 15.6160 - rmse: 30.7044 - val_loss: 11.3734 - val_rmse: 16.2329\n",
      "Epoch 11/25\n",
      "50/50 [==============================] - 11s 211ms/step - loss: 14.4818 - rmse: 28.3841 - val_loss: 10.1259 - val_rmse: 13.9941\n",
      "Epoch 12/25\n",
      "50/50 [==============================] - 10s 210ms/step - loss: 13.8086 - rmse: 26.6391 - val_loss: 9.7916 - val_rmse: 13.6698\n",
      "Epoch 13/25\n",
      "50/50 [==============================] - 10s 207ms/step - loss: 13.2118 - rmse: 25.7690 - val_loss: 9.3367 - val_rmse: 12.7877\n",
      "Epoch 14/25\n",
      "50/50 [==============================] - 10s 204ms/step - loss: 12.3257 - rmse: 24.1386 - val_loss: 11.3653 - val_rmse: 15.6582\n",
      "Epoch 15/25\n",
      "50/50 [==============================] - 10s 207ms/step - loss: 11.7918 - rmse: 23.0296 - val_loss: 8.6812 - val_rmse: 12.1284\n",
      "Epoch 16/25\n",
      "50/50 [==============================] - 10s 205ms/step - loss: 11.3350 - rmse: 21.9991 - val_loss: 11.5085 - val_rmse: 16.1981\n",
      "Epoch 17/25\n",
      "50/50 [==============================] - 10s 205ms/step - loss: 10.8798 - rmse: 21.3915 - val_loss: 10.2087 - val_rmse: 14.0977\n",
      "Epoch 18/25\n",
      "50/50 [==============================] - 10s 209ms/step - loss: 10.5856 - rmse: 20.5514 - val_loss: 10.0644 - val_rmse: 14.0599\n",
      "Epoch 19/25\n",
      "50/50 [==============================] - 10s 205ms/step - loss: 10.4245 - rmse: 20.3116 - val_loss: 9.3012 - val_rmse: 12.7440\n",
      "Epoch 20/25\n",
      "50/50 [==============================] - 10s 208ms/step - loss: 10.2918 - rmse: 20.4677 - val_loss: 9.2834 - val_rmse: 13.0045\n",
      "Epoch 21/25\n",
      "50/50 [==============================] - 10s 206ms/step - loss: 9.8874 - rmse: 19.0655 - val_loss: 8.0381 - val_rmse: 11.0638\n",
      "Epoch 22/25\n",
      "50/50 [==============================] - 10s 203ms/step - loss: 9.7681 - rmse: 19.3161 - val_loss: 7.2335 - val_rmse: 10.2700\n",
      "Epoch 23/25\n",
      "50/50 [==============================] - 10s 207ms/step - loss: 9.2190 - rmse: 18.0240 - val_loss: 8.2284 - val_rmse: 11.4983\n",
      "Epoch 24/25\n",
      "50/50 [==============================] - 10s 208ms/step - loss: 9.4255 - rmse: 18.7705 - val_loss: 7.7596 - val_rmse: 10.8717\n",
      "Epoch 25/25\n",
      "50/50 [==============================] - 10s 205ms/step - loss: 9.2358 - rmse: 18.1388 - val_loss: 8.7851 - val_rmse: 12.0978\n",
      "(0.6000000000000001, 0.8)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daeeab054ad14842b67d61729c6bc781",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 50 steps, validate for 50 steps\n",
      "Epoch 1/25\n",
      "50/50 [==============================] - 14s 280ms/step - loss: 25.5750 - rmse: 31.8826 - val_loss: 25.8322 - val_rmse: 33.6345\n",
      "Epoch 2/25\n",
      "50/50 [==============================] - 7s 144ms/step - loss: 17.8746 - rmse: 23.0256 - val_loss: 23.1886 - val_rmse: 30.2899\n",
      "Epoch 3/25\n",
      "50/50 [==============================] - 7s 141ms/step - loss: 13.7555 - rmse: 18.1278 - val_loss: 25.5687 - val_rmse: 32.9321\n",
      "Epoch 4/25\n",
      "50/50 [==============================] - 7s 145ms/step - loss: 11.2072 - rmse: 15.1408 - val_loss: 22.4751 - val_rmse: 29.4719\n",
      "Epoch 5/25\n",
      "50/50 [==============================] - 7s 142ms/step - loss: 9.9087 - rmse: 13.5621 - val_loss: 14.4107 - val_rmse: 20.1175\n",
      "Epoch 6/25\n",
      "50/50 [==============================] - 7s 147ms/step - loss: 9.0476 - rmse: 12.4583 - val_loss: 19.2112 - val_rmse: 25.9733\n",
      "Epoch 7/25\n",
      "50/50 [==============================] - 7s 143ms/step - loss: 8.5586 - rmse: 11.8298 - val_loss: 16.9062 - val_rmse: 23.3389\n",
      "Epoch 8/25\n",
      "50/50 [==============================] - 7s 143ms/step - loss: 8.0098 - rmse: 11.0795 - val_loss: 14.4192 - val_rmse: 20.4048\n",
      "Epoch 9/25\n",
      "50/50 [==============================] - 7s 146ms/step - loss: 7.7381 - rmse: 10.7679 - val_loss: 15.6677 - val_rmse: 21.7818\n",
      "Epoch 10/25\n",
      "50/50 [==============================] - 7s 143ms/step - loss: 7.4881 - rmse: 10.4459 - val_loss: 12.3604 - val_rmse: 17.5941\n",
      "Epoch 11/25\n",
      "50/50 [==============================] - 7s 145ms/step - loss: 7.1118 - rmse: 9.9692 - val_loss: 15.7527 - val_rmse: 21.9475\n",
      "Epoch 12/25\n",
      "50/50 [==============================] - 7s 143ms/step - loss: 7.0778 - rmse: 9.9122 - val_loss: 12.4848 - val_rmse: 17.8566\n",
      "Epoch 13/25\n",
      "50/50 [==============================] - 7s 145ms/step - loss: 6.6572 - rmse: 9.3601 - val_loss: 17.4425 - val_rmse: 23.9241\n",
      "Epoch 14/25\n",
      "50/50 [==============================] - 7s 143ms/step - loss: 6.7516 - rmse: 9.5306 - val_loss: 11.9267 - val_rmse: 17.4469\n",
      "Epoch 15/25\n",
      "50/50 [==============================] - 7s 145ms/step - loss: 6.3976 - rmse: 9.0423 - val_loss: 10.9549 - val_rmse: 16.1478\n",
      "Epoch 16/25\n",
      "50/50 [==============================] - 7s 142ms/step - loss: 6.4729 - rmse: 9.1734 - val_loss: 12.9881 - val_rmse: 18.7557\n",
      "Epoch 17/25\n",
      "50/50 [==============================] - 7s 144ms/step - loss: 6.1917 - rmse: 8.8211 - val_loss: 13.2583 - val_rmse: 18.9062\n",
      "Epoch 18/25\n",
      "50/50 [==============================] - 7s 145ms/step - loss: 6.1526 - rmse: 8.7637 - val_loss: 11.8180 - val_rmse: 17.2330\n",
      "Epoch 19/25\n",
      "50/50 [==============================] - 7s 144ms/step - loss: 5.9870 - rmse: 8.5380 - val_loss: 12.2814 - val_rmse: 17.5726\n",
      "Epoch 20/25\n",
      "50/50 [==============================] - 7s 145ms/step - loss: 5.9082 - rmse: 8.4779 - val_loss: 10.0437 - val_rmse: 14.6199\n",
      "Epoch 21/25\n",
      "50/50 [==============================] - 7s 142ms/step - loss: 5.8251 - rmse: 8.3716 - val_loss: 10.2856 - val_rmse: 15.0618\n",
      "Epoch 22/25\n",
      "50/50 [==============================] - 7s 145ms/step - loss: 5.6782 - rmse: 8.1963 - val_loss: 12.0659 - val_rmse: 17.2315\n",
      "Epoch 23/25\n",
      "50/50 [==============================] - 7s 144ms/step - loss: 5.6109 - rmse: 8.1146 - val_loss: 9.1703 - val_rmse: 13.4415\n",
      "Epoch 24/25\n",
      "50/50 [==============================] - 7s 145ms/step - loss: 5.5038 - rmse: 7.9997 - val_loss: 10.7879 - val_rmse: 15.5993\n",
      "Epoch 25/25\n",
      "50/50 [==============================] - 7s 143ms/step - loss: 5.3659 - rmse: 7.8295 - val_loss: 11.1213 - val_rmse: 15.9429\n",
      "(0.2, 0.4)\n",
      "Train for 50 steps, validate for 50 steps\n",
      "Epoch 1/25\n",
      "50/50 [==============================] - 21s 427ms/step - loss: 525.0519 - rmse: 732.2728 - val_loss: 95.9294 - val_rmse: 134.5838\n",
      "Epoch 2/25\n",
      "50/50 [==============================] - 16s 326ms/step - loss: 67.6906 - rmse: 97.5134 - val_loss: 69.4161 - val_rmse: 104.7798\n",
      "Epoch 3/25\n",
      "50/50 [==============================] - 15s 303ms/step - loss: 29.7297 - rmse: 38.6387 - val_loss: 72.8960 - val_rmse: 111.8216\n",
      "Epoch 4/25\n",
      "50/50 [==============================] - 15s 302ms/step - loss: 20.4220 - rmse: 26.6805 - val_loss: 76.0115 - val_rmse: 115.6481\n",
      "Epoch 5/25\n",
      "50/50 [==============================] - 15s 300ms/step - loss: 17.2694 - rmse: 23.0164 - val_loss: 74.9472 - val_rmse: 114.6359\n",
      "Epoch 6/25\n",
      "50/50 [==============================] - 15s 303ms/step - loss: 13.1222 - rmse: 17.9463 - val_loss: 73.1762 - val_rmse: 113.1484\n",
      "Epoch 7/25\n",
      "50/50 [==============================] - 15s 302ms/step - loss: 11.0314 - rmse: 15.2852 - val_loss: 68.5211 - val_rmse: 109.5264\n",
      "Epoch 8/25\n",
      "50/50 [==============================] - 15s 302ms/step - loss: 10.0110 - rmse: 13.9402 - val_loss: 69.9607 - val_rmse: 110.5493\n",
      "Epoch 9/25\n",
      "50/50 [==============================] - 15s 307ms/step - loss: 9.0428 - rmse: 12.7268 - val_loss: 64.1047 - val_rmse: 105.1021\n",
      "Epoch 10/25\n",
      "50/50 [==============================] - 15s 302ms/step - loss: 8.6743 - rmse: 12.2225 - val_loss: 68.5998 - val_rmse: 110.1719\n",
      "Epoch 11/25\n",
      "50/50 [==============================] - 15s 303ms/step - loss: 8.2107 - rmse: 11.6059 - val_loss: 64.6423 - val_rmse: 105.9832\n",
      "Epoch 12/25\n",
      "50/50 [==============================] - 15s 305ms/step - loss: 7.9088 - rmse: 11.2024 - val_loss: 66.2070 - val_rmse: 107.9240\n",
      "Epoch 13/25\n",
      "50/50 [==============================] - 15s 301ms/step - loss: 7.6209 - rmse: 10.8341 - val_loss: 66.4146 - val_rmse: 108.1728\n",
      "Epoch 14/25\n",
      "50/50 [==============================] - 15s 303ms/step - loss: 7.3823 - rmse: 10.5508 - val_loss: 65.0592 - val_rmse: 106.6151\n",
      "Epoch 15/25\n",
      "50/50 [==============================] - 15s 303ms/step - loss: 7.1924 - rmse: 10.2905 - val_loss: 67.5547 - val_rmse: 109.5127\n",
      "Epoch 16/25\n",
      "50/50 [==============================] - 15s 303ms/step - loss: 7.0315 - rmse: 10.0713 - val_loss: 64.0113 - val_rmse: 106.1115\n",
      "Epoch 17/25\n",
      "50/50 [==============================] - 15s 301ms/step - loss: 6.8272 - rmse: 9.8025 - val_loss: 66.8836 - val_rmse: 108.8730\n",
      "Epoch 18/25\n",
      "50/50 [==============================] - 15s 303ms/step - loss: 6.7035 - rmse: 9.6349 - val_loss: 66.0359 - val_rmse: 108.1885\n",
      "Epoch 19/25\n",
      "50/50 [==============================] - 15s 302ms/step - loss: 6.6020 - rmse: 9.5185 - val_loss: 65.5693 - val_rmse: 108.1665\n",
      "Epoch 20/25\n",
      "50/50 [==============================] - 15s 302ms/step - loss: 6.4857 - rmse: 9.3454 - val_loss: 66.1541 - val_rmse: 108.4110\n",
      "Epoch 21/25\n",
      "50/50 [==============================] - 15s 303ms/step - loss: 6.3783 - rmse: 9.1999 - val_loss: 65.3101 - val_rmse: 108.5041\n",
      "Epoch 22/25\n",
      "50/50 [==============================] - 15s 300ms/step - loss: 6.2464 - rmse: 9.0218 - val_loss: 66.0385 - val_rmse: 108.6843\n",
      "Epoch 23/25\n",
      "50/50 [==============================] - 15s 303ms/step - loss: 6.1872 - rmse: 8.9416 - val_loss: 64.9146 - val_rmse: 107.5186\n",
      "Epoch 24/25\n",
      "50/50 [==============================] - 15s 303ms/step - loss: 6.0653 - rmse: 8.7966 - val_loss: 65.0270 - val_rmse: 107.8011\n",
      "Epoch 25/25\n",
      "50/50 [==============================] - 15s 302ms/step - loss: 6.0238 - rmse: 8.7125 - val_loss: 65.0224 - val_rmse: 108.5915\n",
      "(0.4, 0.6000000000000001)\n",
      "Train for 50 steps, validate for 50 steps\n",
      "Epoch 1/25\n",
      "50/50 [==============================] - 25s 510ms/step - loss: 42.4792 - rmse: 70.9520 - val_loss: 26.2656 - val_rmse: 34.4333\n",
      "Epoch 2/25\n",
      "50/50 [==============================] - 19s 379ms/step - loss: 33.4337 - rmse: 62.3910 - val_loss: 14.5019 - val_rmse: 19.6367\n",
      "Epoch 3/25\n",
      "50/50 [==============================] - 19s 383ms/step - loss: 30.8912 - rmse: 60.9972 - val_loss: 17.0652 - val_rmse: 24.1321\n",
      "Epoch 4/25\n",
      "50/50 [==============================] - 20s 391ms/step - loss: 28.6899 - rmse: 59.8635 - val_loss: 15.8070 - val_rmse: 21.7931\n",
      "Epoch 5/25\n",
      "50/50 [==============================] - 20s 392ms/step - loss: 27.7150 - rmse: 59.2769 - val_loss: 11.2055 - val_rmse: 15.1355\n",
      "Epoch 6/25\n",
      "50/50 [==============================] - 20s 390ms/step - loss: 26.9295 - rmse: 58.8202 - val_loss: 15.4866 - val_rmse: 21.8559\n",
      "Epoch 7/25\n",
      "50/50 [==============================] - 20s 391ms/step - loss: 25.5159 - rmse: 57.8544 - val_loss: 13.3597 - val_rmse: 18.7073\n",
      "Epoch 8/25\n",
      "50/50 [==============================] - 20s 394ms/step - loss: 24.8811 - rmse: 56.2924 - val_loss: 11.0858 - val_rmse: 15.5671\n",
      "Epoch 9/25\n",
      "50/50 [==============================] - 20s 391ms/step - loss: 28.0266 - rmse: 56.8030 - val_loss: 12.6469 - val_rmse: 17.6825\n",
      "Epoch 10/25\n",
      "50/50 [==============================] - 20s 392ms/step - loss: 22.8063 - rmse: 46.1310 - val_loss: 10.4144 - val_rmse: 14.5296\n",
      "Epoch 11/25\n",
      "50/50 [==============================] - 20s 391ms/step - loss: 18.5212 - rmse: 37.0904 - val_loss: 12.3413 - val_rmse: 17.0008\n",
      "Epoch 12/25\n",
      "50/50 [==============================] - 20s 395ms/step - loss: 15.6267 - rmse: 31.3964 - val_loss: 9.8168 - val_rmse: 13.9478\n",
      "Epoch 13/25\n",
      "50/50 [==============================] - 20s 392ms/step - loss: 14.5654 - rmse: 29.0342 - val_loss: 10.9826 - val_rmse: 15.0480\n",
      "Epoch 14/25\n",
      "50/50 [==============================] - 20s 392ms/step - loss: 13.6673 - rmse: 28.7283 - val_loss: 7.1089 - val_rmse: 9.9083\n",
      "Epoch 15/25\n",
      "50/50 [==============================] - 20s 390ms/step - loss: 12.5093 - rmse: 25.6424 - val_loss: 8.7026 - val_rmse: 11.6536\n",
      "Epoch 16/25\n",
      "50/50 [==============================] - 20s 391ms/step - loss: 11.6862 - rmse: 23.3371 - val_loss: 6.9684 - val_rmse: 10.1612\n",
      "Epoch 17/25\n",
      "50/50 [==============================] - 20s 408ms/step - loss: 11.3164 - rmse: 22.9733 - val_loss: 8.5321 - val_rmse: 11.9894\n",
      "Epoch 18/25\n",
      "50/50 [==============================] - 20s 393ms/step - loss: 10.1483 - rmse: 20.4533 - val_loss: 7.2801 - val_rmse: 10.2765\n",
      "Epoch 19/25\n",
      "50/50 [==============================] - 20s 395ms/step - loss: 12.3734 - rmse: 28.9471 - val_loss: 7.3687 - val_rmse: 10.3157\n",
      "Epoch 20/25\n",
      "50/50 [==============================] - 20s 394ms/step - loss: 10.8667 - rmse: 24.2972 - val_loss: 6.6039 - val_rmse: 9.2816\n",
      "Epoch 21/25\n",
      "50/50 [==============================] - 20s 395ms/step - loss: 10.1688 - rmse: 21.0273 - val_loss: 7.2464 - val_rmse: 10.1066\n",
      "Epoch 22/25\n",
      "50/50 [==============================] - 20s 396ms/step - loss: 9.7642 - rmse: 20.0304 - val_loss: 7.3313 - val_rmse: 10.0917\n",
      "Epoch 23/25\n",
      "50/50 [==============================] - 20s 397ms/step - loss: 9.3997 - rmse: 19.2431 - val_loss: 6.5817 - val_rmse: 9.3930\n",
      "Epoch 24/25\n",
      "50/50 [==============================] - 20s 395ms/step - loss: 9.0340 - rmse: 18.4277 - val_loss: 6.6505 - val_rmse: 9.2343\n",
      "Epoch 25/25\n",
      "50/50 [==============================] - 20s 392ms/step - loss: 8.8785 - rmse: 17.9302 - val_loss: 6.4038 - val_rmse: 9.0140\n",
      "(0.6000000000000001, 0.8)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a2d0703e70b43c58f48960ea5ab914c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 50 steps, validate for 50 steps\n",
      "Epoch 1/25\n",
      "50/50 [==============================] - 22s 435ms/step - loss: 102.8393 - rmse: 135.9978 - val_loss: 25.0203 - val_rmse: 31.8357\n",
      "Epoch 2/25\n",
      "50/50 [==============================] - 15s 304ms/step - loss: 19.5598 - rmse: 24.6293 - val_loss: 26.5922 - val_rmse: 34.9624\n",
      "Epoch 3/25\n",
      "50/50 [==============================] - 15s 303ms/step - loss: 18.0679 - rmse: 23.2772 - val_loss: 31.1781 - val_rmse: 39.8506\n",
      "Epoch 4/25\n",
      "50/50 [==============================] - 15s 304ms/step - loss: 16.5830 - rmse: 21.5180 - val_loss: 24.3348 - val_rmse: 32.1353\n",
      "Epoch 5/25\n",
      "50/50 [==============================] - 15s 305ms/step - loss: 13.6556 - rmse: 18.0701 - val_loss: 10.5253 - val_rmse: 14.8080\n",
      "Epoch 6/25\n",
      "50/50 [==============================] - 15s 305ms/step - loss: 11.5053 - rmse: 15.5169 - val_loss: 13.5663 - val_rmse: 19.3995\n",
      "Epoch 7/25\n",
      "50/50 [==============================] - 15s 302ms/step - loss: 10.0413 - rmse: 13.7175 - val_loss: 12.1791 - val_rmse: 17.0350\n",
      "Epoch 8/25\n",
      "50/50 [==============================] - 15s 308ms/step - loss: 9.3106 - rmse: 12.8604 - val_loss: 11.5871 - val_rmse: 16.8115\n",
      "Epoch 9/25\n",
      "50/50 [==============================] - 15s 301ms/step - loss: 8.5275 - rmse: 11.8079 - val_loss: 16.2190 - val_rmse: 22.6975\n",
      "Epoch 10/25\n",
      "50/50 [==============================] - 15s 305ms/step - loss: 8.2042 - rmse: 11.4503 - val_loss: 9.4007 - val_rmse: 13.3398\n",
      "Epoch 11/25\n",
      "50/50 [==============================] - 15s 299ms/step - loss: 7.6140 - rmse: 10.6561 - val_loss: 9.4289 - val_rmse: 13.7357\n",
      "Epoch 12/25\n",
      "50/50 [==============================] - 15s 306ms/step - loss: 7.4164 - rmse: 10.3908 - val_loss: 9.6614 - val_rmse: 14.2265\n",
      "Epoch 13/25\n",
      "50/50 [==============================] - 15s 302ms/step - loss: 7.1603 - rmse: 10.0927 - val_loss: 11.1690 - val_rmse: 16.2766\n",
      "Epoch 14/25\n",
      "50/50 [==============================] - 15s 308ms/step - loss: 6.9235 - rmse: 9.7384 - val_loss: 7.5649 - val_rmse: 10.9963\n",
      "Epoch 15/25\n",
      "50/50 [==============================] - 15s 301ms/step - loss: 6.6938 - rmse: 9.4658 - val_loss: 10.5110 - val_rmse: 15.4924\n",
      "Epoch 16/25\n",
      "50/50 [==============================] - 15s 302ms/step - loss: 6.5481 - rmse: 9.2851 - val_loss: 10.8603 - val_rmse: 15.7242\n",
      "Epoch 17/25\n",
      "50/50 [==============================] - 15s 303ms/step - loss: 6.3414 - rmse: 9.0572 - val_loss: 7.5373 - val_rmse: 11.1844\n",
      "Epoch 18/25\n",
      "50/50 [==============================] - 15s 302ms/step - loss: 6.2908 - rmse: 8.9502 - val_loss: 7.9084 - val_rmse: 11.8684\n",
      "Epoch 19/25\n",
      "50/50 [==============================] - 15s 303ms/step - loss: 6.0428 - rmse: 8.6704 - val_loss: 7.2702 - val_rmse: 10.4711\n",
      "Epoch 20/25\n",
      "50/50 [==============================] - 15s 302ms/step - loss: 5.9940 - rmse: 8.5949 - val_loss: 10.2774 - val_rmse: 15.0726\n",
      "Epoch 21/25\n",
      "50/50 [==============================] - 15s 302ms/step - loss: 5.8394 - rmse: 8.4142 - val_loss: 7.1024 - val_rmse: 10.6608\n",
      "Epoch 22/25\n",
      "50/50 [==============================] - 15s 302ms/step - loss: 5.6817 - rmse: 8.1640 - val_loss: 8.7891 - val_rmse: 13.2615\n",
      "Epoch 23/25\n",
      "50/50 [==============================] - 15s 299ms/step - loss: 5.4961 - rmse: 7.9543 - val_loss: 7.0681 - val_rmse: 10.4687\n",
      "Epoch 24/25\n",
      "50/50 [==============================] - 15s 301ms/step - loss: 5.3875 - rmse: 7.8282 - val_loss: 7.3123 - val_rmse: 10.8893\n",
      "Epoch 25/25\n",
      "50/50 [==============================] - 15s 298ms/step - loss: 5.2139 - rmse: 7.5834 - val_loss: 8.3274 - val_rmse: 12.2123\n",
      "(0.2, 0.4)\n",
      "Train for 50 steps, validate for 50 steps\n",
      "Epoch 1/25\n",
      "50/50 [==============================] - 28s 567ms/step - loss: 755.7252 - rmse: 1034.2134 - val_loss: 166.8615 - val_rmse: 206.7842\n",
      "Epoch 2/25\n",
      "50/50 [==============================] - 22s 433ms/step - loss: 112.8021 - rmse: 142.1019 - val_loss: 109.2412 - val_rmse: 131.1930\n",
      "Epoch 3/25\n",
      "50/50 [==============================] - 22s 433ms/step - loss: 55.0504 - rmse: 70.8413 - val_loss: 70.9717 - val_rmse: 109.6030\n",
      "Epoch 4/25\n",
      "50/50 [==============================] - 22s 439ms/step - loss: 20.8977 - rmse: 27.5537 - val_loss: 77.3224 - val_rmse: 116.0340\n",
      "Epoch 5/25\n",
      "50/50 [==============================] - 22s 435ms/step - loss: 19.7966 - rmse: 26.4967 - val_loss: 79.6539 - val_rmse: 118.4829\n",
      "Epoch 6/25\n",
      "50/50 [==============================] - 22s 438ms/step - loss: 15.5670 - rmse: 20.7990 - val_loss: 74.3321 - val_rmse: 113.0610\n",
      "Epoch 7/25\n",
      "50/50 [==============================] - 22s 436ms/step - loss: 13.0436 - rmse: 17.8014 - val_loss: 66.8278 - val_rmse: 106.4888\n",
      "Epoch 8/25\n",
      "50/50 [==============================] - 22s 431ms/step - loss: 11.1668 - rmse: 15.3793 - val_loss: 72.8396 - val_rmse: 112.8413\n",
      "Epoch 9/25\n",
      "50/50 [==============================] - 22s 435ms/step - loss: 10.0939 - rmse: 14.1180 - val_loss: 65.3034 - val_rmse: 106.4614\n",
      "Epoch 10/25\n",
      "50/50 [==============================] - 24s 473ms/step - loss: 9.1485 - rmse: 12.8958 - val_loss: 64.1445 - val_rmse: 104.8153\n",
      "Epoch 11/25\n",
      "50/50 [==============================] - 22s 441ms/step - loss: 8.7401 - rmse: 12.3186 - val_loss: 66.5437 - val_rmse: 107.0386\n",
      "Epoch 12/25\n",
      "50/50 [==============================] - 22s 437ms/step - loss: 8.1398 - rmse: 11.5522 - val_loss: 67.9608 - val_rmse: 108.9285\n",
      "Epoch 13/25\n",
      "50/50 [==============================] - 22s 435ms/step - loss: 7.8449 - rmse: 11.1455 - val_loss: 68.7340 - val_rmse: 110.3275\n",
      "Epoch 14/25\n",
      "50/50 [==============================] - 22s 435ms/step - loss: 7.4788 - rmse: 10.7083 - val_loss: 68.2821 - val_rmse: 109.7632\n",
      "Epoch 15/25\n",
      "50/50 [==============================] - 22s 437ms/step - loss: 7.3724 - rmse: 10.5414 - val_loss: 64.6444 - val_rmse: 106.5588\n",
      "Epoch 16/25\n",
      "50/50 [==============================] - 22s 442ms/step - loss: 7.1521 - rmse: 10.2375 - val_loss: 67.1208 - val_rmse: 109.1636\n",
      "Epoch 17/25\n",
      "50/50 [==============================] - 22s 434ms/step - loss: 6.8947 - rmse: 9.9095 - val_loss: 65.7604 - val_rmse: 107.8321\n",
      "Epoch 18/25\n",
      "50/50 [==============================] - 22s 439ms/step - loss: 6.7939 - rmse: 9.7689 - val_loss: 65.2785 - val_rmse: 106.4399\n",
      "Epoch 19/25\n",
      "50/50 [==============================] - 22s 433ms/step - loss: 6.6557 - rmse: 9.5934 - val_loss: 65.6564 - val_rmse: 107.9072\n",
      "Epoch 20/25\n",
      "50/50 [==============================] - 22s 440ms/step - loss: 6.5426 - rmse: 9.4179 - val_loss: 65.6165 - val_rmse: 107.8252\n",
      "Epoch 21/25\n",
      "50/50 [==============================] - 22s 439ms/step - loss: 6.4709 - rmse: 9.3719 - val_loss: 64.4597 - val_rmse: 106.4287\n",
      "Epoch 22/25\n",
      "50/50 [==============================] - 22s 436ms/step - loss: 6.2808 - rmse: 9.0799 - val_loss: 65.2369 - val_rmse: 106.4684\n",
      "Epoch 23/25\n",
      "50/50 [==============================] - 22s 441ms/step - loss: 6.1733 - rmse: 8.9117 - val_loss: 66.0917 - val_rmse: 108.8410\n",
      "Epoch 24/25\n",
      "50/50 [==============================] - 22s 441ms/step - loss: 6.1260 - rmse: 8.8812 - val_loss: 65.3451 - val_rmse: 108.0722\n",
      "Epoch 25/25\n",
      "50/50 [==============================] - 22s 439ms/step - loss: 5.9621 - rmse: 8.6391 - val_loss: 64.8243 - val_rmse: 107.1610\n",
      "(0.4, 0.6000000000000001)\n",
      "Train for 50 steps, validate for 50 steps\n",
      "Epoch 1/25\n",
      "50/50 [==============================] - 37s 749ms/step - loss: 246.7724 - rmse: 341.1706 - val_loss: 35.9618 - val_rmse: 45.3628\n",
      "Epoch 2/25\n",
      "50/50 [==============================] - 29s 585ms/step - loss: 57.2056 - rmse: 83.2584 - val_loss: 37.9802 - val_rmse: 47.4722\n",
      "Epoch 3/25\n",
      "50/50 [==============================] - 29s 584ms/step - loss: 532.2880 - rmse: 756.2156 - val_loss: 82.6358 - val_rmse: 101.7160\n",
      "Epoch 4/25\n",
      "50/50 [==============================] - 29s 584ms/step - loss: 113.0919 - rmse: 143.9625 - val_loss: 55.1712 - val_rmse: 69.6511\n",
      "Epoch 5/25\n",
      "50/50 [==============================] - 30s 592ms/step - loss: 109.6247 - rmse: 153.7245 - val_loss: 40.5607 - val_rmse: 50.9644\n",
      "Epoch 6/25\n",
      "50/50 [==============================] - 29s 588ms/step - loss: 43.6351 - rmse: 70.8761 - val_loss: 22.1753 - val_rmse: 27.7666\n",
      "Epoch 7/25\n",
      "50/50 [==============================] - 30s 592ms/step - loss: 36.6076 - rmse: 64.1237 - val_loss: 31.1674 - val_rmse: 40.1634\n",
      "Epoch 8/25\n",
      "50/50 [==============================] - 30s 592ms/step - loss: 33.3204 - rmse: 62.2121 - val_loss: 18.9504 - val_rmse: 25.5363\n",
      "Epoch 9/25\n",
      "50/50 [==============================] - 30s 593ms/step - loss: 29.1906 - rmse: 60.3277 - val_loss: 17.4578 - val_rmse: 24.3788\n",
      "Epoch 10/25\n",
      "50/50 [==============================] - 29s 589ms/step - loss: 26.9280 - rmse: 58.8158 - val_loss: 10.7581 - val_rmse: 14.6333\n",
      "Epoch 11/25\n",
      "50/50 [==============================] - 30s 596ms/step - loss: 24.8556 - rmse: 54.6832 - val_loss: 10.5711 - val_rmse: 14.5975\n",
      "Epoch 12/25\n",
      "50/50 [==============================] - 30s 594ms/step - loss: 22.1007 - rmse: 48.9718 - val_loss: 7.9561 - val_rmse: 11.1511\n",
      "Epoch 13/25\n",
      "50/50 [==============================] - 30s 599ms/step - loss: 20.9392 - rmse: 44.3204 - val_loss: 8.4878 - val_rmse: 11.5470\n",
      "Epoch 14/25\n",
      "50/50 [==============================] - 30s 596ms/step - loss: 18.9580 - rmse: 39.0480 - val_loss: 8.0163 - val_rmse: 11.1679\n",
      "Epoch 15/25\n",
      "50/50 [==============================] - 30s 597ms/step - loss: 16.3954 - rmse: 33.8304 - val_loss: 9.3495 - val_rmse: 12.7342\n",
      "Epoch 16/25\n",
      "50/50 [==============================] - 30s 596ms/step - loss: 15.4428 - rmse: 32.1940 - val_loss: 8.6619 - val_rmse: 12.1271\n",
      "Epoch 17/25\n",
      "50/50 [==============================] - 30s 597ms/step - loss: 13.2853 - rmse: 26.8330 - val_loss: 10.1496 - val_rmse: 14.3573\n",
      "Epoch 18/25\n",
      "50/50 [==============================] - 30s 601ms/step - loss: 12.7309 - rmse: 25.6576 - val_loss: 8.2505 - val_rmse: 11.4819\n",
      "Epoch 19/25\n",
      "50/50 [==============================] - 30s 601ms/step - loss: 12.9653 - rmse: 25.9744 - val_loss: 8.5299 - val_rmse: 11.9966\n",
      "Epoch 20/25\n",
      "50/50 [==============================] - 30s 598ms/step - loss: 10.4282 - rmse: 20.6668 - val_loss: 9.4371 - val_rmse: 13.0239\n",
      "Epoch 21/25\n",
      "50/50 [==============================] - 30s 609ms/step - loss: 11.8963 - rmse: 23.5498 - val_loss: 6.7694 - val_rmse: 9.5607\n",
      "Epoch 22/25\n",
      "50/50 [==============================] - 30s 599ms/step - loss: 9.9246 - rmse: 19.7513 - val_loss: 9.1953 - val_rmse: 12.5416\n",
      "Epoch 23/25\n",
      "50/50 [==============================] - 31s 615ms/step - loss: 9.9015 - rmse: 19.8898 - val_loss: 6.0135 - val_rmse: 8.4621\n",
      "Epoch 24/25\n",
      "50/50 [==============================] - 30s 604ms/step - loss: 9.9670 - rmse: 20.4469 - val_loss: 7.6527 - val_rmse: 10.7020\n",
      "Epoch 25/25\n",
      "50/50 [==============================] - 31s 628ms/step - loss: 9.4880 - rmse: 19.2383 - val_loss: 8.0087 - val_rmse: 11.2602\n",
      "(0.6000000000000001, 0.8)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9facca571f84283b5adb64aa9b88930",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 50 steps, validate for 50 steps\n",
      "Epoch 1/25\n",
      "50/50 [==============================] - 17s 333ms/step - loss: 23.4449 - rmse: 29.2037 - val_loss: 25.3215 - val_rmse: 33.6867\n",
      "Epoch 2/25\n",
      "50/50 [==============================] - 9s 185ms/step - loss: 17.9408 - rmse: 22.8572 - val_loss: 19.2490 - val_rmse: 26.5963\n",
      "Epoch 3/25\n",
      "50/50 [==============================] - 9s 186ms/step - loss: 13.8187 - rmse: 18.3209 - val_loss: 15.6005 - val_rmse: 22.8217\n",
      "Epoch 4/25\n",
      "50/50 [==============================] - 9s 187ms/step - loss: 11.4675 - rmse: 15.5538 - val_loss: 19.0582 - val_rmse: 26.8704\n",
      "Epoch 5/25\n",
      "50/50 [==============================] - 10s 190ms/step - loss: 10.2320 - rmse: 13.9915 - val_loss: 11.8008 - val_rmse: 16.8824\n",
      "Epoch 6/25\n",
      "50/50 [==============================] - 9s 187ms/step - loss: 9.2417 - rmse: 12.7345 - val_loss: 20.3423 - val_rmse: 28.0441\n",
      "Epoch 7/25\n",
      "50/50 [==============================] - 9s 185ms/step - loss: 8.6852 - rmse: 12.0060 - val_loss: 21.1703 - val_rmse: 28.4912\n",
      "Epoch 8/25\n",
      "50/50 [==============================] - 9s 187ms/step - loss: 8.0659 - rmse: 11.1586 - val_loss: 21.9773 - val_rmse: 29.3717\n",
      "Epoch 9/25\n",
      "50/50 [==============================] - 9s 184ms/step - loss: 7.6175 - rmse: 10.6169 - val_loss: 19.4719 - val_rmse: 26.7199\n",
      "Epoch 10/25\n",
      "50/50 [==============================] - 9s 188ms/step - loss: 7.3797 - rmse: 10.2709 - val_loss: 17.8978 - val_rmse: 24.9155\n",
      "Epoch 11/25\n",
      "50/50 [==============================] - 9s 187ms/step - loss: 7.0466 - rmse: 9.8619 - val_loss: 18.4198 - val_rmse: 25.4399\n",
      "Epoch 12/25\n",
      "50/50 [==============================] - 9s 189ms/step - loss: 6.9141 - rmse: 9.6740 - val_loss: 18.1498 - val_rmse: 25.1464\n",
      "Epoch 13/25\n",
      "50/50 [==============================] - 10s 190ms/step - loss: 6.7514 - rmse: 9.4454 - val_loss: 14.2378 - val_rmse: 20.5626\n",
      "Epoch 14/25\n",
      "50/50 [==============================] - 9s 184ms/step - loss: 6.5894 - rmse: 9.2760 - val_loss: 17.0986 - val_rmse: 23.9844\n",
      "Epoch 15/25\n",
      "50/50 [==============================] - 9s 186ms/step - loss: 6.4446 - rmse: 9.0832 - val_loss: 15.8621 - val_rmse: 22.6241\n",
      "Epoch 16/25\n",
      "50/50 [==============================] - 9s 185ms/step - loss: 6.2905 - rmse: 8.8905 - val_loss: 12.5420 - val_rmse: 18.3583\n",
      "Epoch 17/25\n",
      "50/50 [==============================] - 9s 184ms/step - loss: 6.2599 - rmse: 8.8500 - val_loss: 15.6840 - val_rmse: 22.1686\n",
      "Epoch 18/25\n",
      "50/50 [==============================] - 9s 189ms/step - loss: 6.1235 - rmse: 8.6747 - val_loss: 14.2052 - val_rmse: 20.8292\n",
      "Epoch 19/25\n",
      "50/50 [==============================] - 9s 183ms/step - loss: 5.9810 - rmse: 8.4979 - val_loss: 13.3249 - val_rmse: 19.4326\n",
      "Epoch 20/25\n",
      "50/50 [==============================] - 9s 187ms/step - loss: 5.8372 - rmse: 8.3281 - val_loss: 15.1477 - val_rmse: 21.8364\n",
      "Epoch 21/25\n",
      "50/50 [==============================] - 9s 184ms/step - loss: 5.7361 - rmse: 8.2322 - val_loss: 17.3657 - val_rmse: 24.5878\n",
      "Epoch 22/25\n",
      "50/50 [==============================] - 9s 187ms/step - loss: 5.6558 - rmse: 8.1270 - val_loss: 13.7015 - val_rmse: 20.0206\n",
      "Epoch 23/25\n",
      "50/50 [==============================] - 9s 189ms/step - loss: 5.5163 - rmse: 7.9362 - val_loss: 14.4425 - val_rmse: 20.7512\n",
      "Epoch 24/25\n",
      "50/50 [==============================] - 9s 185ms/step - loss: 5.2893 - rmse: 7.6722 - val_loss: 13.5870 - val_rmse: 19.9629\n",
      "Epoch 25/25\n",
      "50/50 [==============================] - 9s 189ms/step - loss: 5.2457 - rmse: 7.5790 - val_loss: 17.3628 - val_rmse: 24.3514\n",
      "(0.2, 0.4)\n",
      "Train for 50 steps, validate for 50 steps\n",
      "Epoch 1/25\n",
      "50/50 [==============================] - 26s 518ms/step - loss: 37.2232 - rmse: 49.4413 - val_loss: 75.1327 - val_rmse: 114.1367\n",
      "Epoch 2/25\n",
      "50/50 [==============================] - 19s 376ms/step - loss: 21.8028 - rmse: 28.0648 - val_loss: 70.2271 - val_rmse: 110.3123\n",
      "Epoch 3/25\n",
      "50/50 [==============================] - 19s 375ms/step - loss: 21.2221 - rmse: 28.1112 - val_loss: 67.9669 - val_rmse: 108.5422\n",
      "Epoch 4/25\n",
      "50/50 [==============================] - 19s 372ms/step - loss: 16.4009 - rmse: 22.0587 - val_loss: 72.4910 - val_rmse: 112.7544\n",
      "Epoch 5/25\n",
      "50/50 [==============================] - 19s 375ms/step - loss: 12.6653 - rmse: 17.3531 - val_loss: 69.7166 - val_rmse: 109.4629\n",
      "Epoch 6/25\n",
      "50/50 [==============================] - 19s 373ms/step - loss: 10.6801 - rmse: 14.7713 - val_loss: 71.2662 - val_rmse: 111.4224\n",
      "Epoch 7/25\n",
      "50/50 [==============================] - 19s 373ms/step - loss: 9.4699 - rmse: 13.3051 - val_loss: 71.7015 - val_rmse: 112.4560\n",
      "Epoch 8/25\n",
      "50/50 [==============================] - 19s 372ms/step - loss: 8.7430 - rmse: 12.3572 - val_loss: 68.0923 - val_rmse: 107.5304\n",
      "Epoch 9/25\n",
      "50/50 [==============================] - 19s 373ms/step - loss: 8.2656 - rmse: 11.7384 - val_loss: 66.6277 - val_rmse: 107.3859\n",
      "Epoch 10/25\n",
      "50/50 [==============================] - 18s 369ms/step - loss: 7.9748 - rmse: 11.3764 - val_loss: 67.0469 - val_rmse: 107.3296\n",
      "Epoch 11/25\n",
      "50/50 [==============================] - 19s 374ms/step - loss: 7.6184 - rmse: 10.8443 - val_loss: 65.0183 - val_rmse: 106.9565\n",
      "Epoch 12/25\n",
      "50/50 [==============================] - 19s 373ms/step - loss: 7.4336 - rmse: 10.6250 - val_loss: 68.3949 - val_rmse: 110.1940\n",
      "Epoch 13/25\n",
      "50/50 [==============================] - 19s 372ms/step - loss: 7.2016 - rmse: 10.3390 - val_loss: 67.5352 - val_rmse: 109.0113\n",
      "Epoch 14/25\n",
      "50/50 [==============================] - 19s 373ms/step - loss: 7.1171 - rmse: 10.2068 - val_loss: 65.1770 - val_rmse: 106.5122\n",
      "Epoch 15/25\n",
      "50/50 [==============================] - 19s 370ms/step - loss: 6.8765 - rmse: 9.8933 - val_loss: 66.2473 - val_rmse: 107.3693\n",
      "Epoch 16/25\n",
      "50/50 [==============================] - 19s 371ms/step - loss: 6.7716 - rmse: 9.7396 - val_loss: 65.3446 - val_rmse: 107.0435\n",
      "Epoch 17/25\n",
      "50/50 [==============================] - 19s 373ms/step - loss: 6.6749 - rmse: 9.5750 - val_loss: 67.5892 - val_rmse: 109.6826\n",
      "Epoch 18/25\n",
      "50/50 [==============================] - 19s 375ms/step - loss: 6.4851 - rmse: 9.3362 - val_loss: 65.9864 - val_rmse: 108.2124\n",
      "Epoch 19/25\n",
      "50/50 [==============================] - 19s 372ms/step - loss: 6.4195 - rmse: 9.2403 - val_loss: 68.4272 - val_rmse: 109.8294\n",
      "Epoch 20/25\n",
      "50/50 [==============================] - 19s 374ms/step - loss: 6.3143 - rmse: 9.0912 - val_loss: 65.5091 - val_rmse: 106.8421\n",
      "Epoch 21/25\n",
      "50/50 [==============================] - 19s 372ms/step - loss: 6.1986 - rmse: 8.9397 - val_loss: 67.1507 - val_rmse: 109.1444\n",
      "Epoch 22/25\n",
      "50/50 [==============================] - 19s 374ms/step - loss: 6.0593 - rmse: 8.7543 - val_loss: 66.8416 - val_rmse: 108.9335\n",
      "Epoch 23/25\n",
      "50/50 [==============================] - 19s 370ms/step - loss: 6.0200 - rmse: 8.7102 - val_loss: 64.1190 - val_rmse: 106.4022\n",
      "Epoch 24/25\n",
      "50/50 [==============================] - 19s 370ms/step - loss: 5.8785 - rmse: 8.5091 - val_loss: 64.4431 - val_rmse: 106.2493\n",
      "Epoch 25/25\n",
      "50/50 [==============================] - 19s 379ms/step - loss: 5.7908 - rmse: 8.3670 - val_loss: 66.6776 - val_rmse: 108.8035\n",
      "(0.4, 0.6000000000000001)\n",
      "Train for 50 steps, validate for 50 steps\n",
      "Epoch 1/25\n",
      "50/50 [==============================] - 28s 557ms/step - loss: 43.7319 - rmse: 72.3365 - val_loss: 23.5072 - val_rmse: 30.6434\n",
      "Epoch 2/25\n",
      "50/50 [==============================] - 20s 397ms/step - loss: 37.4889 - rmse: 64.2167 - val_loss: 20.1688 - val_rmse: 26.1176\n",
      "Epoch 3/25\n",
      "50/50 [==============================] - 20s 398ms/step - loss: 33.5138 - rmse: 61.5649 - val_loss: 22.0482 - val_rmse: 28.3113\n",
      "Epoch 4/25\n",
      "50/50 [==============================] - 20s 397ms/step - loss: 32.5736 - rmse: 61.2344 - val_loss: 15.2508 - val_rmse: 20.1111\n",
      "Epoch 5/25\n",
      "50/50 [==============================] - 20s 397ms/step - loss: 30.7520 - rmse: 60.4825 - val_loss: 15.0650 - val_rmse: 19.9808\n",
      "Epoch 6/25\n",
      "50/50 [==============================] - 20s 406ms/step - loss: 30.4368 - rmse: 61.0997 - val_loss: 15.9205 - val_rmse: 20.6590\n",
      "Epoch 7/25\n",
      "50/50 [==============================] - 20s 398ms/step - loss: 29.2953 - rmse: 60.4164 - val_loss: 18.0079 - val_rmse: 24.0423\n",
      "Epoch 8/25\n",
      "50/50 [==============================] - 20s 394ms/step - loss: 28.0140 - rmse: 60.0564 - val_loss: 16.1541 - val_rmse: 21.4661\n",
      "Epoch 9/25\n",
      "50/50 [==============================] - 20s 397ms/step - loss: 26.8632 - rmse: 59.5882 - val_loss: 18.4729 - val_rmse: 24.6409\n",
      "Epoch 10/25\n",
      "50/50 [==============================] - 20s 397ms/step - loss: 26.0633 - rmse: 58.8916 - val_loss: 13.9441 - val_rmse: 18.9476\n",
      "Epoch 11/25\n",
      "50/50 [==============================] - 20s 394ms/step - loss: 25.2963 - rmse: 58.0316 - val_loss: 14.2676 - val_rmse: 19.1157\n",
      "Epoch 12/25\n",
      "50/50 [==============================] - 20s 404ms/step - loss: 24.5238 - rmse: 56.7117 - val_loss: 13.1063 - val_rmse: 17.8234\n",
      "Epoch 13/25\n",
      "50/50 [==============================] - 20s 403ms/step - loss: 24.0979 - rmse: 55.6843 - val_loss: 9.4565 - val_rmse: 13.0190\n",
      "Epoch 14/25\n",
      "50/50 [==============================] - 20s 396ms/step - loss: 23.2262 - rmse: 54.3225 - val_loss: 10.7726 - val_rmse: 14.6584\n",
      "Epoch 15/25\n",
      "50/50 [==============================] - 20s 394ms/step - loss: 21.3925 - rmse: 49.9898 - val_loss: 9.0278 - val_rmse: 12.4234\n",
      "Epoch 16/25\n",
      "50/50 [==============================] - 20s 396ms/step - loss: 18.4640 - rmse: 42.3339 - val_loss: 9.9972 - val_rmse: 13.6440\n",
      "Epoch 17/25\n",
      "50/50 [==============================] - 21s 419ms/step - loss: 17.3093 - rmse: 39.2008 - val_loss: 7.3446 - val_rmse: 10.0261\n",
      "Epoch 18/25\n",
      "50/50 [==============================] - 20s 396ms/step - loss: 15.7949 - rmse: 35.3416 - val_loss: 7.2426 - val_rmse: 10.1206\n",
      "Epoch 19/25\n",
      "50/50 [==============================] - 20s 391ms/step - loss: 15.0490 - rmse: 34.6356 - val_loss: 8.1233 - val_rmse: 11.1150\n",
      "Epoch 20/25\n",
      "50/50 [==============================] - 20s 398ms/step - loss: 15.1697 - rmse: 35.9437 - val_loss: 7.5311 - val_rmse: 10.3582\n",
      "Epoch 21/25\n",
      "50/50 [==============================] - 20s 397ms/step - loss: 14.3695 - rmse: 33.5518 - val_loss: 9.8060 - val_rmse: 13.3383\n",
      "Epoch 22/25\n",
      "50/50 [==============================] - 20s 395ms/step - loss: 13.4385 - rmse: 30.4660 - val_loss: 7.9841 - val_rmse: 10.8981\n",
      "Epoch 23/25\n",
      "50/50 [==============================] - 20s 403ms/step - loss: 12.8028 - rmse: 29.1751 - val_loss: 7.1185 - val_rmse: 9.8037\n",
      "Epoch 24/25\n",
      "50/50 [==============================] - 20s 401ms/step - loss: 11.6351 - rmse: 25.0708 - val_loss: 6.9167 - val_rmse: 9.5759\n",
      "Epoch 25/25\n",
      "50/50 [==============================] - 20s 396ms/step - loss: 11.4877 - rmse: 24.4599 - val_loss: 8.3339 - val_rmse: 11.5198\n",
      "(0.6000000000000001, 0.8)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e1585a2fb4748e5a90e4ebd6a356ee9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 50 steps, validate for 50 steps\n",
      "Epoch 1/25\n",
      "50/50 [==============================] - 20s 397ms/step - loss: 25.0628 - rmse: 32.1952 - val_loss: 28.7390 - val_rmse: 37.2254\n",
      "Epoch 2/25\n",
      "50/50 [==============================] - 12s 241ms/step - loss: 18.9362 - rmse: 24.7381 - val_loss: 22.6778 - val_rmse: 30.1309\n",
      "Epoch 3/25\n",
      "50/50 [==============================] - 12s 245ms/step - loss: 15.9317 - rmse: 20.9526 - val_loss: 25.2385 - val_rmse: 32.5623\n",
      "Epoch 4/25\n",
      "50/50 [==============================] - 12s 244ms/step - loss: 12.1942 - rmse: 16.3930 - val_loss: 21.6644 - val_rmse: 28.5047\n",
      "Epoch 5/25\n",
      "50/50 [==============================] - 12s 243ms/step - loss: 10.6468 - rmse: 14.5183 - val_loss: 18.3337 - val_rmse: 24.9088\n",
      "Epoch 6/25\n",
      "50/50 [==============================] - 12s 242ms/step - loss: 9.7097 - rmse: 13.2656 - val_loss: 21.0927 - val_rmse: 27.9924\n",
      "Epoch 7/25\n",
      "50/50 [==============================] - 12s 246ms/step - loss: 9.0611 - rmse: 12.4557 - val_loss: 14.2043 - val_rmse: 20.2769\n",
      "Epoch 8/25\n",
      "50/50 [==============================] - 12s 243ms/step - loss: 8.3862 - rmse: 11.5743 - val_loss: 17.6806 - val_rmse: 24.1075\n",
      "Epoch 9/25\n",
      "50/50 [==============================] - 12s 248ms/step - loss: 7.9557 - rmse: 11.0129 - val_loss: 20.1436 - val_rmse: 27.1671\n",
      "Epoch 10/25\n",
      "50/50 [==============================] - 12s 239ms/step - loss: 7.6742 - rmse: 10.6361 - val_loss: 18.5157 - val_rmse: 25.3155\n",
      "Epoch 11/25\n",
      "50/50 [==============================] - 12s 245ms/step - loss: 7.4489 - rmse: 10.3879 - val_loss: 13.8208 - val_rmse: 19.7012\n",
      "Epoch 12/25\n",
      "50/50 [==============================] - 12s 247ms/step - loss: 7.2449 - rmse: 10.1117 - val_loss: 16.9454 - val_rmse: 23.9022\n",
      "Epoch 13/25\n",
      "50/50 [==============================] - 12s 243ms/step - loss: 6.8815 - rmse: 9.6338 - val_loss: 19.2298 - val_rmse: 26.3783\n",
      "Epoch 14/25\n",
      "50/50 [==============================] - 12s 242ms/step - loss: 6.9588 - rmse: 9.7630 - val_loss: 14.2064 - val_rmse: 20.4628\n",
      "Epoch 15/25\n",
      "50/50 [==============================] - 12s 243ms/step - loss: 6.6490 - rmse: 9.3159 - val_loss: 10.7819 - val_rmse: 15.7129\n",
      "Epoch 16/25\n",
      "50/50 [==============================] - 12s 245ms/step - loss: 6.6009 - rmse: 9.2710 - val_loss: 11.3091 - val_rmse: 16.4084\n",
      "Epoch 17/25\n",
      "50/50 [==============================] - 12s 246ms/step - loss: 6.3817 - rmse: 9.0045 - val_loss: 10.0788 - val_rmse: 14.6550\n",
      "Epoch 18/25\n",
      "50/50 [==============================] - 12s 244ms/step - loss: 6.3791 - rmse: 9.0172 - val_loss: 12.9492 - val_rmse: 18.6547\n",
      "Epoch 19/25\n",
      "50/50 [==============================] - 12s 246ms/step - loss: 6.0759 - rmse: 8.6462 - val_loss: 9.2718 - val_rmse: 13.5321\n",
      "Epoch 20/25\n",
      "50/50 [==============================] - 12s 244ms/step - loss: 6.0145 - rmse: 8.5628 - val_loss: 13.7449 - val_rmse: 19.4554\n",
      "Epoch 21/25\n",
      "50/50 [==============================] - 12s 245ms/step - loss: 5.8924 - rmse: 8.4156 - val_loss: 10.4855 - val_rmse: 15.3096\n",
      "Epoch 22/25\n",
      "50/50 [==============================] - 12s 247ms/step - loss: 5.8311 - rmse: 8.3128 - val_loss: 9.6632 - val_rmse: 14.1803\n",
      "Epoch 23/25\n",
      "50/50 [==============================] - 12s 240ms/step - loss: 5.6885 - rmse: 8.1601 - val_loss: 9.5065 - val_rmse: 13.9359\n",
      "Epoch 24/25\n",
      "50/50 [==============================] - 12s 243ms/step - loss: 5.5077 - rmse: 7.9123 - val_loss: 13.9276 - val_rmse: 20.0868\n",
      "Epoch 25/25\n",
      "50/50 [==============================] - 12s 241ms/step - loss: 5.4381 - rmse: 7.8363 - val_loss: 14.5395 - val_rmse: 21.0044\n",
      "(0.2, 0.4)\n",
      "Train for 50 steps, validate for 50 steps\n",
      "Epoch 1/25\n",
      "50/50 [==============================] - 29s 573ms/step - loss: 127.4717 - rmse: 166.6048 - val_loss: 77.8987 - val_rmse: 116.0716\n",
      "Epoch 2/25\n",
      "50/50 [==============================] - 21s 416ms/step - loss: 30.3773 - rmse: 38.9028 - val_loss: 72.2501 - val_rmse: 109.6089\n",
      "Epoch 3/25\n",
      "50/50 [==============================] - 21s 418ms/step - loss: 22.2647 - rmse: 27.3968 - val_loss: 67.9451 - val_rmse: 107.0059\n",
      "Epoch 4/25\n",
      "50/50 [==============================] - 21s 423ms/step - loss: 32.3379 - rmse: 41.7333 - val_loss: 82.0041 - val_rmse: 120.1025\n",
      "Epoch 5/25\n",
      "50/50 [==============================] - 21s 419ms/step - loss: 27.1851 - rmse: 33.6786 - val_loss: 73.2821 - val_rmse: 112.1129\n",
      "Epoch 6/25\n",
      "50/50 [==============================] - 21s 425ms/step - loss: 27.0238 - rmse: 33.6735 - val_loss: 441.7507 - val_rmse: 562.5762\n",
      "Epoch 7/25\n",
      "50/50 [==============================] - 21s 421ms/step - loss: 50.3430 - rmse: 67.1169 - val_loss: 68.8576 - val_rmse: 106.1686\n",
      "Epoch 8/25\n",
      "50/50 [==============================] - 21s 422ms/step - loss: 20.5855 - rmse: 26.1694 - val_loss: 69.0629 - val_rmse: 108.6518\n",
      "Epoch 9/25\n",
      "50/50 [==============================] - 22s 433ms/step - loss: 15.4213 - rmse: 20.5398 - val_loss: 68.3910 - val_rmse: 109.3516\n",
      "Epoch 10/25\n",
      "50/50 [==============================] - 21s 430ms/step - loss: 13.0218 - rmse: 17.6628 - val_loss: 70.4970 - val_rmse: 110.6650\n",
      "Epoch 11/25\n",
      "50/50 [==============================] - 21s 421ms/step - loss: 10.6502 - rmse: 14.6703 - val_loss: 69.8556 - val_rmse: 109.9972\n",
      "Epoch 12/25\n",
      "50/50 [==============================] - 21s 419ms/step - loss: 9.8930 - rmse: 13.7063 - val_loss: 66.2985 - val_rmse: 106.4448\n",
      "Epoch 13/25\n",
      "50/50 [==============================] - 21s 424ms/step - loss: 9.2249 - rmse: 12.8046 - val_loss: 69.1252 - val_rmse: 109.7350\n",
      "Epoch 14/25\n",
      "50/50 [==============================] - 21s 419ms/step - loss: 8.6154 - rmse: 12.0401 - val_loss: 68.2110 - val_rmse: 109.3950\n",
      "Epoch 15/25\n",
      "50/50 [==============================] - 21s 426ms/step - loss: 8.2429 - rmse: 11.5517 - val_loss: 70.3250 - val_rmse: 110.7072\n",
      "Epoch 16/25\n",
      "50/50 [==============================] - 21s 422ms/step - loss: 7.8586 - rmse: 11.0729 - val_loss: 63.8402 - val_rmse: 104.7477\n",
      "Epoch 17/25\n",
      "50/50 [==============================] - 21s 419ms/step - loss: 7.7178 - rmse: 10.8959 - val_loss: 67.1306 - val_rmse: 108.9149\n",
      "Epoch 18/25\n",
      "50/50 [==============================] - 21s 418ms/step - loss: 7.4040 - rmse: 10.5045 - val_loss: 64.8914 - val_rmse: 105.7349\n",
      "Epoch 19/25\n",
      "50/50 [==============================] - 21s 418ms/step - loss: 7.2765 - rmse: 10.3389 - val_loss: 67.3276 - val_rmse: 107.4280\n",
      "Epoch 20/25\n",
      "50/50 [==============================] - 21s 419ms/step - loss: 7.0977 - rmse: 10.1192 - val_loss: 64.8941 - val_rmse: 106.0197\n",
      "Epoch 21/25\n",
      "50/50 [==============================] - 21s 419ms/step - loss: 6.9875 - rmse: 9.9909 - val_loss: 67.7722 - val_rmse: 108.5278\n",
      "Epoch 22/25\n",
      "50/50 [==============================] - 21s 416ms/step - loss: 6.8131 - rmse: 9.7812 - val_loss: 68.3735 - val_rmse: 109.1346\n",
      "Epoch 23/25\n",
      "50/50 [==============================] - 21s 422ms/step - loss: 6.8264 - rmse: 9.8068 - val_loss: 65.9344 - val_rmse: 106.3340\n",
      "Epoch 24/25\n",
      "50/50 [==============================] - 21s 422ms/step - loss: 6.6229 - rmse: 9.5462 - val_loss: 67.9854 - val_rmse: 108.3973\n",
      "Epoch 25/25\n",
      "50/50 [==============================] - 21s 422ms/step - loss: 6.5145 - rmse: 9.4057 - val_loss: 64.1642 - val_rmse: 105.3622\n",
      "(0.4, 0.6000000000000001)\n",
      "Train for 50 steps, validate for 50 steps\n",
      "Epoch 1/25\n",
      "50/50 [==============================] - 45s 900ms/step - loss: 53.0808 - rmse: 83.4711 - val_loss: 23.0411 - val_rmse: 30.1042\n",
      "Epoch 2/25\n",
      "50/50 [==============================] - 34s 680ms/step - loss: 34.8125 - rmse: 62.5872 - val_loss: 19.1834 - val_rmse: 25.6875\n",
      "Epoch 3/25\n",
      "50/50 [==============================] - 32s 645ms/step - loss: 32.7073 - rmse: 61.7592 - val_loss: 24.3912 - val_rmse: 32.0507\n",
      "Epoch 4/25\n",
      "50/50 [==============================] - 32s 645ms/step - loss: 30.3568 - rmse: 60.9750 - val_loss: 14.2001 - val_rmse: 20.3176\n",
      "Epoch 5/25\n",
      "50/50 [==============================] - 33s 651ms/step - loss: 28.8216 - rmse: 60.1059 - val_loss: 20.8596 - val_rmse: 27.7502\n",
      "Epoch 6/25\n",
      "50/50 [==============================] - 33s 651ms/step - loss: 27.3553 - rmse: 59.3078 - val_loss: 19.5559 - val_rmse: 26.6528\n",
      "Epoch 7/25\n",
      "50/50 [==============================] - 32s 648ms/step - loss: 25.9607 - rmse: 58.3360 - val_loss: 11.6004 - val_rmse: 16.0102\n",
      "Epoch 8/25\n",
      "50/50 [==============================] - 32s 650ms/step - loss: 24.7796 - rmse: 56.0306 - val_loss: 13.7386 - val_rmse: 19.4304\n",
      "Epoch 9/25\n",
      "50/50 [==============================] - 33s 651ms/step - loss: 24.5285 - rmse: 54.2770 - val_loss: 13.6012 - val_rmse: 19.2099\n",
      "Epoch 10/25\n",
      "50/50 [==============================] - 33s 655ms/step - loss: 21.8299 - rmse: 47.6605 - val_loss: 14.2193 - val_rmse: 20.3333\n",
      "Epoch 11/25\n",
      "50/50 [==============================] - 33s 652ms/step - loss: 19.1676 - rmse: 40.8685 - val_loss: 10.9146 - val_rmse: 15.5500\n",
      "Epoch 12/25\n",
      "50/50 [==============================] - 33s 650ms/step - loss: 18.1390 - rmse: 37.9508 - val_loss: 11.8629 - val_rmse: 16.0887\n",
      "Epoch 13/25\n",
      "50/50 [==============================] - 34s 682ms/step - loss: 15.8808 - rmse: 32.6347 - val_loss: 9.9862 - val_rmse: 13.8749\n",
      "Epoch 14/25\n",
      "50/50 [==============================] - 33s 651ms/step - loss: 13.7577 - rmse: 28.4510 - val_loss: 9.2132 - val_rmse: 13.0178\n",
      "Epoch 15/25\n",
      "50/50 [==============================] - 32s 649ms/step - loss: 14.8287 - rmse: 30.2101 - val_loss: 8.6616 - val_rmse: 12.1379\n",
      "Epoch 16/25\n",
      "50/50 [==============================] - 33s 651ms/step - loss: 11.9029 - rmse: 24.0528 - val_loss: 9.5632 - val_rmse: 13.4293\n",
      "Epoch 17/25\n",
      "50/50 [==============================] - 33s 658ms/step - loss: 12.5132 - rmse: 26.2735 - val_loss: 9.6742 - val_rmse: 13.6967\n",
      "Epoch 18/25\n",
      "50/50 [==============================] - 32s 649ms/step - loss: 11.8086 - rmse: 23.9724 - val_loss: 10.7175 - val_rmse: 15.4898\n",
      "Epoch 19/25\n",
      "50/50 [==============================] - 33s 651ms/step - loss: 10.7528 - rmse: 22.2426 - val_loss: 11.7877 - val_rmse: 17.1027\n",
      "Epoch 20/25\n",
      "50/50 [==============================] - 33s 651ms/step - loss: 10.9001 - rmse: 22.3149 - val_loss: 10.5841 - val_rmse: 14.9222\n",
      "Epoch 21/25\n",
      "50/50 [==============================] - 32s 649ms/step - loss: 9.9167 - rmse: 19.7447 - val_loss: 10.9664 - val_rmse: 14.9916\n",
      "Epoch 22/25\n",
      "50/50 [==============================] - 33s 650ms/step - loss: 10.2016 - rmse: 21.1904 - val_loss: 10.6794 - val_rmse: 15.5158\n",
      "Epoch 23/25\n",
      "50/50 [==============================] - 33s 657ms/step - loss: 9.8516 - rmse: 20.2218 - val_loss: 9.4685 - val_rmse: 13.1942\n",
      "Epoch 24/25\n",
      "50/50 [==============================] - 34s 679ms/step - loss: 9.3390 - rmse: 18.8960 - val_loss: 9.9638 - val_rmse: 14.1344\n",
      "Epoch 25/25\n",
      "50/50 [==============================] - 33s 657ms/step - loss: 9.1336 - rmse: 18.6608 - val_loss: 9.4853 - val_rmse: 13.3645\n",
      "(0.6000000000000001, 0.8)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e728b225ddda42058519d62be27f6752",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 50 steps, validate for 50 steps\n",
      "Epoch 1/25\n",
      "50/50 [==============================] - 29s 575ms/step - loss: 208.1158 - rmse: 282.4236 - val_loss: 25.2305 - val_rmse: 32.5140\n",
      "Epoch 2/25\n",
      "50/50 [==============================] - 22s 438ms/step - loss: 34.9282 - rmse: 45.5412 - val_loss: 53.1427 - val_rmse: 68.2689\n",
      "Epoch 3/25\n",
      "50/50 [==============================] - 22s 436ms/step - loss: 23.2862 - rmse: 29.4790 - val_loss: 26.7357 - val_rmse: 34.1582\n",
      "Epoch 4/25\n",
      "50/50 [==============================] - 22s 438ms/step - loss: 24.2747 - rmse: 32.5477 - val_loss: 25.6762 - val_rmse: 32.9703\n",
      "Epoch 5/25\n",
      "50/50 [==============================] - 22s 434ms/step - loss: 24.5439 - rmse: 31.1382 - val_loss: 23.0422 - val_rmse: 28.5075\n",
      "Epoch 6/25\n",
      "50/50 [==============================] - 22s 435ms/step - loss: 19.4567 - rmse: 24.2105 - val_loss: 29.8934 - val_rmse: 38.8844\n",
      "Epoch 7/25\n",
      "50/50 [==============================] - 22s 438ms/step - loss: 14.0337 - rmse: 18.3656 - val_loss: 15.8650 - val_rmse: 22.0794\n",
      "Epoch 8/25\n",
      "50/50 [==============================] - 22s 436ms/step - loss: 11.1646 - rmse: 15.0603 - val_loss: 12.1431 - val_rmse: 18.2006\n",
      "Epoch 9/25\n",
      "50/50 [==============================] - 22s 436ms/step - loss: 9.5682 - rmse: 13.0646 - val_loss: 15.3493 - val_rmse: 21.9939\n",
      "Epoch 10/25\n",
      "50/50 [==============================] - 22s 440ms/step - loss: 8.7023 - rmse: 11.9918 - val_loss: 15.3559 - val_rmse: 22.4925\n",
      "Epoch 11/25\n",
      "50/50 [==============================] - 22s 436ms/step - loss: 8.2039 - rmse: 11.4493 - val_loss: 12.9884 - val_rmse: 19.1496\n",
      "Epoch 12/25\n",
      "50/50 [==============================] - 22s 438ms/step - loss: 7.7111 - rmse: 10.6785 - val_loss: 15.3461 - val_rmse: 22.0647\n",
      "Epoch 13/25\n",
      "50/50 [==============================] - 22s 446ms/step - loss: 7.4146 - rmse: 10.3195 - val_loss: 14.3624 - val_rmse: 20.9769\n",
      "Epoch 14/25\n",
      "50/50 [==============================] - 22s 437ms/step - loss: 7.1330 - rmse: 9.9517 - val_loss: 12.8623 - val_rmse: 18.9491\n",
      "Epoch 15/25\n",
      "50/50 [==============================] - 22s 440ms/step - loss: 6.8623 - rmse: 9.6110 - val_loss: 9.2706 - val_rmse: 13.6813\n",
      "Epoch 16/25\n",
      "50/50 [==============================] - 22s 447ms/step - loss: 6.7279 - rmse: 9.4437 - val_loss: 13.4183 - val_rmse: 19.8376\n",
      "Epoch 17/25\n",
      "50/50 [==============================] - 22s 439ms/step - loss: 6.4229 - rmse: 9.0275 - val_loss: 10.4882 - val_rmse: 15.0522\n",
      "Epoch 18/25\n",
      "50/50 [==============================] - 23s 450ms/step - loss: 6.3721 - rmse: 8.9696 - val_loss: 9.5508 - val_rmse: 14.0441\n",
      "Epoch 19/25\n",
      "50/50 [==============================] - 22s 442ms/step - loss: 6.1255 - rmse: 8.6487 - val_loss: 12.1724 - val_rmse: 17.9822\n",
      "Epoch 20/25\n",
      "50/50 [==============================] - 22s 444ms/step - loss: 5.8721 - rmse: 8.3108 - val_loss: 9.6623 - val_rmse: 14.3047\n",
      "Epoch 21/25\n",
      "50/50 [==============================] - 22s 442ms/step - loss: 5.9057 - rmse: 8.3652 - val_loss: 8.1539 - val_rmse: 12.1088\n",
      "Epoch 22/25\n",
      "50/50 [==============================] - 22s 440ms/step - loss: 5.6205 - rmse: 8.0131 - val_loss: 12.4306 - val_rmse: 18.6975\n",
      "Epoch 23/25\n",
      "50/50 [==============================] - 22s 443ms/step - loss: 5.5114 - rmse: 7.9072 - val_loss: 9.0035 - val_rmse: 13.2140\n",
      "Epoch 24/25\n",
      "50/50 [==============================] - 22s 439ms/step - loss: 5.2657 - rmse: 7.6004 - val_loss: 11.2412 - val_rmse: 16.6637\n",
      "Epoch 25/25\n",
      "50/50 [==============================] - 22s 443ms/step - loss: 5.1713 - rmse: 7.4994 - val_loss: 9.9984 - val_rmse: 14.9420\n",
      "(0.2, 0.4)\n",
      "Train for 50 steps, validate for 50 steps\n",
      "Epoch 1/25\n",
      "50/50 [==============================] - 42s 849ms/step - loss: 41.4486 - rmse: 55.9266 - val_loss: 74.0957 - val_rmse: 113.6035\n",
      "Epoch 2/25\n",
      "50/50 [==============================] - 35s 710ms/step - loss: 23.0046 - rmse: 30.3496 - val_loss: 76.5396 - val_rmse: 115.9098\n",
      "Epoch 3/25\n",
      "50/50 [==============================] - 35s 709ms/step - loss: 19.6460 - rmse: 26.2093 - val_loss: 74.4397 - val_rmse: 112.7315\n",
      "Epoch 4/25\n",
      "50/50 [==============================] - 35s 705ms/step - loss: 22.4035 - rmse: 29.1518 - val_loss: 76.2350 - val_rmse: 115.6178\n",
      "Epoch 5/25\n",
      "50/50 [==============================] - 35s 707ms/step - loss: 15.6465 - rmse: 20.7780 - val_loss: 70.5079 - val_rmse: 110.0962\n",
      "Epoch 6/25\n",
      "50/50 [==============================] - 35s 706ms/step - loss: 11.9154 - rmse: 16.2295 - val_loss: 70.6642 - val_rmse: 110.3709\n",
      "Epoch 7/25\n",
      "50/50 [==============================] - 35s 708ms/step - loss: 10.4447 - rmse: 14.4655 - val_loss: 69.2297 - val_rmse: 108.7991\n",
      "Epoch 8/25\n",
      "50/50 [==============================] - 36s 710ms/step - loss: 9.4683 - rmse: 13.1868 - val_loss: 70.3343 - val_rmse: 111.5143\n",
      "Epoch 9/25\n",
      "50/50 [==============================] - 36s 712ms/step - loss: 8.7759 - rmse: 12.2866 - val_loss: 70.7115 - val_rmse: 111.7065\n",
      "Epoch 10/25\n",
      "50/50 [==============================] - 35s 709ms/step - loss: 8.3228 - rmse: 11.7091 - val_loss: 68.8163 - val_rmse: 110.8449\n",
      "Epoch 11/25\n",
      "50/50 [==============================] - 35s 705ms/step - loss: 8.0387 - rmse: 11.3703 - val_loss: 66.4622 - val_rmse: 107.7861\n",
      "Epoch 12/25\n",
      "50/50 [==============================] - 36s 710ms/step - loss: 7.5635 - rmse: 10.7239 - val_loss: 66.6246 - val_rmse: 107.5819\n",
      "Epoch 13/25\n",
      "50/50 [==============================] - 36s 721ms/step - loss: 7.3681 - rmse: 10.4603 - val_loss: 68.5660 - val_rmse: 110.3755\n",
      "Epoch 14/25\n",
      "50/50 [==============================] - 36s 712ms/step - loss: 7.0994 - rmse: 10.1027 - val_loss: 71.1044 - val_rmse: 112.3901\n",
      "Epoch 15/25\n",
      "50/50 [==============================] - 36s 719ms/step - loss: 6.9883 - rmse: 9.9270 - val_loss: 68.2835 - val_rmse: 109.9950\n",
      "Epoch 16/25\n",
      "50/50 [==============================] - 43s 862ms/step - loss: 6.7227 - rmse: 9.5960 - val_loss: 66.3303 - val_rmse: 109.6834\n",
      "Epoch 17/25\n",
      "50/50 [==============================] - 45s 903ms/step - loss: 6.5955 - rmse: 9.3985 - val_loss: 66.3533 - val_rmse: 109.3812\n",
      "Epoch 18/25\n",
      "50/50 [==============================] - 44s 870ms/step - loss: 6.4605 - rmse: 9.2203 - val_loss: 65.1210 - val_rmse: 107.6736\n",
      "Epoch 19/25\n",
      "50/50 [==============================] - 44s 889ms/step - loss: 6.2265 - rmse: 8.9391 - val_loss: 65.0923 - val_rmse: 107.7959\n",
      "Epoch 20/25\n",
      "50/50 [==============================] - 39s 774ms/step - loss: 6.1452 - rmse: 8.7766 - val_loss: 66.8214 - val_rmse: 110.1787\n",
      "Epoch 21/25\n",
      "50/50 [==============================] - 41s 812ms/step - loss: 6.0429 - rmse: 8.6819 - val_loss: 66.7558 - val_rmse: 110.0218\n",
      "Epoch 22/25\n",
      "50/50 [==============================] - 42s 842ms/step - loss: 5.8965 - rmse: 8.4884 - val_loss: 64.6493 - val_rmse: 106.9614\n",
      "Epoch 23/25\n",
      "50/50 [==============================] - 50s 990ms/step - loss: 5.8426 - rmse: 8.4115 - val_loss: 66.1168 - val_rmse: 109.5723\n",
      "Epoch 24/25\n",
      "50/50 [==============================] - 46s 927ms/step - loss: 5.7262 - rmse: 8.2518 - val_loss: 65.7270 - val_rmse: 109.3667\n",
      "Epoch 25/25\n",
      "50/50 [==============================] - 50s 996ms/step - loss: 5.5878 - rmse: 8.0849 - val_loss: 66.2634 - val_rmse: 109.5889\n",
      "(0.4, 0.6000000000000001)\n",
      "Train for 50 steps, validate for 50 steps\n",
      "Epoch 1/25\n",
      "50/50 [==============================] - 66s 1s/step - loss: 379.0572 - rmse: 499.2053 - val_loss: 34.8326 - val_rmse: 43.1424\n",
      "Epoch 2/25\n",
      "50/50 [==============================] - 59s 1s/step - loss: 62.2221 - rmse: 87.5020 - val_loss: 25.6033 - val_rmse: 32.6060\n",
      "Epoch 3/25\n",
      "50/50 [==============================] - 57s 1s/step - loss: 44.3432 - rmse: 71.2784 - val_loss: 26.4497 - val_rmse: 34.5970\n",
      "Epoch 4/25\n",
      "50/50 [==============================] - 64s 1s/step - loss: 35.7267 - rmse: 64.5439 - val_loss: 21.2752 - val_rmse: 28.5621\n",
      "Epoch 5/25\n",
      "50/50 [==============================] - 63s 1s/step - loss: 36.9151 - rmse: 65.3546 - val_loss: 17.1404 - val_rmse: 22.5251\n",
      "Epoch 6/25\n",
      "50/50 [==============================] - 59s 1s/step - loss: 33.1619 - rmse: 62.4275 - val_loss: 30.7133 - val_rmse: 39.3280\n",
      "Epoch 7/25\n",
      "50/50 [==============================] - 65s 1s/step - loss: 30.1343 - rmse: 60.8040 - val_loss: 13.6471 - val_rmse: 18.5544\n",
      "Epoch 8/25\n",
      "50/50 [==============================] - 58s 1s/step - loss: 27.0523 - rmse: 58.7663 - val_loss: 13.7052 - val_rmse: 19.0824\n",
      "Epoch 9/25\n",
      "50/50 [==============================] - 58s 1s/step - loss: 25.8943 - rmse: 57.9461 - val_loss: 7.9901 - val_rmse: 11.3790\n",
      "Epoch 10/25\n",
      "50/50 [==============================] - 60s 1s/step - loss: 24.9856 - rmse: 56.3910 - val_loss: 9.7720 - val_rmse: 13.7946\n",
      "Epoch 11/25\n",
      "50/50 [==============================] - 54s 1s/step - loss: 24.3935 - rmse: 53.6106 - val_loss: 8.4721 - val_rmse: 11.9561\n",
      "Epoch 12/25\n",
      "50/50 [==============================] - 51s 1s/step - loss: 19.9161 - rmse: 42.4766 - val_loss: 7.8656 - val_rmse: 11.2331\n",
      "Epoch 13/25\n",
      "50/50 [==============================] - 50s 1s/step - loss: 17.7958 - rmse: 36.8032 - val_loss: 11.6603 - val_rmse: 16.7625\n",
      "Epoch 14/25\n",
      "50/50 [==============================] - 50s 996ms/step - loss: 15.0166 - rmse: 30.5391 - val_loss: 8.7058 - val_rmse: 11.7553\n",
      "Epoch 15/25\n",
      "50/50 [==============================] - 46s 923ms/step - loss: 13.8574 - rmse: 27.9136 - val_loss: 7.8964 - val_rmse: 10.9728\n",
      "Epoch 16/25\n",
      "50/50 [==============================] - 47s 935ms/step - loss: 12.9354 - rmse: 25.6821 - val_loss: 7.8537 - val_rmse: 10.8717\n",
      "Epoch 17/25\n",
      "50/50 [==============================] - 47s 937ms/step - loss: 16.2508 - rmse: 33.7881 - val_loss: 9.0544 - val_rmse: 12.7672\n",
      "Epoch 18/25\n",
      "50/50 [==============================] - 47s 935ms/step - loss: 11.6938 - rmse: 23.2303 - val_loss: 8.3825 - val_rmse: 11.6524\n",
      "Epoch 19/25\n",
      "50/50 [==============================] - 46s 928ms/step - loss: 11.0758 - rmse: 21.8797 - val_loss: 7.2024 - val_rmse: 10.0030\n",
      "Epoch 20/25\n",
      "50/50 [==============================] - 47s 933ms/step - loss: 10.5372 - rmse: 21.5750 - val_loss: 6.3582 - val_rmse: 9.1291\n",
      "Epoch 21/25\n",
      "50/50 [==============================] - 46s 920ms/step - loss: 10.0324 - rmse: 20.1067 - val_loss: 8.4740 - val_rmse: 11.9448\n",
      "Epoch 22/25\n",
      "50/50 [==============================] - 47s 935ms/step - loss: 9.5305 - rmse: 18.6196 - val_loss: 8.0164 - val_rmse: 11.0552\n",
      "Epoch 23/25\n",
      "50/50 [==============================] - 46s 929ms/step - loss: 9.4615 - rmse: 19.5524 - val_loss: 7.2801 - val_rmse: 10.1734\n",
      "Epoch 24/25\n",
      "50/50 [==============================] - 47s 941ms/step - loss: 9.0950 - rmse: 18.1232 - val_loss: 7.2617 - val_rmse: 10.2965\n",
      "Epoch 25/25\n",
      "50/50 [==============================] - 47s 941ms/step - loss: 8.6469 - rmse: 17.7350 - val_loss: 7.7046 - val_rmse: 10.6970\n",
      "(0.6000000000000001, 0.8)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0eeafa176ca45ec88487655a813b32d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 50 steps, validate for 50 steps\n",
      "Epoch 1/25\n",
      "50/50 [==============================] - 20s 400ms/step - loss: 25.1893 - rmse: 32.0602 - val_loss: 33.9657 - val_rmse: 42.9114\n",
      "Epoch 2/25\n",
      "50/50 [==============================] - 11s 224ms/step - loss: 18.5169 - rmse: 23.8289 - val_loss: 23.3715 - val_rmse: 31.2964\n",
      "Epoch 3/25\n",
      "50/50 [==============================] - 11s 224ms/step - loss: 15.1113 - rmse: 19.8214 - val_loss: 26.7939 - val_rmse: 34.6556\n",
      "Epoch 4/25\n",
      "50/50 [==============================] - 11s 222ms/step - loss: 12.6782 - rmse: 17.0613 - val_loss: 26.0720 - val_rmse: 33.9613\n",
      "Epoch 5/25\n",
      "50/50 [==============================] - 11s 223ms/step - loss: 11.5888 - rmse: 15.9431 - val_loss: 24.8203 - val_rmse: 32.2461\n",
      "Epoch 6/25\n",
      "50/50 [==============================] - 11s 223ms/step - loss: 10.7162 - rmse: 14.7548 - val_loss: 15.8986 - val_rmse: 22.5175\n",
      "Epoch 7/25\n",
      "50/50 [==============================] - 11s 227ms/step - loss: 9.6555 - rmse: 13.2691 - val_loss: 15.5902 - val_rmse: 22.1022\n",
      "Epoch 8/25\n",
      "50/50 [==============================] - 11s 223ms/step - loss: 8.9730 - rmse: 12.3631 - val_loss: 21.4310 - val_rmse: 28.7786\n",
      "Epoch 9/25\n",
      "50/50 [==============================] - 11s 223ms/step - loss: 8.4223 - rmse: 11.6773 - val_loss: 16.8235 - val_rmse: 23.3939\n",
      "Epoch 10/25\n",
      "50/50 [==============================] - 11s 223ms/step - loss: 8.1205 - rmse: 11.2839 - val_loss: 14.1577 - val_rmse: 20.1972\n",
      "Epoch 11/25\n",
      "50/50 [==============================] - 11s 222ms/step - loss: 7.7815 - rmse: 10.8658 - val_loss: 16.4033 - val_rmse: 23.0961\n",
      "Epoch 12/25\n",
      "50/50 [==============================] - 11s 222ms/step - loss: 7.5234 - rmse: 10.4841 - val_loss: 20.9451 - val_rmse: 28.5630\n",
      "Epoch 13/25\n",
      "50/50 [==============================] - 11s 223ms/step - loss: 7.3506 - rmse: 10.3347 - val_loss: 19.6464 - val_rmse: 27.1980\n",
      "Epoch 14/25\n",
      "50/50 [==============================] - 11s 221ms/step - loss: 7.1795 - rmse: 10.0994 - val_loss: 18.3667 - val_rmse: 25.5663\n",
      "Epoch 15/25\n",
      "50/50 [==============================] - 11s 223ms/step - loss: 7.1801 - rmse: 10.1564 - val_loss: 22.2115 - val_rmse: 29.9293\n",
      "Epoch 16/25\n",
      "50/50 [==============================] - 11s 223ms/step - loss: 6.8304 - rmse: 9.6323 - val_loss: 21.5613 - val_rmse: 29.2974\n",
      "Epoch 17/25\n",
      "50/50 [==============================] - 11s 221ms/step - loss: 6.8363 - rmse: 9.6433 - val_loss: 20.9147 - val_rmse: 28.4970\n",
      "Epoch 18/25\n",
      "50/50 [==============================] - 11s 222ms/step - loss: 6.6718 - rmse: 9.4774 - val_loss: 18.7482 - val_rmse: 26.2271\n",
      "Epoch 19/25\n",
      "50/50 [==============================] - 11s 223ms/step - loss: 6.5880 - rmse: 9.3688 - val_loss: 16.6134 - val_rmse: 23.5235\n",
      "Epoch 20/25\n",
      "50/50 [==============================] - 11s 225ms/step - loss: 6.4424 - rmse: 9.1815 - val_loss: 14.8125 - val_rmse: 21.2257\n",
      "Epoch 21/25\n",
      "50/50 [==============================] - 11s 220ms/step - loss: 6.4607 - rmse: 9.2152 - val_loss: 14.0926 - val_rmse: 20.3730\n",
      "Epoch 22/25\n",
      "50/50 [==============================] - 11s 226ms/step - loss: 6.3681 - rmse: 9.0930 - val_loss: 16.5113 - val_rmse: 23.6782\n",
      "Epoch 23/25\n",
      "50/50 [==============================] - 11s 224ms/step - loss: 6.2235 - rmse: 8.9017 - val_loss: 18.7596 - val_rmse: 26.0753\n",
      "Epoch 24/25\n",
      "50/50 [==============================] - 11s 220ms/step - loss: 6.2135 - rmse: 8.9165 - val_loss: 16.2269 - val_rmse: 23.2550\n",
      "Epoch 25/25\n",
      "50/50 [==============================] - 11s 228ms/step - loss: 6.1132 - rmse: 8.7963 - val_loss: 16.9542 - val_rmse: 24.3890\n",
      "(0.2, 0.4)\n",
      "Train for 50 steps, validate for 50 steps\n",
      "Epoch 1/25\n",
      "50/50 [==============================] - 35s 709ms/step - loss: 33.3797 - rmse: 42.0753 - val_loss: 80.2701 - val_rmse: 119.1737\n",
      "Epoch 2/25\n",
      "50/50 [==============================] - 26s 517ms/step - loss: 22.5463 - rmse: 29.1200 - val_loss: 75.9038 - val_rmse: 115.1490\n",
      "Epoch 3/25\n",
      "50/50 [==============================] - 26s 515ms/step - loss: 16.6269 - rmse: 22.0243 - val_loss: 72.0651 - val_rmse: 111.5213\n",
      "Epoch 4/25\n",
      "50/50 [==============================] - 26s 512ms/step - loss: 13.4545 - rmse: 18.2858 - val_loss: 71.3446 - val_rmse: 110.6216\n",
      "Epoch 5/25\n",
      "50/50 [==============================] - 26s 514ms/step - loss: 11.9279 - rmse: 16.3944 - val_loss: 76.8885 - val_rmse: 115.9032\n",
      "Epoch 6/25\n",
      "50/50 [==============================] - 26s 518ms/step - loss: 10.8414 - rmse: 15.1275 - val_loss: 69.4141 - val_rmse: 108.5679\n",
      "Epoch 7/25\n",
      "50/50 [==============================] - 26s 510ms/step - loss: 9.9732 - rmse: 13.9623 - val_loss: 71.4328 - val_rmse: 110.4748\n",
      "Epoch 8/25\n",
      "50/50 [==============================] - 26s 516ms/step - loss: 9.3029 - rmse: 13.0103 - val_loss: 70.2046 - val_rmse: 109.5845\n",
      "Epoch 9/25\n",
      "50/50 [==============================] - 25s 510ms/step - loss: 8.8885 - rmse: 12.4920 - val_loss: 66.2580 - val_rmse: 104.8906\n",
      "Epoch 10/25\n",
      "50/50 [==============================] - 26s 513ms/step - loss: 8.5514 - rmse: 12.0249 - val_loss: 74.8298 - val_rmse: 114.1006\n",
      "Epoch 11/25\n",
      "50/50 [==============================] - 25s 510ms/step - loss: 8.2184 - rmse: 11.5871 - val_loss: 75.0414 - val_rmse: 114.4272\n",
      "Epoch 12/25\n",
      "50/50 [==============================] - 26s 511ms/step - loss: 7.9886 - rmse: 11.2903 - val_loss: 69.0140 - val_rmse: 108.7152\n",
      "Epoch 13/25\n",
      "50/50 [==============================] - 26s 515ms/step - loss: 7.7952 - rmse: 11.0242 - val_loss: 70.9331 - val_rmse: 111.2154\n",
      "Epoch 14/25\n",
      "50/50 [==============================] - 26s 513ms/step - loss: 7.4971 - rmse: 10.6420 - val_loss: 69.5032 - val_rmse: 109.7635\n",
      "Epoch 15/25\n",
      "50/50 [==============================] - 27s 534ms/step - loss: 7.5120 - rmse: 10.6696 - val_loss: 68.6568 - val_rmse: 110.5088\n",
      "Epoch 16/25\n",
      "50/50 [==============================] - 26s 513ms/step - loss: 7.2213 - rmse: 10.2887 - val_loss: 68.6952 - val_rmse: 110.0540\n",
      "Epoch 17/25\n",
      "50/50 [==============================] - 26s 513ms/step - loss: 7.0994 - rmse: 10.1292 - val_loss: 68.8292 - val_rmse: 111.5978\n",
      "Epoch 18/25\n",
      "50/50 [==============================] - 26s 515ms/step - loss: 7.0116 - rmse: 9.9843 - val_loss: 71.6548 - val_rmse: 112.9644\n",
      "Epoch 19/25\n",
      "50/50 [==============================] - 26s 513ms/step - loss: 6.9255 - rmse: 9.9272 - val_loss: 67.8496 - val_rmse: 109.7196\n",
      "Epoch 20/25\n",
      "50/50 [==============================] - 26s 516ms/step - loss: 6.7541 - rmse: 9.6719 - val_loss: 67.7800 - val_rmse: 109.2582\n",
      "Epoch 21/25\n",
      "50/50 [==============================] - 26s 516ms/step - loss: 6.7426 - rmse: 9.6654 - val_loss: 71.8254 - val_rmse: 113.0721\n",
      "Epoch 22/25\n",
      "50/50 [==============================] - 25s 509ms/step - loss: 6.5638 - rmse: 9.4285 - val_loss: 67.6775 - val_rmse: 109.5981\n",
      "Epoch 23/25\n",
      "50/50 [==============================] - 26s 514ms/step - loss: 6.5573 - rmse: 9.3868 - val_loss: 67.4452 - val_rmse: 109.6102\n",
      "Epoch 24/25\n",
      "50/50 [==============================] - 26s 518ms/step - loss: 6.4446 - rmse: 9.2611 - val_loss: 70.6425 - val_rmse: 112.7145\n",
      "Epoch 25/25\n",
      "50/50 [==============================] - 26s 516ms/step - loss: 6.3409 - rmse: 9.1205 - val_loss: 71.9786 - val_rmse: 113.0971\n",
      "(0.4, 0.6000000000000001)\n",
      "Train for 50 steps, validate for 50 steps\n",
      "Epoch 1/25\n",
      "50/50 [==============================] - 41s 813ms/step - loss: 73.5735 - rmse: 108.5433 - val_loss: 29.8198 - val_rmse: 38.7008\n",
      "Epoch 2/25\n",
      "50/50 [==============================] - 32s 635ms/step - loss: 33.5473 - rmse: 61.8538 - val_loss: 27.3729 - val_rmse: 35.5106\n",
      "Epoch 3/25\n",
      "50/50 [==============================] - 32s 635ms/step - loss: 31.4278 - rmse: 61.2045 - val_loss: 27.2925 - val_rmse: 35.1073\n",
      "Epoch 4/25\n",
      "50/50 [==============================] - 32s 632ms/step - loss: 29.4493 - rmse: 60.3237 - val_loss: 25.5172 - val_rmse: 32.6995\n",
      "Epoch 5/25\n",
      "50/50 [==============================] - 32s 637ms/step - loss: 27.9850 - rmse: 59.4636 - val_loss: 14.4895 - val_rmse: 19.7142\n",
      "Epoch 6/25\n",
      "50/50 [==============================] - 32s 631ms/step - loss: 26.8874 - rmse: 58.7567 - val_loss: 21.6254 - val_rmse: 28.7356\n",
      "Epoch 7/25\n",
      "50/50 [==============================] - 32s 634ms/step - loss: 25.9790 - rmse: 58.2214 - val_loss: 16.7922 - val_rmse: 22.8827\n",
      "Epoch 8/25\n",
      "50/50 [==============================] - 32s 634ms/step - loss: 25.3374 - rmse: 57.6138 - val_loss: 13.3030 - val_rmse: 18.3022\n",
      "Epoch 9/25\n",
      "50/50 [==============================] - 32s 632ms/step - loss: 24.9013 - rmse: 56.6440 - val_loss: 12.8859 - val_rmse: 17.7705\n",
      "Epoch 10/25\n",
      "50/50 [==============================] - 32s 634ms/step - loss: 23.9231 - rmse: 54.6984 - val_loss: 13.1051 - val_rmse: 17.9891\n",
      "Epoch 11/25\n",
      "50/50 [==============================] - 31s 628ms/step - loss: 22.5416 - rmse: 50.2872 - val_loss: 10.5394 - val_rmse: 14.9011\n",
      "Epoch 12/25\n",
      "50/50 [==============================] - 31s 622ms/step - loss: 22.2258 - rmse: 48.9484 - val_loss: 10.7580 - val_rmse: 15.0174\n",
      "Epoch 13/25\n",
      "50/50 [==============================] - 32s 631ms/step - loss: 18.2242 - rmse: 38.0063 - val_loss: 11.7165 - val_rmse: 15.9572\n",
      "Epoch 14/25\n",
      "50/50 [==============================] - 31s 625ms/step - loss: 16.3856 - rmse: 33.5652 - val_loss: 10.8692 - val_rmse: 14.8860\n",
      "Epoch 15/25\n",
      "50/50 [==============================] - 31s 626ms/step - loss: 15.4582 - rmse: 31.2936 - val_loss: 8.8657 - val_rmse: 12.4466\n",
      "Epoch 16/25\n",
      "50/50 [==============================] - 31s 626ms/step - loss: 14.3324 - rmse: 29.2551 - val_loss: 9.8428 - val_rmse: 13.7190\n",
      "Epoch 17/25\n",
      "50/50 [==============================] - 32s 632ms/step - loss: 13.4129 - rmse: 26.7560 - val_loss: 8.6697 - val_rmse: 12.2193\n",
      "Epoch 18/25\n",
      "50/50 [==============================] - 32s 631ms/step - loss: 12.5015 - rmse: 24.9734 - val_loss: 9.0435 - val_rmse: 12.7883\n",
      "Epoch 19/25\n",
      "50/50 [==============================] - 31s 623ms/step - loss: 12.4466 - rmse: 25.2773 - val_loss: 7.3326 - val_rmse: 10.4407\n",
      "Epoch 20/25\n",
      "50/50 [==============================] - 32s 630ms/step - loss: 11.6471 - rmse: 22.8910 - val_loss: 7.6515 - val_rmse: 10.6551\n",
      "Epoch 21/25\n",
      "50/50 [==============================] - 31s 626ms/step - loss: 11.1022 - rmse: 21.9203 - val_loss: 8.1262 - val_rmse: 11.5013\n",
      "Epoch 22/25\n",
      "50/50 [==============================] - 31s 623ms/step - loss: 10.6475 - rmse: 20.7934 - val_loss: 7.3330 - val_rmse: 10.2831\n",
      "Epoch 23/25\n",
      "50/50 [==============================] - 39s 770ms/step - loss: 10.1651 - rmse: 19.8781 - val_loss: 6.7292 - val_rmse: 9.6917\n",
      "Epoch 24/25\n",
      "50/50 [==============================] - 43s 867ms/step - loss: 10.2340 - rmse: 20.2367 - val_loss: 8.0947 - val_rmse: 11.2160\n",
      "Epoch 25/25\n",
      "50/50 [==============================] - 32s 638ms/step - loss: 9.8991 - rmse: 19.1848 - val_loss: 7.2850 - val_rmse: 10.2706\n",
      "(0.6000000000000001, 0.8)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8311037ae44e4a40a36b097e653485d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 50 steps, validate for 50 steps\n",
      "Epoch 1/25\n",
      "50/50 [==============================] - 27s 543ms/step - loss: 175.2437 - rmse: 242.2475 - val_loss: 29.5760 - val_rmse: 37.0691\n",
      "Epoch 2/25\n",
      "50/50 [==============================] - 19s 372ms/step - loss: 50.7763 - rmse: 67.1201 - val_loss: 25.5924 - val_rmse: 33.7042\n",
      "Epoch 3/25\n",
      "50/50 [==============================] - 19s 373ms/step - loss: 23.0665 - rmse: 28.8698 - val_loss: 24.7997 - val_rmse: 33.1255\n",
      "Epoch 4/25\n",
      "50/50 [==============================] - 18s 366ms/step - loss: 24.0506 - rmse: 30.8483 - val_loss: 26.6766 - val_rmse: 33.6381\n",
      "Epoch 5/25\n",
      "50/50 [==============================] - 19s 375ms/step - loss: 24.5914 - rmse: 32.0639 - val_loss: 27.3682 - val_rmse: 35.7743\n",
      "Epoch 6/25\n",
      "50/50 [==============================] - 19s 378ms/step - loss: 19.9484 - rmse: 25.9400 - val_loss: 24.1907 - val_rmse: 29.5885\n",
      "Epoch 7/25\n",
      "50/50 [==============================] - 18s 367ms/step - loss: 20.3257 - rmse: 25.5010 - val_loss: 26.2280 - val_rmse: 34.5771\n",
      "Epoch 8/25\n",
      "50/50 [==============================] - 18s 367ms/step - loss: 15.6087 - rmse: 20.1670 - val_loss: 20.0726 - val_rmse: 27.0767\n",
      "Epoch 9/25\n",
      "50/50 [==============================] - 19s 372ms/step - loss: 12.6952 - rmse: 16.8718 - val_loss: 14.8891 - val_rmse: 20.5735\n",
      "Epoch 10/25\n",
      "50/50 [==============================] - 18s 368ms/step - loss: 10.8242 - rmse: 14.6477 - val_loss: 13.6519 - val_rmse: 19.6879\n",
      "Epoch 11/25\n",
      "50/50 [==============================] - 19s 378ms/step - loss: 9.3144 - rmse: 12.6819 - val_loss: 14.5711 - val_rmse: 20.9201\n",
      "Epoch 12/25\n",
      "50/50 [==============================] - 19s 378ms/step - loss: 8.5587 - rmse: 11.7450 - val_loss: 9.8806 - val_rmse: 13.9840\n",
      "Epoch 13/25\n",
      "50/50 [==============================] - 19s 371ms/step - loss: 7.9584 - rmse: 10.9600 - val_loss: 8.6304 - val_rmse: 12.2384\n",
      "Epoch 14/25\n",
      "50/50 [==============================] - 18s 370ms/step - loss: 7.5292 - rmse: 10.3915 - val_loss: 9.5866 - val_rmse: 13.8115\n",
      "Epoch 15/25\n",
      "50/50 [==============================] - 18s 368ms/step - loss: 7.2631 - rmse: 10.0902 - val_loss: 8.3940 - val_rmse: 12.0471\n",
      "Epoch 16/25\n",
      "50/50 [==============================] - 19s 371ms/step - loss: 7.0449 - rmse: 9.8019 - val_loss: 9.6399 - val_rmse: 13.6531\n",
      "Epoch 17/25\n",
      "50/50 [==============================] - 19s 380ms/step - loss: 6.8012 - rmse: 9.4818 - val_loss: 13.0623 - val_rmse: 18.7968\n",
      "Epoch 18/25\n",
      "50/50 [==============================] - 19s 377ms/step - loss: 6.6432 - rmse: 9.3188 - val_loss: 8.9162 - val_rmse: 13.1978\n",
      "Epoch 19/25\n",
      "50/50 [==============================] - 19s 386ms/step - loss: 6.2706 - rmse: 8.8717 - val_loss: 9.8114 - val_rmse: 13.7465\n",
      "Epoch 20/25\n",
      "50/50 [==============================] - 18s 370ms/step - loss: 6.2446 - rmse: 8.8330 - val_loss: 7.9329 - val_rmse: 11.3797\n",
      "Epoch 21/25\n",
      "50/50 [==============================] - 19s 375ms/step - loss: 6.1725 - rmse: 8.9133 - val_loss: 8.7026 - val_rmse: 12.5614\n",
      "Epoch 22/25\n",
      "50/50 [==============================] - 19s 373ms/step - loss: 5.9001 - rmse: 8.4321 - val_loss: 7.4208 - val_rmse: 10.8156\n",
      "Epoch 23/25\n",
      "50/50 [==============================] - 19s 379ms/step - loss: 5.8894 - rmse: 8.4075 - val_loss: 7.6270 - val_rmse: 11.0662\n",
      "Epoch 24/25\n",
      "50/50 [==============================] - 19s 374ms/step - loss: 5.7330 - rmse: 8.2329 - val_loss: 8.6627 - val_rmse: 12.3908\n",
      "Epoch 25/25\n",
      "50/50 [==============================] - 19s 373ms/step - loss: 5.6398 - rmse: 8.1576 - val_loss: 8.6078 - val_rmse: 12.1501\n",
      "(0.2, 0.4)\n",
      "Train for 50 steps, validate for 50 steps\n",
      "Epoch 1/25\n",
      "50/50 [==============================] - 43s 853ms/step - loss: 54.3219 - rmse: 76.0586 - val_loss: 77.4517 - val_rmse: 117.3243\n",
      "Epoch 2/25\n",
      "50/50 [==============================] - 34s 679ms/step - loss: 18.6255 - rmse: 24.5331 - val_loss: 77.7954 - val_rmse: 117.0059\n",
      "Epoch 3/25\n",
      "50/50 [==============================] - 34s 678ms/step - loss: 16.7925 - rmse: 22.2771 - val_loss: 79.8760 - val_rmse: 118.6515\n",
      "Epoch 4/25\n",
      "50/50 [==============================] - 34s 681ms/step - loss: 18.3196 - rmse: 25.4651 - val_loss: 77.1169 - val_rmse: 115.7643\n",
      "Epoch 5/25\n",
      "50/50 [==============================] - 34s 672ms/step - loss: 13.3835 - rmse: 18.1034 - val_loss: 77.9089 - val_rmse: 116.7773\n",
      "Epoch 6/25\n",
      "50/50 [==============================] - 34s 678ms/step - loss: 12.5034 - rmse: 17.1518 - val_loss: 71.8575 - val_rmse: 111.0391\n",
      "Epoch 7/25\n",
      "50/50 [==============================] - 35s 710ms/step - loss: 10.8189 - rmse: 14.9502 - val_loss: 71.2701 - val_rmse: 109.7910\n",
      "Epoch 8/25\n",
      "50/50 [==============================] - 34s 683ms/step - loss: 10.1504 - rmse: 14.1196 - val_loss: 70.9403 - val_rmse: 110.1536\n",
      "Epoch 9/25\n",
      "50/50 [==============================] - 34s 683ms/step - loss: 9.4126 - rmse: 13.2163 - val_loss: 76.8005 - val_rmse: 115.3058\n",
      "Epoch 10/25\n",
      "50/50 [==============================] - 34s 678ms/step - loss: 8.9314 - rmse: 12.5631 - val_loss: 74.0311 - val_rmse: 112.8862\n",
      "Epoch 11/25\n",
      "50/50 [==============================] - 34s 681ms/step - loss: 8.5638 - rmse: 12.1114 - val_loss: 73.0056 - val_rmse: 111.7378\n",
      "Epoch 12/25\n",
      "50/50 [==============================] - 34s 685ms/step - loss: 8.1961 - rmse: 11.5866 - val_loss: 73.6975 - val_rmse: 112.7995\n",
      "Epoch 13/25\n",
      "50/50 [==============================] - 34s 680ms/step - loss: 7.9631 - rmse: 11.3094 - val_loss: 69.7006 - val_rmse: 109.2944\n",
      "Epoch 14/25\n",
      "50/50 [==============================] - 35s 691ms/step - loss: 7.6775 - rmse: 10.9482 - val_loss: 69.4841 - val_rmse: 108.7706\n",
      "Epoch 15/25\n",
      "50/50 [==============================] - 34s 690ms/step - loss: 7.4903 - rmse: 10.6900 - val_loss: 71.8449 - val_rmse: 111.1622\n",
      "Epoch 16/25\n",
      "50/50 [==============================] - 34s 684ms/step - loss: 7.4015 - rmse: 10.5591 - val_loss: 69.5945 - val_rmse: 109.0636\n",
      "Epoch 17/25\n",
      "50/50 [==============================] - 34s 680ms/step - loss: 7.1282 - rmse: 10.1938 - val_loss: 67.6319 - val_rmse: 107.9069\n",
      "Epoch 18/25\n",
      "50/50 [==============================] - 34s 681ms/step - loss: 7.0617 - rmse: 10.1319 - val_loss: 71.3854 - val_rmse: 111.4041\n",
      "Epoch 19/25\n",
      "50/50 [==============================] - 34s 681ms/step - loss: 6.9885 - rmse: 10.0140 - val_loss: 71.9958 - val_rmse: 111.3882\n",
      "Epoch 20/25\n",
      "50/50 [==============================] - 34s 682ms/step - loss: 6.8648 - rmse: 9.8738 - val_loss: 68.6515 - val_rmse: 108.5360\n",
      "Epoch 21/25\n",
      "50/50 [==============================] - 34s 681ms/step - loss: 6.6996 - rmse: 9.6357 - val_loss: 71.0423 - val_rmse: 110.5672\n",
      "Epoch 22/25\n",
      "50/50 [==============================] - 34s 684ms/step - loss: 6.5826 - rmse: 9.5013 - val_loss: 71.6799 - val_rmse: 111.7381\n",
      "Epoch 23/25\n",
      "50/50 [==============================] - 34s 687ms/step - loss: 6.4956 - rmse: 9.3589 - val_loss: 70.5087 - val_rmse: 110.4534\n",
      "Epoch 24/25\n",
      "50/50 [==============================] - 34s 684ms/step - loss: 6.3292 - rmse: 9.1479 - val_loss: 67.2298 - val_rmse: 107.1393\n",
      "Epoch 25/25\n",
      "50/50 [==============================] - 34s 680ms/step - loss: 6.2172 - rmse: 9.0307 - val_loss: 68.2049 - val_rmse: 108.2045\n",
      "(0.4, 0.6000000000000001)\n",
      "Train for 50 steps, validate for 50 steps\n",
      "Epoch 1/25\n",
      "50/50 [==============================] - 61s 1s/step - loss: 304.5622 - rmse: 418.6228 - val_loss: 32.8538 - val_rmse: 40.7485\n",
      "Epoch 2/25\n",
      "50/50 [==============================] - 54s 1s/step - loss: 44.6310 - rmse: 73.4078 - val_loss: 25.8449 - val_rmse: 32.8784\n",
      "Epoch 3/25\n",
      "50/50 [==============================] - 55s 1s/step - loss: 37.6191 - rmse: 64.6336 - val_loss: 32.0385 - val_rmse: 44.8735\n",
      "Epoch 4/25\n",
      "50/50 [==============================] - 56s 1s/step - loss: 42.6561 - rmse: 71.7550 - val_loss: 29.9867 - val_rmse: 38.7965\n",
      "Epoch 5/25\n",
      "50/50 [==============================] - 57s 1s/step - loss: 35.9582 - rmse: 64.0271 - val_loss: 32.4995 - val_rmse: 41.6231\n",
      "Epoch 6/25\n",
      "50/50 [==============================] - 57s 1s/step - loss: 36.0737 - rmse: 64.1442 - val_loss: 26.1150 - val_rmse: 33.2689\n",
      "Epoch 7/25\n",
      "50/50 [==============================] - 57s 1s/step - loss: 31.5510 - rmse: 61.5860 - val_loss: 25.2917 - val_rmse: 32.5822\n",
      "Epoch 8/25\n",
      "50/50 [==============================] - 58s 1s/step - loss: 29.1465 - rmse: 60.2836 - val_loss: 22.7769 - val_rmse: 29.5120\n",
      "Epoch 9/25\n",
      "50/50 [==============================] - 58s 1s/step - loss: 27.4356 - rmse: 59.3042 - val_loss: 14.1648 - val_rmse: 19.3737\n",
      "Epoch 10/25\n",
      "50/50 [==============================] - 58s 1s/step - loss: 26.1325 - rmse: 58.4766 - val_loss: 15.9222 - val_rmse: 21.5643\n",
      "Epoch 11/25\n",
      "50/50 [==============================] - 58s 1s/step - loss: 25.3718 - rmse: 57.6386 - val_loss: 17.3237 - val_rmse: 23.3814\n",
      "Epoch 12/25\n",
      "50/50 [==============================] - 58s 1s/step - loss: 24.8745 - rmse: 56.2550 - val_loss: 16.8058 - val_rmse: 22.9438\n",
      "Epoch 13/25\n",
      "50/50 [==============================] - 59s 1s/step - loss: 23.5081 - rmse: 52.6063 - val_loss: 21.0759 - val_rmse: 27.7672\n",
      "Epoch 14/25\n",
      "50/50 [==============================] - 59s 1s/step - loss: 20.3682 - rmse: 42.6594 - val_loss: 23.6383 - val_rmse: 30.7432\n",
      "Epoch 15/25\n",
      "50/50 [==============================] - 61s 1s/step - loss: 18.2184 - rmse: 37.5475 - val_loss: 19.9314 - val_rmse: 26.2478\n",
      "Epoch 16/25\n",
      "50/50 [==============================] - 59s 1s/step - loss: 16.7177 - rmse: 32.7253 - val_loss: 18.9639 - val_rmse: 25.3536\n",
      "Epoch 17/25\n",
      "50/50 [==============================] - 59s 1s/step - loss: 14.6167 - rmse: 28.6478 - val_loss: 17.3160 - val_rmse: 24.1932\n",
      "Epoch 18/25\n",
      "50/50 [==============================] - 58s 1s/step - loss: 14.3737 - rmse: 28.4243 - val_loss: 16.7377 - val_rmse: 22.6735\n",
      "Epoch 19/25\n",
      "50/50 [==============================] - 59s 1s/step - loss: 12.8789 - rmse: 25.2951 - val_loss: 13.4171 - val_rmse: 18.5352\n",
      "Epoch 20/25\n",
      "50/50 [==============================] - 59s 1s/step - loss: 11.9832 - rmse: 23.9176 - val_loss: 10.0928 - val_rmse: 14.1692\n",
      "Epoch 21/25\n",
      "50/50 [==============================] - 60s 1s/step - loss: 12.0457 - rmse: 23.4712 - val_loss: 9.9630 - val_rmse: 13.5385\n",
      "Epoch 22/25\n",
      "50/50 [==============================] - 59s 1s/step - loss: 11.6004 - rmse: 23.4487 - val_loss: 11.9675 - val_rmse: 16.3799\n",
      "Epoch 23/25\n",
      "50/50 [==============================] - 60s 1s/step - loss: 10.9940 - rmse: 22.1688 - val_loss: 8.7996 - val_rmse: 12.1293\n",
      "Epoch 24/25\n",
      "50/50 [==============================] - 59s 1s/step - loss: 10.4021 - rmse: 20.7147 - val_loss: 8.1808 - val_rmse: 11.3499\n",
      "Epoch 25/25\n",
      "50/50 [==============================] - 59s 1s/step - loss: 10.1782 - rmse: 20.0319 - val_loss: 8.0137 - val_rmse: 11.1825\n",
      "(0.6000000000000001, 0.8)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "714dafcd52ca459b814781a270b6daab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 50 steps, validate for 50 steps\n",
      "Epoch 1/25\n",
      "50/50 [==============================] - 44s 887ms/step - loss: 413.7067 - rmse: 560.1672 - val_loss: 159.4156 - val_rmse: 205.7175\n",
      "Epoch 2/25\n",
      "50/50 [==============================] - 36s 720ms/step - loss: 188.4518 - rmse: 257.8101 - val_loss: 28.8717 - val_rmse: 36.6497\n",
      "Epoch 3/25\n",
      "50/50 [==============================] - 36s 726ms/step - loss: 100.3073 - rmse: 133.7411 - val_loss: 365.3354 - val_rmse: 489.0358\n",
      "Epoch 4/25\n",
      "50/50 [==============================] - 36s 725ms/step - loss: 135.9535 - rmse: 187.0481 - val_loss: 170.1585 - val_rmse: 224.5976\n",
      "Epoch 5/25\n",
      "50/50 [==============================] - 36s 728ms/step - loss: 518.9847 - rmse: 712.7269 - val_loss: 95.0337 - val_rmse: 120.1593\n",
      "Epoch 6/25\n",
      "50/50 [==============================] - 36s 729ms/step - loss: 209.5094 - rmse: 290.9216 - val_loss: 54.1047 - val_rmse: 71.4482\n",
      "Epoch 7/25\n",
      "50/50 [==============================] - 36s 728ms/step - loss: 211.9690 - rmse: 307.7745 - val_loss: 30.0587 - val_rmse: 37.5832\n",
      "Epoch 8/25\n",
      "50/50 [==============================] - 36s 727ms/step - loss: 93.7361 - rmse: 143.7734 - val_loss: 30.8445 - val_rmse: 40.1113\n",
      "Epoch 9/25\n",
      "50/50 [==============================] - 37s 733ms/step - loss: 26.9956 - rmse: 35.6509 - val_loss: 33.7487 - val_rmse: 42.8784\n",
      "Epoch 10/25\n",
      "50/50 [==============================] - 36s 724ms/step - loss: 28.9070 - rmse: 36.2547 - val_loss: 27.8286 - val_rmse: 36.5244\n",
      "Epoch 11/25\n",
      "50/50 [==============================] - 37s 745ms/step - loss: 22.3501 - rmse: 27.2408 - val_loss: 30.2325 - val_rmse: 39.3727\n",
      "Epoch 12/25\n",
      "50/50 [==============================] - 37s 734ms/step - loss: 18.0053 - rmse: 22.7387 - val_loss: 16.9983 - val_rmse: 22.5457\n",
      "Epoch 13/25\n",
      "50/50 [==============================] - 37s 731ms/step - loss: 13.2479 - rmse: 17.3985 - val_loss: 19.3644 - val_rmse: 25.4114\n",
      "Epoch 14/25\n",
      "50/50 [==============================] - 37s 739ms/step - loss: 10.9196 - rmse: 14.5836 - val_loss: 19.7612 - val_rmse: 26.2734\n",
      "Epoch 15/25\n",
      "50/50 [==============================] - 37s 730ms/step - loss: 9.7638 - rmse: 13.1591 - val_loss: 17.0697 - val_rmse: 23.2405\n",
      "Epoch 16/25\n",
      "50/50 [==============================] - 37s 737ms/step - loss: 8.9667 - rmse: 12.1575 - val_loss: 14.6836 - val_rmse: 20.3161\n",
      "Epoch 17/25\n",
      "50/50 [==============================] - 37s 738ms/step - loss: 8.4266 - rmse: 11.4425 - val_loss: 9.9771 - val_rmse: 14.5240\n",
      "Epoch 18/25\n",
      "50/50 [==============================] - 37s 738ms/step - loss: 7.9258 - rmse: 10.8521 - val_loss: 11.8146 - val_rmse: 17.1990\n",
      "Epoch 19/25\n",
      "50/50 [==============================] - 36s 729ms/step - loss: 7.6382 - rmse: 10.5312 - val_loss: 10.2517 - val_rmse: 14.5827\n",
      "Epoch 20/25\n",
      "50/50 [==============================] - 37s 733ms/step - loss: 7.3325 - rmse: 10.1272 - val_loss: 9.6832 - val_rmse: 13.6904\n",
      "Epoch 21/25\n",
      "50/50 [==============================] - 36s 728ms/step - loss: 7.1168 - rmse: 9.8514 - val_loss: 11.6580 - val_rmse: 16.6329\n",
      "Epoch 22/25\n",
      "50/50 [==============================] - 37s 735ms/step - loss: 6.8949 - rmse: 9.5923 - val_loss: 10.3148 - val_rmse: 15.2135\n",
      "Epoch 23/25\n",
      "50/50 [==============================] - 37s 738ms/step - loss: 6.7495 - rmse: 9.4204 - val_loss: 8.2393 - val_rmse: 11.9314\n",
      "Epoch 24/25\n",
      "50/50 [==============================] - 37s 737ms/step - loss: 6.4724 - rmse: 9.0943 - val_loss: 11.2087 - val_rmse: 16.1748\n",
      "Epoch 25/25\n",
      "50/50 [==============================] - 36s 730ms/step - loss: 6.4431 - rmse: 9.0663 - val_loss: 8.0459 - val_rmse: 11.9714\n",
      "(0.2, 0.4)\n",
      "Train for 50 steps, validate for 50 steps\n",
      "Epoch 1/25\n",
      "50/50 [==============================] - 70s 1s/step - loss: 157.5342 - rmse: 213.7607 - val_loss: 75.8963 - val_rmse: 113.6667\n",
      "Epoch 2/25\n",
      "50/50 [==============================] - 61s 1s/step - loss: 28.7684 - rmse: 36.3724 - val_loss: 79.2663 - val_rmse: 117.9183\n",
      "Epoch 3/25\n",
      "50/50 [==============================] - 62s 1s/step - loss: 931.8489 - rmse: 1298.0366 - val_loss: 329.3139 - val_rmse: 438.1506\n",
      "Epoch 4/25\n",
      "50/50 [==============================] - 62s 1s/step - loss: 432.7526 - rmse: 604.6830 - val_loss: 936.5908 - val_rmse: 1101.3135\n",
      "Epoch 5/25\n",
      "50/50 [==============================] - 62s 1s/step - loss: 275.0025 - rmse: 368.5293 - val_loss: 76.0332 - val_rmse: 111.2658\n",
      "Epoch 6/25\n",
      "50/50 [==============================] - 63s 1s/step - loss: 327.2827 - rmse: 431.6100 - val_loss: 83.5715 - val_rmse: 120.6171\n",
      "Epoch 7/25\n",
      "50/50 [==============================] - 63s 1s/step - loss: 141.0157 - rmse: 213.0136 - val_loss: 85.2141 - val_rmse: 122.9826\n",
      "Epoch 8/25\n",
      "50/50 [==============================] - 63s 1s/step - loss: 42.4412 - rmse: 55.3945 - val_loss: 82.9940 - val_rmse: 121.4523\n",
      "Epoch 9/25\n",
      "50/50 [==============================] - 63s 1s/step - loss: 31.4890 - rmse: 39.7752 - val_loss: 82.0662 - val_rmse: 120.5877\n",
      "Epoch 10/25\n",
      "50/50 [==============================] - 64s 1s/step - loss: 79.7807 - rmse: 112.9522 - val_loss: 80.0530 - val_rmse: 118.4081\n",
      "Epoch 11/25\n",
      "50/50 [==============================] - 63s 1s/step - loss: 51.3766 - rmse: 70.3563 - val_loss: 73.4257 - val_rmse: 113.3256\n",
      "Epoch 12/25\n",
      "50/50 [==============================] - 63s 1s/step - loss: 24.6137 - rmse: 33.7172 - val_loss: 74.3324 - val_rmse: 108.2547\n",
      "Epoch 13/25\n",
      "50/50 [==============================] - 63s 1s/step - loss: 16.6863 - rmse: 21.6228 - val_loss: 78.5890 - val_rmse: 117.3338\n",
      "Epoch 14/25\n",
      "50/50 [==============================] - 63s 1s/step - loss: 14.7584 - rmse: 19.4660 - val_loss: 70.8774 - val_rmse: 110.3102\n",
      "Epoch 15/25\n",
      "50/50 [==============================] - 63s 1s/step - loss: 13.2279 - rmse: 18.4978 - val_loss: 71.4133 - val_rmse: 110.7056\n",
      "Epoch 16/25\n",
      "50/50 [==============================] - 63s 1s/step - loss: 10.2207 - rmse: 14.1339 - val_loss: 72.7415 - val_rmse: 110.7606\n",
      "Epoch 17/25\n",
      "50/50 [==============================] - 63s 1s/step - loss: 11.2732 - rmse: 15.6577 - val_loss: 72.9940 - val_rmse: 112.4670\n",
      "Epoch 18/25\n",
      "50/50 [==============================] - 64s 1s/step - loss: 9.8591 - rmse: 13.6721 - val_loss: 72.6985 - val_rmse: 111.8227\n",
      "Epoch 19/25\n",
      "50/50 [==============================] - 63s 1s/step - loss: 9.0882 - rmse: 12.6582 - val_loss: 70.7271 - val_rmse: 110.7282\n",
      "Epoch 20/25\n",
      "50/50 [==============================] - 63s 1s/step - loss: 8.4739 - rmse: 11.9098 - val_loss: 66.4454 - val_rmse: 106.0088\n",
      "Epoch 21/25\n",
      "50/50 [==============================] - 64s 1s/step - loss: 8.0505 - rmse: 11.3259 - val_loss: 66.9767 - val_rmse: 106.3403\n",
      "Epoch 22/25\n",
      "50/50 [==============================] - 64s 1s/step - loss: 7.8138 - rmse: 11.0349 - val_loss: 66.1222 - val_rmse: 107.7918\n",
      "Epoch 23/25\n",
      "50/50 [==============================] - 64s 1s/step - loss: 7.4955 - rmse: 10.6342 - val_loss: 64.3091 - val_rmse: 106.4847\n",
      "Epoch 24/25\n",
      "50/50 [==============================] - 63s 1s/step - loss: 7.2955 - rmse: 10.3621 - val_loss: 63.9037 - val_rmse: 105.8491\n",
      "Epoch 25/25\n",
      "50/50 [==============================] - 64s 1s/step - loss: 7.1471 - rmse: 10.1809 - val_loss: 63.9141 - val_rmse: 106.3728\n",
      "(0.4, 0.6000000000000001)\n",
      "Train for 50 steps, validate for 50 steps\n",
      "Epoch 1/25\n",
      "50/50 [==============================] - 88s 2s/step - loss: 42.6607 - rmse: 70.2064 - val_loss: 29.3252 - val_rmse: 37.9870\n",
      "Epoch 2/25\n",
      "50/50 [==============================] - 81s 2s/step - loss: 39.9923 - rmse: 67.5576 - val_loss: 31.5836 - val_rmse: 40.5231\n",
      "Epoch 3/25\n",
      "50/50 [==============================] - 82s 2s/step - loss: 33.7944 - rmse: 62.7070 - val_loss: 14.7149 - val_rmse: 19.6183\n",
      "Epoch 4/25\n",
      "50/50 [==============================] - 82s 2s/step - loss: 30.6481 - rmse: 60.9670 - val_loss: 20.3617 - val_rmse: 27.3042\n",
      "Epoch 5/25\n",
      "50/50 [==============================] - 83s 2s/step - loss: 28.5028 - rmse: 60.0123 - val_loss: 16.9255 - val_rmse: 22.5623\n",
      "Epoch 6/25\n",
      "50/50 [==============================] - 85s 2s/step - loss: 26.7082 - rmse: 58.9901 - val_loss: 13.9106 - val_rmse: 18.9078\n",
      "Epoch 7/25\n",
      "50/50 [==============================] - 84s 2s/step - loss: 25.7282 - rmse: 58.3789 - val_loss: 9.1320 - val_rmse: 12.3096\n",
      "Epoch 8/25\n",
      "50/50 [==============================] - 84s 2s/step - loss: 25.8374 - rmse: 59.2461 - val_loss: 10.4312 - val_rmse: 13.8719\n",
      "Epoch 9/25\n",
      "50/50 [==============================] - 85s 2s/step - loss: 22.2569 - rmse: 50.5552 - val_loss: 14.6297 - val_rmse: 20.0687\n",
      "Epoch 10/25\n",
      "50/50 [==============================] - 87s 2s/step - loss: 19.4799 - rmse: 41.4912 - val_loss: 9.3507 - val_rmse: 12.7648\n",
      "Epoch 11/25\n",
      "50/50 [==============================] - 86s 2s/step - loss: 16.4616 - rmse: 33.6904 - val_loss: 7.9097 - val_rmse: 10.8361\n",
      "Epoch 12/25\n",
      "50/50 [==============================] - 86s 2s/step - loss: 14.4050 - rmse: 28.8980 - val_loss: 9.2136 - val_rmse: 12.6205\n",
      "Epoch 13/25\n",
      "50/50 [==============================] - 87s 2s/step - loss: 13.9416 - rmse: 28.6722 - val_loss: 7.0519 - val_rmse: 9.9456\n",
      "Epoch 14/25\n",
      "50/50 [==============================] - 86s 2s/step - loss: 12.2845 - rmse: 24.1114 - val_loss: 8.8731 - val_rmse: 12.4492\n",
      "Epoch 15/25\n",
      "50/50 [==============================] - 87s 2s/step - loss: 10.9872 - rmse: 21.8764 - val_loss: 8.1899 - val_rmse: 11.4134\n",
      "Epoch 16/25\n",
      "50/50 [==============================] - 87s 2s/step - loss: 11.0662 - rmse: 21.4950 - val_loss: 10.0085 - val_rmse: 14.0464\n",
      "Epoch 17/25\n",
      "50/50 [==============================] - 87s 2s/step - loss: 10.9000 - rmse: 21.6758 - val_loss: 7.5160 - val_rmse: 10.2630\n",
      "Epoch 18/25\n",
      "50/50 [==============================] - 88s 2s/step - loss: 10.4808 - rmse: 20.7395 - val_loss: 6.8530 - val_rmse: 9.5455\n",
      "Epoch 19/25\n",
      "50/50 [==============================] - 88s 2s/step - loss: 9.9419 - rmse: 19.3851 - val_loss: 7.4401 - val_rmse: 10.1003\n",
      "Epoch 20/25\n",
      "50/50 [==============================] - 88s 2s/step - loss: 9.5010 - rmse: 18.5830 - val_loss: 8.0240 - val_rmse: 11.2090\n",
      "Epoch 21/25\n",
      "50/50 [==============================] - 88s 2s/step - loss: 9.7358 - rmse: 18.9413 - val_loss: 7.6217 - val_rmse: 10.4941\n",
      "Epoch 22/25\n",
      "50/50 [==============================] - 88s 2s/step - loss: 9.2496 - rmse: 18.7125 - val_loss: 6.3665 - val_rmse: 8.9390\n",
      "Epoch 23/25\n",
      "50/50 [==============================] - 88s 2s/step - loss: 8.8508 - rmse: 17.7418 - val_loss: 6.6893 - val_rmse: 9.2752\n",
      "Epoch 24/25\n",
      "50/50 [==============================] - 88s 2s/step - loss: 8.5065 - rmse: 16.8678 - val_loss: 6.0288 - val_rmse: 8.5969\n",
      "Epoch 25/25\n",
      "50/50 [==============================] - 88s 2s/step - loss: 8.4518 - rmse: 16.8593 - val_loss: 7.3051 - val_rmse: 10.1372\n",
      "(0.6000000000000001, 0.8)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_dict = {\"epochs\":[25], \"layer_count\":[5, 6, 7], \"node_number\":[60, 80, 110], \"dropout\":[0.8]}\n",
    "\n",
    "grid_search.search(feature_dict, unimodo_data, windows=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator(x):\n",
    "    return sum([splits[-1]*values['val_loss'] for (splits, values) in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'epochs': 25, 'layer_count': 7, 'node_number': 110, 'dropout': 0.8},\n",
       "  [[(0.2, 0.4),\n",
       "    {'loss': 6.443119125366211,\n",
       "     'rmse': 9.066284,\n",
       "     'val_loss': 8.045858383178711,\n",
       "     'val_rmse': 11.971369}],\n",
       "   [(0.4, 0.6000000000000001),\n",
       "    {'loss': 7.147062463760376,\n",
       "     'rmse': 10.180936,\n",
       "     'val_loss': 63.91410827636719,\n",
       "     'val_rmse': 106.37285}],\n",
       "   [(0.6000000000000001, 0.8),\n",
       "    {'loss': 8.451807041168212,\n",
       "     'rmse': 16.859343,\n",
       "     'val_loss': 7.305148124694824,\n",
       "     'val_rmse': 10.13723}]]],\n",
       " [{'epochs': 25, 'layer_count': 5, 'node_number': 80, 'dropout': 0.8},\n",
       "  [[(0.2, 0.4),\n",
       "    {'loss': 5.365896091461182,\n",
       "     'rmse': 7.8295307,\n",
       "     'val_loss': 11.1212739944458,\n",
       "     'val_rmse': 15.942946}],\n",
       "   [(0.4, 0.6000000000000001),\n",
       "    {'loss': 6.023767557144165,\n",
       "     'rmse': 8.712482,\n",
       "     'val_loss': 65.02237701416016,\n",
       "     'val_rmse': 108.591484}],\n",
       "   [(0.6000000000000001, 0.8),\n",
       "    {'loss': 8.87853536605835,\n",
       "     'rmse': 17.930183,\n",
       "     'val_loss': 6.4038310050964355,\n",
       "     'val_rmse': 9.013953}]]],\n",
       " [{'epochs': 25, 'layer_count': 5, 'node_number': 110, 'dropout': 0.8},\n",
       "  [[(0.2, 0.4),\n",
       "    {'loss': 5.213888311386109,\n",
       "     'rmse': 7.5833755,\n",
       "     'val_loss': 8.327378273010254,\n",
       "     'val_rmse': 12.212346}],\n",
       "   [(0.4, 0.6000000000000001),\n",
       "    {'loss': 5.962134866714478,\n",
       "     'rmse': 8.6390915,\n",
       "     'val_loss': 64.82433319091797,\n",
       "     'val_rmse': 107.16096}],\n",
       "   [(0.6000000000000001, 0.8),\n",
       "    {'loss': 9.487969808578491,\n",
       "     'rmse': 19.238314,\n",
       "     'val_loss': 8.008713722229004,\n",
       "     'val_rmse': 11.260199}]]],\n",
       " [{'epochs': 25, 'layer_count': 6, 'node_number': 110, 'dropout': 0.8},\n",
       "  [[(0.2, 0.4),\n",
       "    {'loss': 5.171285982131958,\n",
       "     'rmse': 7.499413,\n",
       "     'val_loss': 9.998433113098145,\n",
       "     'val_rmse': 14.942018}],\n",
       "   [(0.4, 0.6000000000000001),\n",
       "    {'loss': 5.587832107543945,\n",
       "     'rmse': 8.084932,\n",
       "     'val_loss': 66.26338958740234,\n",
       "     'val_rmse': 109.58886}],\n",
       "   [(0.6000000000000001, 0.8),\n",
       "    {'loss': 8.646877717971801,\n",
       "     'rmse': 17.73501,\n",
       "     'val_loss': 7.704596996307373,\n",
       "     'val_rmse': 10.696982}]]],\n",
       " [{'epochs': 25, 'layer_count': 7, 'node_number': 80, 'dropout': 0.8},\n",
       "  [[(0.2, 0.4),\n",
       "    {'loss': 5.639808044433594,\n",
       "     'rmse': 8.157617,\n",
       "     'val_loss': 8.607827186584473,\n",
       "     'val_rmse': 12.1501045}],\n",
       "   [(0.4, 0.6000000000000001),\n",
       "    {'loss': 6.217198972702026,\n",
       "     'rmse': 9.0306835,\n",
       "     'val_loss': 68.20489501953125,\n",
       "     'val_rmse': 108.204544}],\n",
       "   [(0.6000000000000001, 0.8),\n",
       "    {'loss': 10.178178739547729,\n",
       "     'rmse': 20.031858,\n",
       "     'val_loss': 8.013665199279785,\n",
       "     'val_rmse': 11.182503}]]],\n",
       " [{'epochs': 25, 'layer_count': 6, 'node_number': 80, 'dropout': 0.8},\n",
       "  [[(0.2, 0.4),\n",
       "    {'loss': 5.438128719329834,\n",
       "     'rmse': 7.8363247,\n",
       "     'val_loss': 14.539533615112305,\n",
       "     'val_rmse': 21.004438}],\n",
       "   [(0.4, 0.6000000000000001),\n",
       "    {'loss': 6.514458103179932,\n",
       "     'rmse': 9.405744,\n",
       "     'val_loss': 64.16421508789062,\n",
       "     'val_rmse': 105.36216}],\n",
       "   [(0.6000000000000001, 0.8),\n",
       "    {'loss': 9.133622608184815,\n",
       "     'rmse': 18.660799,\n",
       "     'val_loss': 9.48530387878418,\n",
       "     'val_rmse': 13.364479}]]],\n",
       " [{'epochs': 25, 'layer_count': 6, 'node_number': 60, 'dropout': 0.8},\n",
       "  [[(0.2, 0.4),\n",
       "    {'loss': 5.245686683654785,\n",
       "     'rmse': 7.579007,\n",
       "     'val_loss': 17.36281394958496,\n",
       "     'val_rmse': 24.351435}],\n",
       "   [(0.4, 0.6000000000000001),\n",
       "    {'loss': 5.790827703475952,\n",
       "     'rmse': 8.366974,\n",
       "     'val_loss': 66.67759704589844,\n",
       "     'val_rmse': 108.803535}],\n",
       "   [(0.6000000000000001, 0.8),\n",
       "    {'loss': 11.487701015472412,\n",
       "     'rmse': 24.459915,\n",
       "     'val_loss': 8.33386516571045,\n",
       "     'val_rmse': 11.519773}]]],\n",
       " [{'epochs': 25, 'layer_count': 5, 'node_number': 60, 'dropout': 0.8},\n",
       "  [[(0.2, 0.4),\n",
       "    {'loss': 5.1621395874023435,\n",
       "     'rmse': 7.635326,\n",
       "     'val_loss': 9.789531707763672,\n",
       "     'val_rmse': 14.290833}],\n",
       "   [(0.4, 0.6000000000000001),\n",
       "    {'loss': 5.86313416481018,\n",
       "     'rmse': 8.484132,\n",
       "     'val_loss': 71.59339141845703,\n",
       "     'val_rmse': 112.72786}],\n",
       "   [(0.6000000000000001, 0.8),\n",
       "    {'loss': 9.235843029022217,\n",
       "     'rmse': 18.138807,\n",
       "     'val_loss': 8.78506088256836,\n",
       "     'val_rmse': 12.0978365}]]],\n",
       " [{'epochs': 25, 'layer_count': 7, 'node_number': 60, 'dropout': 0.8},\n",
       "  [[(0.2, 0.4),\n",
       "    {'loss': 6.113166627883911,\n",
       "     'rmse': 8.796301,\n",
       "     'val_loss': 16.954233169555664,\n",
       "     'val_rmse': 24.38904}],\n",
       "   [(0.4, 0.6000000000000001),\n",
       "    {'loss': 6.340918645858765,\n",
       "     'rmse': 9.12054,\n",
       "     'val_loss': 71.97855377197266,\n",
       "     'val_rmse': 113.097145}],\n",
       "   [(0.6000000000000001, 0.8),\n",
       "    {'loss': 9.899138202667237,\n",
       "     'rmse': 19.184772,\n",
       "     'val_loss': 7.284982681274414,\n",
       "     'val_rmse': 10.270575}]]]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.evaluations.sort(key=lambda x:evaluator(x[1]))\n",
    "grid_search.evaluations #Unimodo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'epochs': 25, 'layer_count': 7, 'node_number': 110, 'dropout': 0.8},\n",
       "  [[(0.2, 0.4),\n",
       "    {'loss': 0.09985854402184487,\n",
       "     'rmse': 0.48959342,\n",
       "     'val_loss': 50.34468078613281,\n",
       "     'val_rmse': 218.95598}],\n",
       "   [(0.4, 0.6000000000000001),\n",
       "    {'loss': 6.384657497406006,\n",
       "     'rmse': 45.841778,\n",
       "     'val_loss': 361.4893493652344,\n",
       "     'val_rmse': 428.8502}],\n",
       "   [(0.6000000000000001, 0.8),\n",
       "    {'loss': 105.14816802978515,\n",
       "     'rmse': 204.56816,\n",
       "     'val_loss': 163.1005401611328,\n",
       "     'val_rmse': 197.17387}]]],\n",
       " [{'epochs': 25, 'layer_count': 5, 'node_number': 60, 'dropout': 0.8},\n",
       "  [[(0.2, 0.4),\n",
       "    {'loss': 0.09648234695196152,\n",
       "     'rmse': 0.48970473,\n",
       "     'val_loss': 50.34015655517578,\n",
       "     'val_rmse': 218.95772}],\n",
       "   [(0.4, 0.6000000000000001),\n",
       "    {'loss': 39.36996440887451,\n",
       "     'rmse': 170.5051,\n",
       "     'val_loss': 455.2791442871094,\n",
       "     'val_rmse': 526.3296}],\n",
       "   [(0.6000000000000001, 0.8),\n",
       "    {'loss': 213.36861389160157,\n",
       "     'rmse': 468.7553,\n",
       "     'val_loss': 326.29290771484375,\n",
       "     'val_rmse': 373.41605}]]],\n",
       " [{'epochs': 25, 'layer_count': 7, 'node_number': 80, 'dropout': 0.8},\n",
       "  [[(0.2, 0.4),\n",
       "    {'loss': 0.09847676917910576,\n",
       "     'rmse': 0.48981643,\n",
       "     'val_loss': 50.34135437011719,\n",
       "     'val_rmse': 218.95674}],\n",
       "   [(0.4, 0.6000000000000001),\n",
       "    {'loss': 8.445902519226074,\n",
       "     'rmse': 53.01859,\n",
       "     'val_loss': 1119.054443359375,\n",
       "     'val_rmse': 2071.2915}],\n",
       "   [(0.6000000000000001, 0.8),\n",
       "    {'loss': 75.9103646850586,\n",
       "     'rmse': 179.58568,\n",
       "     'val_loss': 206.1903839111328,\n",
       "     'val_rmse': 241.63762}]]],\n",
       " [{'epochs': 25, 'layer_count': 3, 'node_number': 60, 'dropout': 0.8},\n",
       "  [[(0.2, 0.4),\n",
       "    {'loss': 0.09786783277988434,\n",
       "     'rmse': 0.48971412,\n",
       "     'val_loss': 50.342063903808594,\n",
       "     'val_rmse': 218.95738}],\n",
       "   [(0.4, 0.6000000000000001),\n",
       "    {'loss': 8.047250452041625,\n",
       "     'rmse': 51.785046,\n",
       "     'val_loss': 990.0717163085938,\n",
       "     'val_rmse': 1325.5459}],\n",
       "   [(0.6000000000000001, 0.8),\n",
       "    {'loss': 56.016255645751954,\n",
       "     'rmse': 127.91254,\n",
       "     'val_loss': 319.2504577636719,\n",
       "     'val_rmse': 368.08966}]]],\n",
       " [{'epochs': 25, 'layer_count': 5, 'node_number': 110, 'dropout': 0.8},\n",
       "  [[(0.2, 0.4),\n",
       "    {'loss': 0.09623736247420311,\n",
       "     'rmse': 0.4902081,\n",
       "     'val_loss': 50.33984375,\n",
       "     'val_rmse': 218.95712}],\n",
       "   [(0.4, 0.6000000000000001),\n",
       "    {'loss': 6.875148420333862,\n",
       "     'rmse': 43.2828,\n",
       "     'val_loss': 1485.3541259765625,\n",
       "     'val_rmse': 2211.1584}],\n",
       "   [(0.6000000000000001, 0.8),\n",
       "    {'loss': 66.92950790405274,\n",
       "     'rmse': 157.3594,\n",
       "     'val_loss': 190.28721618652344,\n",
       "     'val_rmse': 220.75655}]]],\n",
       " [{'epochs': 25, 'layer_count': 5, 'node_number': 80, 'dropout': 0.8},\n",
       "  [[(0.2, 0.4),\n",
       "    {'loss': 0.10001567021012306,\n",
       "     'rmse': 0.49101883,\n",
       "     'val_loss': 50.39118194580078,\n",
       "     'val_rmse': 218.97354}],\n",
       "   [(0.4, 0.6000000000000001),\n",
       "    {'loss': 7.261396999359131,\n",
       "     'rmse': 45.376694,\n",
       "     'val_loss': 1844.38916015625,\n",
       "     'val_rmse': 3435.8704}],\n",
       "   [(0.6000000000000001, 0.8),\n",
       "    {'loss': 57.000468521118165,\n",
       "     'rmse': 126.69833,\n",
       "     'val_loss': 191.98492431640625,\n",
       "     'val_rmse': 230.45116}]]],\n",
       " [{'epochs': 25, 'layer_count': 3, 'node_number': 110, 'dropout': 0.8},\n",
       "  [[(0.2, 0.4),\n",
       "    {'loss': 0.10039762243628501,\n",
       "     'rmse': 0.49126855,\n",
       "     'val_loss': 50.339866638183594,\n",
       "     'val_rmse': 218.95908}],\n",
       "   [(0.4, 0.6000000000000001),\n",
       "    {'loss': 7.467473812103272,\n",
       "     'rmse': 47.151558,\n",
       "     'val_loss': 5804.6259765625,\n",
       "     'val_rmse': 6700.813}],\n",
       "   [(0.6000000000000001, 0.8),\n",
       "    {'loss': 203.3039422607422,\n",
       "     'rmse': 329.01642,\n",
       "     'val_loss': 307.88458251953125,\n",
       "     'val_rmse': 356.98157}]]],\n",
       " [{'epochs': 25, 'layer_count': 3, 'node_number': 80, 'dropout': 0.8},\n",
       "  [[(0.2, 0.4),\n",
       "    {'loss': 0.09574130326509475,\n",
       "     'rmse': 0.48907456,\n",
       "     'val_loss': 50.34410858154297,\n",
       "     'val_rmse': 218.95506}],\n",
       "   [(0.4, 0.6000000000000001),\n",
       "    {'loss': 7.817086639404297,\n",
       "     'rmse': 51.91814,\n",
       "     'val_loss': 6174.9697265625,\n",
       "     'val_rmse': 11918.979}],\n",
       "   [(0.6000000000000001, 0.8),\n",
       "    {'loss': 131.73001991271974,\n",
       "     'rmse': 287.24915,\n",
       "     'val_loss': 255.4911346435547,\n",
       "     'val_rmse': 305.25665}]]],\n",
       " [{'epochs': 25, 'layer_count': 7, 'node_number': 60, 'dropout': 0.8},\n",
       "  [[(0.2, 0.4),\n",
       "    {'loss': 0.0985549296438694,\n",
       "     'rmse': 0.49018177,\n",
       "     'val_loss': 50.339202880859375,\n",
       "     'val_rmse': 218.95908}],\n",
       "   [(0.4, 0.6000000000000001),\n",
       "    {'loss': 10.830572786331176,\n",
       "     'rmse': 67.50626,\n",
       "     'val_loss': 7024.859375,\n",
       "     'val_rmse': 9126.164}],\n",
       "   [(0.6000000000000001, 0.8),\n",
       "    {'loss': 88.46200408935547,\n",
       "     'rmse': 196.71675,\n",
       "     'val_loss': 196.77130126953125,\n",
       "     'val_rmse': 228.57846}]]]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.evaluations.sort(key=lambda x:evaluator(x[1]))\n",
    "grid_search.evaluations #Unievo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluations on Evo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "feature_dict = {\"epochs\":[30], \"layer_count\":[5], \"node_number\":[80, 100, 120, 150], \"dropout\":[0.6, 0.7, 0.8, 0.9]}\n",
    "\n",
    "grid_search.search(feature_dict, evo_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'epochs': 30, 'layer_count': 5, 'node_number': 120, 'dropout': 0.8},\n",
       "  {'loss': 49.51356346130371,\n",
       "   'rmse': 109.657265,\n",
       "   'val_loss': 78.93724822998047,\n",
       "   'val_rmse': 96.40157}],\n",
       " [{'epochs': 30, 'layer_count': 5, 'node_number': 100, 'dropout': 0.8},\n",
       "  {'loss': 61.726402587890625,\n",
       "   'rmse': 122.815506,\n",
       "   'val_loss': 86.97623443603516,\n",
       "   'val_rmse': 108.30454}],\n",
       " [{'epochs': 30, 'layer_count': 5, 'node_number': 80, 'dropout': 0.8},\n",
       "  {'loss': 51.63334159851074,\n",
       "   'rmse': 114.50193,\n",
       "   'val_loss': 89.99913787841797,\n",
       "   'val_rmse': 106.89356}],\n",
       " [{'epochs': 30, 'layer_count': 5, 'node_number': 100, 'dropout': 0.9},\n",
       "  {'loss': 55.006822204589845,\n",
       "   'rmse': 116.58102,\n",
       "   'val_loss': 91.61908721923828,\n",
       "   'val_rmse': 110.98308}],\n",
       " [{'epochs': 30, 'layer_count': 5, 'node_number': 80, 'dropout': 0.7},\n",
       "  {'loss': 52.82768119812012,\n",
       "   'rmse': 114.70442,\n",
       "   'val_loss': 97.27867126464844,\n",
       "   'val_rmse': 119.96011}],\n",
       " [{'epochs': 30, 'layer_count': 5, 'node_number': 80, 'dropout': 0.6},\n",
       "  {'loss': 47.188268508911136,\n",
       "   'rmse': 110.22227,\n",
       "   'val_loss': 99.04442596435547,\n",
       "   'val_rmse': 121.62597}],\n",
       " [{'epochs': 30, 'layer_count': 5, 'node_number': 150, 'dropout': 0.8},\n",
       "  {'loss': 47.552582244873044,\n",
       "   'rmse': 111.09002,\n",
       "   'val_loss': 100.25788116455078,\n",
       "   'val_rmse': 121.22164}],\n",
       " [{'epochs': 30, 'layer_count': 5, 'node_number': 150, 'dropout': 0.7},\n",
       "  {'loss': 48.09884407043457,\n",
       "   'rmse': 109.803406,\n",
       "   'val_loss': 101.93317413330078,\n",
       "   'val_rmse': 125.80825}],\n",
       " [{'epochs': 30, 'layer_count': 5, 'node_number': 120, 'dropout': 0.9},\n",
       "  {'loss': 57.38759521484375,\n",
       "   'rmse': 123.11453,\n",
       "   'val_loss': 104.70089721679688,\n",
       "   'val_rmse': 133.34276}],\n",
       " [{'epochs': 30, 'layer_count': 5, 'node_number': 100, 'dropout': 0.6},\n",
       "  {'loss': 55.57654808044433,\n",
       "   'rmse': 118.12665,\n",
       "   'val_loss': 105.61467742919922,\n",
       "   'val_rmse': 125.96421}],\n",
       " [{'epochs': 30, 'layer_count': 5, 'node_number': 100, 'dropout': 0.7},\n",
       "  {'loss': 43.994720916748044,\n",
       "   'rmse': 103.33675,\n",
       "   'val_loss': 107.57276153564453,\n",
       "   'val_rmse': 126.84901}],\n",
       " [{'epochs': 30, 'layer_count': 5, 'node_number': 120, 'dropout': 0.7},\n",
       "  {'loss': 47.91206771850586,\n",
       "   'rmse': 109.36778,\n",
       "   'val_loss': 109.00221252441406,\n",
       "   'val_rmse': 130.15414}],\n",
       " [{'epochs': 30, 'layer_count': 5, 'node_number': 120, 'dropout': 0.6},\n",
       "  {'loss': 52.788270492553714,\n",
       "   'rmse': 114.0835,\n",
       "   'val_loss': 116.96217346191406,\n",
       "   'val_rmse': 147.333}],\n",
       " [{'epochs': 30, 'layer_count': 5, 'node_number': 150, 'dropout': 0.6},\n",
       "  {'loss': 44.77233642578125,\n",
       "   'rmse': 102.245636,\n",
       "   'val_loss': 128.83029174804688,\n",
       "   'val_rmse': 157.90536}],\n",
       " [{'epochs': 30, 'layer_count': 5, 'node_number': 150, 'dropout': 0.9},\n",
       "  {'loss': 51.47044197082519,\n",
       "   'rmse': 113.88121,\n",
       "   'val_loss': 130.3959503173828,\n",
       "   'val_rmse': 154.1919}],\n",
       " [{'epochs': 30, 'layer_count': 5, 'node_number': 80, 'dropout': 0.9},\n",
       "  {'loss': 74.79263534545899,\n",
       "   'rmse': 134.63995,\n",
       "   'val_loss': 206.69676208496094,\n",
       "   'val_rmse': 246.76588}]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.evaluations #evo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'epochs': 30, 'layer_count': 5, 'node_number': 60, 'dropout': 0.7},\n",
       "  {'loss': 59.834226837158205,\n",
       "   'rmse': 120.75018,\n",
       "   'val_loss': 78.8970947265625,\n",
       "   'val_rmse': 97.61479}],\n",
       " [{'epochs': 30, 'layer_count': 5, 'node_number': 120, 'dropout': 0.8},\n",
       "  {'loss': 54.921137466430665,\n",
       "   'rmse': 116.213264,\n",
       "   'val_loss': 96.0332260131836,\n",
       "   'val_rmse': 114.81347}],\n",
       " [{'epochs': 30, 'layer_count': 5, 'node_number': 80, 'dropout': 0.7},\n",
       "  {'loss': 49.36703758239746,\n",
       "   'rmse': 109.98419,\n",
       "   'val_loss': 96.65272521972656,\n",
       "   'val_rmse': 118.28333}],\n",
       " [{'epochs': 30, 'layer_count': 5, 'node_number': 100, 'dropout': 0.7},\n",
       "  {'loss': 47.30355560302734,\n",
       "   'rmse': 107.17045,\n",
       "   'val_loss': 104.60826110839844,\n",
       "   'val_rmse': 129.04442}],\n",
       " [{'epochs': 30, 'layer_count': 5, 'node_number': 100, 'dropout': 0.8},\n",
       "  {'loss': 50.6439501953125,\n",
       "   'rmse': 112.08298,\n",
       "   'val_loss': 105.54985046386719,\n",
       "   'val_rmse': 124.65917}],\n",
       " [{'epochs': 30, 'layer_count': 5, 'node_number': 80, 'dropout': 0.8},\n",
       "  {'loss': 54.61161277770996,\n",
       "   'rmse': 116.02507,\n",
       "   'val_loss': 105.7001953125,\n",
       "   'val_rmse': 128.44823}],\n",
       " [{'epochs': 30, 'layer_count': 5, 'node_number': 60, 'dropout': 0.9},\n",
       "  {'loss': 60.02934982299805,\n",
       "   'rmse': 121.36112,\n",
       "   'val_loss': 107.10043334960938,\n",
       "   'val_rmse': 131.12903}],\n",
       " [{'epochs': 30, 'layer_count': 5, 'node_number': 120, 'dropout': 0.7},\n",
       "  {'loss': 109.01725921630859,\n",
       "   'rmse': 173.48584,\n",
       "   'val_loss': 150.47567749023438,\n",
       "   'val_rmse': 178.01857}],\n",
       " [{'epochs': 30, 'layer_count': 5, 'node_number': 120, 'dropout': 0.9},\n",
       "  {'loss': 58.07984138488769,\n",
       "   'rmse': 118.79468,\n",
       "   'val_loss': 150.53582763671875,\n",
       "   'val_rmse': 186.30275}],\n",
       " [{'epochs': 30, 'layer_count': 5, 'node_number': 80, 'dropout': 0.9},\n",
       "  {'loss': 64.01417129516602,\n",
       "   'rmse': 124.866165,\n",
       "   'val_loss': 161.16204833984375,\n",
       "   'val_rmse': 191.19571}],\n",
       " [{'epochs': 30, 'layer_count': 5, 'node_number': 100, 'dropout': 0.9},\n",
       "  {'loss': 59.08925437927246,\n",
       "   'rmse': 119.0058,\n",
       "   'val_loss': 193.91957092285156,\n",
       "   'val_rmse': 235.42479}],\n",
       " [{'epochs': 30, 'layer_count': 5, 'node_number': 60, 'dropout': 0.8},\n",
       "  {'loss': 63.38395385742187,\n",
       "   'rmse': 124.696465,\n",
       "   'val_loss': 198.05690002441406,\n",
       "   'val_rmse': 237.38504}]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.evaluations #unievo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'epochs': 30, 'layer_count': 5, 'node_number': 100, 'dropout': 0.7},\n",
       "  {'loss': 61.98115303039551,\n",
       "   'rmse': 123.183075,\n",
       "   'val_loss': 88.98165130615234,\n",
       "   'val_rmse': 113.064804}],\n",
       " [{'epochs': 30, 'layer_count': 4, 'node_number': 60, 'dropout': 0.7},\n",
       "  {'loss': 48.69632125854492,\n",
       "   'rmse': 113.06194,\n",
       "   'val_loss': 90.21286010742188,\n",
       "   'val_rmse': 113.73388}],\n",
       " [{'epochs': 30, 'layer_count': 3, 'node_number': 60, 'dropout': 0.7},\n",
       "  {'loss': 50.08780746459961,\n",
       "   'rmse': 114.24129,\n",
       "   'val_loss': 93.33883666992188,\n",
       "   'val_rmse': 116.08402}],\n",
       " [{'epochs': 30, 'layer_count': 5, 'node_number': 60, 'dropout': 0.7},\n",
       "  {'loss': 49.519894714355466,\n",
       "   'rmse': 113.607605,\n",
       "   'val_loss': 94.20116424560547,\n",
       "   'val_rmse': 115.09389}],\n",
       " [{'epochs': 50, 'layer_count': 3, 'node_number': 100, 'dropout': 0.7},\n",
       "  {'loss': 36.9069128036499,\n",
       "   'rmse': 99.26817,\n",
       "   'val_loss': 96.38170623779297,\n",
       "   'val_rmse': 117.6753}],\n",
       " [{'epochs': 50, 'layer_count': 5, 'node_number': 80, 'dropout': 0.7},\n",
       "  {'loss': 38.50223976135254,\n",
       "   'rmse': 103.569855,\n",
       "   'val_loss': 97.00611877441406,\n",
       "   'val_rmse': 117.485176}],\n",
       " [{'epochs': 30, 'layer_count': 4, 'node_number': 80, 'dropout': 0.7},\n",
       "  {'loss': 46.53671096801758,\n",
       "   'rmse': 110.31899,\n",
       "   'val_loss': 97.76178741455078,\n",
       "   'val_rmse': 118.04789}],\n",
       " [{'epochs': 30, 'layer_count': 5, 'node_number': 100, 'dropout': 0.5},\n",
       "  {'loss': 44.28121971130371,\n",
       "   'rmse': 108.763535,\n",
       "   'val_loss': 98.07693481445312,\n",
       "   'val_rmse': 120.63917}],\n",
       " [{'epochs': 30, 'layer_count': 5, 'node_number': 80, 'dropout': 0.7},\n",
       "  {'loss': 48.033453369140624,\n",
       "   'rmse': 110.65266,\n",
       "   'val_loss': 101.02263641357422,\n",
       "   'val_rmse': 121.26187}],\n",
       " [{'epochs': 30, 'layer_count': 3, 'node_number': 80, 'dropout': 0.5},\n",
       "  {'loss': 49.68339309692383,\n",
       "   'rmse': 112.89597,\n",
       "   'val_loss': 102.08502960205078,\n",
       "   'val_rmse': 125.63169}],\n",
       " [{'epochs': 50, 'layer_count': 3, 'node_number': 80, 'dropout': 0.7},\n",
       "  {'loss': 36.23989139556885,\n",
       "   'rmse': 98.57724,\n",
       "   'val_loss': 102.6342544555664,\n",
       "   'val_rmse': 123.37259}],\n",
       " [{'epochs': 30, 'layer_count': 5, 'node_number': 80, 'dropout': 0.5},\n",
       "  {'loss': 56.10853096008301,\n",
       "   'rmse': 116.825905,\n",
       "   'val_loss': 103.5596923828125,\n",
       "   'val_rmse': 123.134415}],\n",
       " [{'epochs': 30, 'layer_count': 3, 'node_number': 100, 'dropout': 0.5},\n",
       "  {'loss': 41.06804061889648,\n",
       "   'rmse': 104.844246,\n",
       "   'val_loss': 103.82350158691406,\n",
       "   'val_rmse': 124.47607}],\n",
       " [{'epochs': 50, 'layer_count': 5, 'node_number': 80, 'dropout': 0.5},\n",
       "  {'loss': 38.331123428344725,\n",
       "   'rmse': 98.92881,\n",
       "   'val_loss': 104.74909973144531,\n",
       "   'val_rmse': 124.775246}],\n",
       " [{'epochs': 50, 'layer_count': 5, 'node_number': 60, 'dropout': 0.7},\n",
       "  {'loss': 39.020518417358396,\n",
       "   'rmse': 105.42285,\n",
       "   'val_loss': 105.23970031738281,\n",
       "   'val_rmse': 125.402374}],\n",
       " [{'epochs': 50, 'layer_count': 3, 'node_number': 100, 'dropout': 0.5},\n",
       "  {'loss': 33.35077041625976,\n",
       "   'rmse': 89.85271,\n",
       "   'val_loss': 105.9058609008789,\n",
       "   'val_rmse': 126.530876}],\n",
       " [{'epochs': 50, 'layer_count': 5, 'node_number': 60, 'dropout': 0.5},\n",
       "  {'loss': 45.33202499389648,\n",
       "   'rmse': 108.34803,\n",
       "   'val_loss': 107.12471771240234,\n",
       "   'val_rmse': 127.66102}],\n",
       " [{'epochs': 50, 'layer_count': 3, 'node_number': 80, 'dropout': 0.5},\n",
       "  {'loss': 36.07600700378418,\n",
       "   'rmse': 94.3145,\n",
       "   'val_loss': 107.12710571289062,\n",
       "   'val_rmse': 126.05893}],\n",
       " [{'epochs': 30, 'layer_count': 3, 'node_number': 100, 'dropout': 0.7},\n",
       "  {'loss': 47.421465759277346,\n",
       "   'rmse': 108.732,\n",
       "   'val_loss': 107.30828857421875,\n",
       "   'val_rmse': 135.78746}],\n",
       " [{'epochs': 30, 'layer_count': 3, 'node_number': 60, 'dropout': 0.5},\n",
       "  {'loss': 55.24233100891113,\n",
       "   'rmse': 124.21234,\n",
       "   'val_loss': 107.78038024902344,\n",
       "   'val_rmse': 131.23776}],\n",
       " [{'epochs': 50, 'layer_count': 4, 'node_number': 60, 'dropout': 0.5},\n",
       "  {'loss': 42.73431213378906,\n",
       "   'rmse': 104.425026,\n",
       "   'val_loss': 108.77364349365234,\n",
       "   'val_rmse': 130.88377}],\n",
       " [{'epochs': 30, 'layer_count': 4, 'node_number': 100, 'dropout': 0.7},\n",
       "  {'loss': 52.433025970458985,\n",
       "   'rmse': 114.10176,\n",
       "   'val_loss': 109.66228485107422,\n",
       "   'val_rmse': 132.23373}],\n",
       " [{'epochs': 30, 'layer_count': 4, 'node_number': 60, 'dropout': 0.5},\n",
       "  {'loss': 54.56562637329102,\n",
       "   'rmse': 116.84824,\n",
       "   'val_loss': 110.55964660644531,\n",
       "   'val_rmse': 135.63773}],\n",
       " [{'epochs': 50, 'layer_count': 4, 'node_number': 80, 'dropout': 0.7},\n",
       "  {'loss': 37.25129699707031,\n",
       "   'rmse': 103.83501,\n",
       "   'val_loss': 110.56967163085938,\n",
       "   'val_rmse': 137.27235}],\n",
       " [{'epochs': 50, 'layer_count': 4, 'node_number': 80, 'dropout': 0.5},\n",
       "  {'loss': 37.218818016052246,\n",
       "   'rmse': 96.629974,\n",
       "   'val_loss': 111.3173828125,\n",
       "   'val_rmse': 138.25035}],\n",
       " [{'epochs': 30, 'layer_count': 3, 'node_number': 80, 'dropout': 0.7},\n",
       "  {'loss': 47.57545616149903,\n",
       "   'rmse': 111.436134,\n",
       "   'val_loss': 111.47734069824219,\n",
       "   'val_rmse': 133.42876}],\n",
       " [{'epochs': 30, 'layer_count': 4, 'node_number': 80, 'dropout': 0.5},\n",
       "  {'loss': 82.79157196044922,\n",
       "   'rmse': 147.31607,\n",
       "   'val_loss': 112.19837951660156,\n",
       "   'val_rmse': 139.41505}],\n",
       " [{'epochs': 50, 'layer_count': 4, 'node_number': 100, 'dropout': 0.5},\n",
       "  {'loss': 38.789608039855956,\n",
       "   'rmse': 96.24689,\n",
       "   'val_loss': 114.97291564941406,\n",
       "   'val_rmse': 140.76332}],\n",
       " [{'epochs': 50, 'layer_count': 4, 'node_number': 100, 'dropout': 0.7},\n",
       "  {'loss': 36.20130237579346,\n",
       "   'rmse': 94.69749,\n",
       "   'val_loss': 119.90796661376953,\n",
       "   'val_rmse': 142.04839}],\n",
       " [{'epochs': 50, 'layer_count': 3, 'node_number': 60, 'dropout': 0.7},\n",
       "  {'loss': 41.16920761108398,\n",
       "   'rmse': 107.17056,\n",
       "   'val_loss': 122.08403015136719,\n",
       "   'val_rmse': 143.01869}],\n",
       " [{'epochs': 30, 'layer_count': 5, 'node_number': 60, 'dropout': 0.5},\n",
       "  {'loss': 73.359359664917,\n",
       "   'rmse': 132.92339,\n",
       "   'val_loss': 122.5522689819336,\n",
       "   'val_rmse': 149.7501}],\n",
       " [{'epochs': 50, 'layer_count': 3, 'node_number': 60, 'dropout': 0.5},\n",
       "  {'loss': 40.808185729980465,\n",
       "   'rmse': 104.179436,\n",
       "   'val_loss': 122.65337371826172,\n",
       "   'val_rmse': 142.87599}],\n",
       " [{'epochs': 50, 'layer_count': 5, 'node_number': 100, 'dropout': 0.7},\n",
       "  {'loss': 44.905558547973634,\n",
       "   'rmse': 107.66308,\n",
       "   'val_loss': 125.60595703125,\n",
       "   'val_rmse': 146.55627}],\n",
       " [{'epochs': 50, 'layer_count': 5, 'node_number': 100, 'dropout': 0.5},\n",
       "  {'loss': 35.803858070373536,\n",
       "   'rmse': 95.29581,\n",
       "   'val_loss': 126.18875885009766,\n",
       "   'val_rmse': 152.64163}],\n",
       " [{'epochs': 50, 'layer_count': 4, 'node_number': 60, 'dropout': 0.7},\n",
       "  {'loss': 128.3272090148926,\n",
       "   'rmse': 199.24406,\n",
       "   'val_loss': 162.93984985351562,\n",
       "   'val_rmse': 197.55469}],\n",
       " [{'epochs': 30, 'layer_count': 4, 'node_number': 100, 'dropout': 0.5},\n",
       "  {'loss': 283.1083571624756,\n",
       "   'rmse': 539.60815,\n",
       "   'val_loss': 181.86648559570312,\n",
       "   'val_rmse': 358.93573}]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8343a2e640a542c0b02de292a614ce67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=36.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[136, 181]\n",
      "[136, 181]\n",
      "[136, 181]\n",
      "[136, 181]\n",
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "[136, 181]\n",
      "[136, 181]\n",
      "[136, 181]\n",
      "[136, 181]\n",
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "[136, 181]\n",
      "[136, 181]\n",
      "[136, 181]\n",
      "[136, 181]\n",
      "[136, 181]\n",
      "[136, 181]\n",
      "[136, 181]\n",
      "[136, 181]\n",
      "[136, 181]\n",
      "[136, 181]\n",
      "[136, 181]\n",
      "[136, 181]\n",
      "[136, 181]\n",
      "[136, 181]\n",
      "[136, 181]\n",
      "[136, 181]\n",
      "[136, 181]\n",
      "[136, 181]\n",
      "[136, 181]\n",
      "[136, 181]\n",
      "[136, 181]\n",
      "[136, 181]\n",
      "[136, 181]\n",
      "[136, 181]\n",
      "[136, 181]\n",
      "[136, 181]\n",
      "[136, 181]\n",
      "[136, 181]\n",
      "[136, 181]\n",
      "[136, 181]\n",
      "[136, 181]\n",
      "[136, 181]\n",
      "[136, 181]\n",
      "[136, 181]\n",
      "[136, 181]\n",
      "[136, 181]\n",
      "[136, 181]\n",
      "[136, 181]\n",
      "[136, 181]\n",
      "[136, 181]\n",
      "[136, 181]\n",
      "[136, 181]\n",
      "[136, 181]\n",
      "[136, 181]\n",
      "[136, 181]\n",
      "[136, 181]\n",
      "[136, 181]\n",
      "[136, 181]\n",
      "[136, 181]\n",
      "[136, 181]\n",
      "[136, 181]\n",
      "[136, 181]\n",
      "[136, 181]\n",
      "[136, 181]\n",
      "[136, 181]\n",
      "[136, 181]\n",
      "[136, 181]\n",
      "[136, 181]\n",
      "[136, 181]\n",
      "[136, 181]\n",
      "[136, 181]\n",
      "[136, 181]\n",
      "[136, 181]\n",
      "[136, 181]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_dict = {\"epochs\":[30, 50], \"layer_count\":[3, 4, 5], \"node_number\":[60, 80, 100], \"dropout\":[0.5, 0.7]}\n",
    "\n",
    "grid_search.search(feature_dict, unievo_data, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'epochs': 30, 'layer_count': 5, 'node_number': 60, 'dropout': 0.5},\n",
       "  {'loss': 49.16347648620606,\n",
       "   'rmse': 111.650566,\n",
       "   'val_loss': 91.99232482910156,\n",
       "   'val_rmse': 114.38819}],\n",
       " [{'epochs': 30, 'layer_count': 5, 'node_number': 80, 'dropout': 0.7},\n",
       "  {'loss': 60.79417556762695,\n",
       "   'rmse': 121.694855,\n",
       "   'val_loss': 92.54352569580078,\n",
       "   'val_rmse': 113.08544}],\n",
       " [{'epochs': 30, 'layer_count': 3, 'node_number': 100, 'dropout': 0.7},\n",
       "  {'loss': 49.68187171936035,\n",
       "   'rmse': 106.38354,\n",
       "   'val_loss': 96.49043273925781,\n",
       "   'val_rmse': 119.60009}],\n",
       " [{'epochs': 30, 'layer_count': 4, 'node_number': 80, 'dropout': 0.7},\n",
       "  {'loss': 48.58590560913086,\n",
       "   'rmse': 108.54301,\n",
       "   'val_loss': 98.93069458007812,\n",
       "   'val_rmse': 121.50648}],\n",
       " [{'epochs': 50, 'layer_count': 3, 'node_number': 60, 'dropout': 0.7},\n",
       "  {'loss': 41.57910179138184,\n",
       "   'rmse': 103.59932,\n",
       "   'val_loss': 99.25018310546875,\n",
       "   'val_rmse': 122.40756}],\n",
       " [{'epochs': 30, 'layer_count': 5, 'node_number': 80, 'dropout': 0.5},\n",
       "  {'loss': 52.563844223022464,\n",
       "   'rmse': 113.67128,\n",
       "   'val_loss': 100.00529479980469,\n",
       "   'val_rmse': 120.91615}],\n",
       " [{'epochs': 30, 'layer_count': 3, 'node_number': 80, 'dropout': 0.5},\n",
       "  {'loss': 51.615981826782225,\n",
       "   'rmse': 111.862686,\n",
       "   'val_loss': 101.59333038330078,\n",
       "   'val_rmse': 123.10727}],\n",
       " [{'epochs': 50, 'layer_count': 5, 'node_number': 80, 'dropout': 0.7},\n",
       "  {'loss': 41.59498962402344,\n",
       "   'rmse': 103.19044,\n",
       "   'val_loss': 102.30077362060547,\n",
       "   'val_rmse': 126.53951}],\n",
       " [{'epochs': 50, 'layer_count': 4, 'node_number': 80, 'dropout': 0.5},\n",
       "  {'loss': 43.45781005859375,\n",
       "   'rmse': 108.69204,\n",
       "   'val_loss': 102.30188751220703,\n",
       "   'val_rmse': 124.26615}],\n",
       " [{'epochs': 30, 'layer_count': 4, 'node_number': 80, 'dropout': 0.5},\n",
       "  {'loss': 52.82712379455566,\n",
       "   'rmse': 113.031296,\n",
       "   'val_loss': 102.47264862060547,\n",
       "   'val_rmse': 124.38578}],\n",
       " [{'epochs': 30, 'layer_count': 3, 'node_number': 60, 'dropout': 0.5},\n",
       "  {'loss': 49.62088073730469,\n",
       "   'rmse': 110.725624,\n",
       "   'val_loss': 102.63919067382812,\n",
       "   'val_rmse': 127.52099}],\n",
       " [{'epochs': 30, 'layer_count': 4, 'node_number': 100, 'dropout': 0.5},\n",
       "  {'loss': 55.29493766784668,\n",
       "   'rmse': 112.81802,\n",
       "   'val_loss': 103.91422271728516,\n",
       "   'val_rmse': 128.14001}],\n",
       " [{'epochs': 30, 'layer_count': 4, 'node_number': 100, 'dropout': 0.7},\n",
       "  {'loss': 46.53829833984375,\n",
       "   'rmse': 102.5678,\n",
       "   'val_loss': 105.19416046142578,\n",
       "   'val_rmse': 128.15874}],\n",
       " [{'epochs': 50, 'layer_count': 3, 'node_number': 80, 'dropout': 0.7},\n",
       "  {'loss': 41.49958366394043,\n",
       "   'rmse': 101.82101,\n",
       "   'val_loss': 106.94819641113281,\n",
       "   'val_rmse': 132.33774}],\n",
       " [{'epochs': 50, 'layer_count': 3, 'node_number': 60, 'dropout': 0.5},\n",
       "  {'loss': 40.10296859741211,\n",
       "   'rmse': 105.22143,\n",
       "   'val_loss': 107.01387023925781,\n",
       "   'val_rmse': 131.75243}],\n",
       " [{'epochs': 50, 'layer_count': 4, 'node_number': 60, 'dropout': 0.7},\n",
       "  {'loss': 44.433249969482425,\n",
       "   'rmse': 107.2004,\n",
       "   'val_loss': 108.10940551757812,\n",
       "   'val_rmse': 134.11295}],\n",
       " [{'epochs': 50, 'layer_count': 4, 'node_number': 60, 'dropout': 0.5},\n",
       "  {'loss': 40.66736213684082,\n",
       "   'rmse': 103.631256,\n",
       "   'val_loss': 108.48201751708984,\n",
       "   'val_rmse': 132.89354}],\n",
       " [{'epochs': 50, 'layer_count': 5, 'node_number': 60, 'dropout': 0.7},\n",
       "  {'loss': 44.544614486694336,\n",
       "   'rmse': 108.472176,\n",
       "   'val_loss': 108.69893646240234,\n",
       "   'val_rmse': 132.05286}],\n",
       " [{'epochs': 50, 'layer_count': 3, 'node_number': 80, 'dropout': 0.5},\n",
       "  {'loss': 36.55480686187744,\n",
       "   'rmse': 93.08452,\n",
       "   'val_loss': 108.72737884521484,\n",
       "   'val_rmse': 131.40952}],\n",
       " [{'epochs': 30, 'layer_count': 4, 'node_number': 60, 'dropout': 0.7},\n",
       "  {'loss': 52.52147499084472,\n",
       "   'rmse': 113.27602,\n",
       "   'val_loss': 108.94243621826172,\n",
       "   'val_rmse': 135.43668}],\n",
       " [{'epochs': 50, 'layer_count': 3, 'node_number': 100, 'dropout': 0.7},\n",
       "  {'loss': 38.288934020996095,\n",
       "   'rmse': 97.06055,\n",
       "   'val_loss': 109.24234008789062,\n",
       "   'val_rmse': 133.65414}],\n",
       " [{'epochs': 50, 'layer_count': 5, 'node_number': 100, 'dropout': 0.5},\n",
       "  {'loss': 38.35109245300293,\n",
       "   'rmse': 96.96757,\n",
       "   'val_loss': 109.53096771240234,\n",
       "   'val_rmse': 130.95883}],\n",
       " [{'epochs': 50, 'layer_count': 4, 'node_number': 80, 'dropout': 0.7},\n",
       "  {'loss': 42.00069732666016,\n",
       "   'rmse': 105.411354,\n",
       "   'val_loss': 109.8795166015625,\n",
       "   'val_rmse': 132.53088}],\n",
       " [{'epochs': 50, 'layer_count': 5, 'node_number': 80, 'dropout': 0.5},\n",
       "  {'loss': 39.6432341003418,\n",
       "   'rmse': 103.00802,\n",
       "   'val_loss': 110.18292236328125,\n",
       "   'val_rmse': 135.01321}],\n",
       " [{'epochs': 50, 'layer_count': 5, 'node_number': 100, 'dropout': 0.7},\n",
       "  {'loss': 38.589520606994625,\n",
       "   'rmse': 96.16697,\n",
       "   'val_loss': 111.64995574951172,\n",
       "   'val_rmse': 141.38332}],\n",
       " [{'epochs': 30, 'layer_count': 3, 'node_number': 100, 'dropout': 0.5},\n",
       "  {'loss': 47.67840766906738,\n",
       "   'rmse': 108.7092,\n",
       "   'val_loss': 111.78092193603516,\n",
       "   'val_rmse': 137.39928}],\n",
       " [{'epochs': 50, 'layer_count': 5, 'node_number': 60, 'dropout': 0.5},\n",
       "  {'loss': 39.64915756225586,\n",
       "   'rmse': 103.200485,\n",
       "   'val_loss': 113.14244079589844,\n",
       "   'val_rmse': 134.04771}],\n",
       " [{'epochs': 30, 'layer_count': 3, 'node_number': 80, 'dropout': 0.7},\n",
       "  {'loss': 49.33099479675293,\n",
       "   'rmse': 111.73346,\n",
       "   'val_loss': 113.26567840576172,\n",
       "   'val_rmse': 135.50679}],\n",
       " [{'epochs': 30, 'layer_count': 4, 'node_number': 60, 'dropout': 0.5},\n",
       "  {'loss': 50.84608535766601,\n",
       "   'rmse': 112.27598,\n",
       "   'val_loss': 114.51477813720703,\n",
       "   'val_rmse': 139.40092}],\n",
       " [{'epochs': 30, 'layer_count': 5, 'node_number': 100, 'dropout': 0.7},\n",
       "  {'loss': 48.984889373779296,\n",
       "   'rmse': 110.15019,\n",
       "   'val_loss': 117.53404998779297,\n",
       "   'val_rmse': 143.5005}],\n",
       " [{'epochs': 50, 'layer_count': 3, 'node_number': 100, 'dropout': 0.5},\n",
       "  {'loss': 35.100968551635745,\n",
       "   'rmse': 90.30117,\n",
       "   'val_loss': 117.62207794189453,\n",
       "   'val_rmse': 141.4015}],\n",
       " [{'epochs': 50, 'layer_count': 4, 'node_number': 100, 'dropout': 0.5},\n",
       "  {'loss': 36.40964454650879,\n",
       "   'rmse': 88.98088,\n",
       "   'val_loss': 119.46725463867188,\n",
       "   'val_rmse': 147.4762}],\n",
       " [{'epochs': 50, 'layer_count': 4, 'node_number': 100, 'dropout': 0.7},\n",
       "  {'loss': 37.82442138671875,\n",
       "   'rmse': 96.36516,\n",
       "   'val_loss': 125.37772369384766,\n",
       "   'val_rmse': 149.83604}],\n",
       " [{'epochs': 30, 'layer_count': 5, 'node_number': 100, 'dropout': 0.5},\n",
       "  {'loss': 66.77556388854981,\n",
       "   'rmse': 125.85808,\n",
       "   'val_loss': 126.40670776367188,\n",
       "   'val_rmse': 150.36536}],\n",
       " [{'epochs': 30, 'layer_count': 5, 'node_number': 60, 'dropout': 0.7},\n",
       "  {'loss': 56.107684020996096,\n",
       "   'rmse': 116.952194,\n",
       "   'val_loss': 130.9766387939453,\n",
       "   'val_rmse': 159.9077}],\n",
       " [{'epochs': 30, 'layer_count': 3, 'node_number': 60, 'dropout': 0.7},\n",
       "  {'loss': 62.88592842102051,\n",
       "   'rmse': 122.81424,\n",
       "   'val_loss': 136.38955688476562,\n",
       "   'val_rmse': 163.13245}]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'epochs': 50, 'layer_count': 4, 'node_number': 80, 'dropout': 0.7},\n",
       "  {'RMSE': 162.35465398209146,\n",
       "   'MAE': 98.66833072296089,\n",
       "   'R2': 0.12723739996712005}],\n",
       " [{'epochs': 50, 'layer_count': 5, 'node_number': 80, 'dropout': 0.7},\n",
       "  {'RMSE': 167.96424522934947,\n",
       "   'MAE': 111.04613152448682,\n",
       "   'R2': 0.0717189666230026}],\n",
       " [{'epochs': 30, 'layer_count': 4, 'node_number': 80, 'dropout': 0.7},\n",
       "  {'RMSE': 169.5624757862915,\n",
       "   'MAE': 114.56481393091921,\n",
       "   'R2': 0.0519735506769354}],\n",
       " [{'epochs': 30, 'layer_count': 4, 'node_number': 80, 'dropout': 0.5},\n",
       "  {'RMSE': 178.52453876247571,\n",
       "   'MAE': 114.95373132738514,\n",
       "   'R2': -0.05765273791179789}],\n",
       " [{'epochs': 50, 'layer_count': 4, 'node_number': 80, 'dropout': 0.5},\n",
       "  {'RMSE': 169.96668573362294,\n",
       "   'MAE': 115.84041734709257,\n",
       "   'R2': 0.04534592232713058}],\n",
       " [{'epochs': 50, 'layer_count': 5, 'node_number': 80, 'dropout': 0.5},\n",
       "  {'RMSE': 170.70319108707923,\n",
       "   'MAE': 116.51601840102155,\n",
       "   'R2': 0.04077082728880005}],\n",
       " [{'epochs': 30, 'layer_count': 5, 'node_number': 80, 'dropout': 0.5},\n",
       "  {'RMSE': 172.90199000905795,\n",
       "   'MAE': 116.71214925724529,\n",
       "   'R2': 0.015994743835803998}],\n",
       " [{'epochs': 30, 'layer_count': 5, 'node_number': 80, 'dropout': 0.7},\n",
       "  {'RMSE': 170.50687251225253,\n",
       "   'MAE': 118.68897885861605,\n",
       "   'R2': 0.044506179600168}]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'epochs': 30, 'layer_count': 3, 'node_number': 80, 'dropout': 0.5},\n",
       "  {'RMSE': 156.89216176717633,\n",
       "   'MAE': 90.44141034889911,\n",
       "   'R2': 0.18229860225635006}],\n",
       " [{'epochs': 50, 'layer_count': 3, 'node_number': 80, 'dropout': 0.7},\n",
       "  {'RMSE': 160.75687936313233,\n",
       "   'MAE': 93.47899978402732,\n",
       "   'R2': 0.14363741376468986}],\n",
       " [{'epochs': 30, 'layer_count': 3, 'node_number': 80, 'dropout': 0.3},\n",
       "  {'RMSE': 161.24735397338654,\n",
       "   'MAE': 95.41294302629387,\n",
       "   'R2': 0.1369881539715284}],\n",
       " [{'epochs': 30, 'layer_count': 3, 'node_number': 50, 'dropout': 0.5},\n",
       "  {'RMSE': 160.3776318433857,\n",
       "   'MAE': 96.25941219191621,\n",
       "   'R2': 0.1456387522665716}],\n",
       " [{'epochs': 30, 'layer_count': 2, 'node_number': 50, 'dropout': 0.3},\n",
       "  {'RMSE': 161.92682414714625,\n",
       "   'MAE': 98.33593439796694,\n",
       "   'R2': 0.13022077235481136}],\n",
       " [{'epochs': 50, 'layer_count': 2, 'node_number': 50, 'dropout': 0.7},\n",
       "  {'RMSE': 164.11180620426185,\n",
       "   'MAE': 98.4271030322365,\n",
       "   'R2': 0.10759922701138487}],\n",
       " [{'epochs': 50, 'layer_count': 2, 'node_number': 80, 'dropout': 0.7},\n",
       "  {'RMSE': 160.8155830904763,\n",
       "   'MAE': 98.86028239346932,\n",
       "   'R2': 0.1437927042561851}],\n",
       " [{'epochs': 30, 'layer_count': 2, 'node_number': 80, 'dropout': 0.3},\n",
       "  {'RMSE': 165.40696398396938,\n",
       "   'MAE': 101.51846295163251,\n",
       "   'R2': 0.09411210731177357}],\n",
       " [{'epochs': 50, 'layer_count': 2, 'node_number': 80, 'dropout': 0.3},\n",
       "  {'RMSE': 167.91632869080476,\n",
       "   'MAE': 102.1557058147762,\n",
       "   'R2': 0.06530106280453914}],\n",
       " [{'epochs': 50, 'layer_count': 2, 'node_number': 80, 'dropout': 0.5},\n",
       "  {'RMSE': 161.25076585708698,\n",
       "   'MAE': 102.55057012862052,\n",
       "   'R2': 0.1385967746416932}],\n",
       " [{'epochs': 30, 'layer_count': 3, 'node_number': 50, 'dropout': 0.3},\n",
       "  {'RMSE': 166.65681262546835,\n",
       "   'MAE': 103.42430960786517,\n",
       "   'R2': 0.08161844673388062}],\n",
       " [{'epochs': 50, 'layer_count': 3, 'node_number': 50, 'dropout': 0.3},\n",
       "  {'RMSE': 167.12174773130178,\n",
       "   'MAE': 103.56173242952514,\n",
       "   'R2': 0.07742632809664822}],\n",
       " [{'epochs': 50, 'layer_count': 3, 'node_number': 80, 'dropout': 0.3},\n",
       "  {'RMSE': 167.53356174442254,\n",
       "   'MAE': 104.40744749013926,\n",
       "   'R2': 0.0700948971736352}],\n",
       " [{'epochs': 50, 'layer_count': 3, 'node_number': 80, 'dropout': 0.5},\n",
       "  {'RMSE': 168.00139981664583,\n",
       "   'MAE': 105.90289920482083,\n",
       "   'R2': 0.06681000736648003}],\n",
       " [{'epochs': 50, 'layer_count': 6, 'node_number': 80, 'dropout': 0.5},\n",
       "  {'RMSE': 169.82754896524054,\n",
       "   'MAE': 106.51226518119591,\n",
       "   'R2': 0.04524749711012801}],\n",
       " [{'epochs': 50, 'layer_count': 3, 'node_number': 50, 'dropout': 0.5},\n",
       "  {'RMSE': 165.03452151429164,\n",
       "   'MAE': 107.98819643863733,\n",
       "   'R2': 0.09901845837891883}],\n",
       " [{'epochs': 50, 'layer_count': 2, 'node_number': 50, 'dropout': 0.5},\n",
       "  {'RMSE': 172.44273172001425,\n",
       "   'MAE': 108.13066561671269,\n",
       "   'R2': 0.01648425563276612}],\n",
       " [{'epochs': 50, 'layer_count': 6, 'node_number': 80, 'dropout': 0.3},\n",
       "  {'RMSE': 170.01960844786578,\n",
       "   'MAE': 109.12530546991724,\n",
       "   'R2': 0.04253619232852444}],\n",
       " [{'epochs': 30, 'layer_count': 2, 'node_number': 80, 'dropout': 0.7},\n",
       "  {'RMSE': 174.7216528547985,\n",
       "   'MAE': 110.43198248268902,\n",
       "   'R2': -0.008823862377802824}],\n",
       " [{'epochs': 50, 'layer_count': 6, 'node_number': 50, 'dropout': 0.3},\n",
       "  {'RMSE': 168.0636519984302,\n",
       "   'MAE': 111.14929399628572,\n",
       "   'R2': 0.06686436394282107}],\n",
       " [{'epochs': 30, 'layer_count': 6, 'node_number': 80, 'dropout': 0.3},\n",
       "  {'RMSE': 169.80603619898216,\n",
       "   'MAE': 111.18326673991437,\n",
       "   'R2': 0.04757368873840262}],\n",
       " [{'epochs': 30, 'layer_count': 2, 'node_number': 50, 'dropout': 0.7},\n",
       "  {'RMSE': 167.43867349431352,\n",
       "   'MAE': 113.32066820259543,\n",
       "   'R2': 0.07582419316696758}],\n",
       " [{'epochs': 30, 'layer_count': 2, 'node_number': 80, 'dropout': 0.5},\n",
       "  {'RMSE': 178.29656515479138,\n",
       "   'MAE': 116.07157134837,\n",
       "   'R2': -0.049041260854233513}],\n",
       " [{'epochs': 50, 'layer_count': 6, 'node_number': 80, 'dropout': 0.7},\n",
       "  {'RMSE': 178.23923399517352,\n",
       "   'MAE': 123.9948805466942,\n",
       "   'R2': -0.04105106582706578}],\n",
       " [{'epochs': 50, 'layer_count': 3, 'node_number': 50, 'dropout': 0.7},\n",
       "  {'RMSE': 187.9233460748289,\n",
       "   'MAE': 131.15366207732671,\n",
       "   'R2': -0.161862889275611}],\n",
       " [{'epochs': 30, 'layer_count': 6, 'node_number': 80, 'dropout': 0.5},\n",
       "  {'RMSE': 180.86305953808173,\n",
       "   'MAE': 132.6768720530081,\n",
       "   'R2': -0.07247586356076592}],\n",
       " [{'epochs': 50, 'layer_count': 2, 'node_number': 50, 'dropout': 0.3},\n",
       "  {'RMSE': 173.6574445693807,\n",
       "   'MAE': 135.9227553796077,\n",
       "   'R2': 0.014157276523266668}],\n",
       " [{'epochs': 50, 'layer_count': 6, 'node_number': 50, 'dropout': 0.5},\n",
       "  {'RMSE': 187.59874255457774,\n",
       "   'MAE': 137.26988137286642,\n",
       "   'R2': -0.15153609457658562}],\n",
       " [{'epochs': 30, 'layer_count': 6, 'node_number': 50, 'dropout': 0.5},\n",
       "  {'RMSE': 188.90175903364099,\n",
       "   'MAE': 138.95992148095283,\n",
       "   'R2': -0.16828824594226477}],\n",
       " [{'epochs': 30, 'layer_count': 6, 'node_number': 50, 'dropout': 0.3},\n",
       "  {'RMSE': 199.94940970617677,\n",
       "   'MAE': 143.48165598554888,\n",
       "   'R2': -0.31004764995698436}],\n",
       " [{'epochs': 30, 'layer_count': 2, 'node_number': 50, 'dropout': 0.5},\n",
       "  {'RMSE': 189.67592594217948,\n",
       "   'MAE': 151.53860061756077,\n",
       "   'R2': -0.16941265667153418}],\n",
       " [{'epochs': 30, 'layer_count': 6, 'node_number': 80, 'dropout': 0.7},\n",
       "  {'RMSE': 204.09516416659915,\n",
       "   'MAE': 160.17001213198122,\n",
       "   'R2': -0.3457226378766695}],\n",
       " [{'epochs': 30, 'layer_count': 6, 'node_number': 50, 'dropout': 0.7},\n",
       "  {'RMSE': 226.0394211408613,\n",
       "   'MAE': 177.5531654027493,\n",
       "   'R2': -0.6699914983537248}],\n",
       " [{'epochs': 50, 'layer_count': 6, 'node_number': 50, 'dropout': 0.7},\n",
       "  {'RMSE': 235.06547428458137,\n",
       "   'MAE': 180.83893583822942,\n",
       "   'R2': -0.8335818730997507}],\n",
       " [{'epochs': 50, 'layer_count': 1, 'node_number': 80, 'dropout': 0.3},\n",
       "  {'RMSE': 228.5617804955659,\n",
       "   'MAE': 196.0960665440214,\n",
       "   'R2': -0.7037852337630852}],\n",
       " [{'epochs': 50, 'layer_count': 1, 'node_number': 80, 'dropout': 0.5},\n",
       "  {'RMSE': 232.5232715507873,\n",
       "   'MAE': 199.48275170809976,\n",
       "   'R2': -0.7634033909302969}],\n",
       " [{'epochs': 50, 'layer_count': 1, 'node_number': 80, 'dropout': 0.7},\n",
       "  {'RMSE': 233.33741791704577,\n",
       "   'MAE': 200.16736870917717,\n",
       "   'R2': -0.7757235384130025}],\n",
       " [{'epochs': 30, 'layer_count': 3, 'node_number': 80, 'dropout': 0.7},\n",
       "  {'RMSE': 267.65299425654143,\n",
       "   'MAE': 219.34332022060087,\n",
       "   'R2': -1.3490093216628818}],\n",
       " [{'epochs': 30, 'layer_count': 3, 'node_number': 50, 'dropout': 0.7},\n",
       "  {'RMSE': 281.10751953020554,\n",
       "   'MAE': 226.2695869298085,\n",
       "   'R2': -1.6108854547051619}],\n",
       " [{'epochs': 50, 'layer_count': 1, 'node_number': 50, 'dropout': 0.5},\n",
       "  {'RMSE': 282.4616190368352,\n",
       "   'MAE': 242.76455515709475,\n",
       "   'R2': -1.6032794129738068}],\n",
       " [{'epochs': 50, 'layer_count': 1, 'node_number': 50, 'dropout': 0.7},\n",
       "  {'RMSE': 283.5067611253653,\n",
       "   'MAE': 243.79508105568263,\n",
       "   'R2': -1.622333539798025}],\n",
       " [{'epochs': 30, 'layer_count': 1, 'node_number': 80, 'dropout': 0.5},\n",
       "  {'RMSE': 284.77767639487524,\n",
       "   'MAE': 244.92173515540966,\n",
       "   'R2': -1.6458911066651984}],\n",
       " [{'epochs': 30, 'layer_count': 1, 'node_number': 80, 'dropout': 0.3},\n",
       "  {'RMSE': 285.67065767140116,\n",
       "   'MAE': 245.75630434008613,\n",
       "   'R2': -1.662761598046412}],\n",
       " [{'epochs': 30, 'layer_count': 1, 'node_number': 80, 'dropout': 0.7},\n",
       "  {'RMSE': 286.40514643162254,\n",
       "   'MAE': 246.41215755628505,\n",
       "   'R2': -1.676086194846403}],\n",
       " [{'epochs': 50, 'layer_count': 1, 'node_number': 50, 'dropout': 0.3},\n",
       "  {'RMSE': 286.501266095742,\n",
       "   'MAE': 246.50420813629592,\n",
       "   'R2': -1.6777716624806678}],\n",
       " [{'epochs': 30, 'layer_count': 1, 'node_number': 50, 'dropout': 0.3},\n",
       "  {'RMSE': 321.06560049597914,\n",
       "   'MAE': 277.18326156726783,\n",
       "   'R2': -2.363419806156968}],\n",
       " [{'epochs': 30, 'layer_count': 1, 'node_number': 50, 'dropout': 0.7},\n",
       "  {'RMSE': 321.6602390898192,\n",
       "   'MAE': 277.7253270218338,\n",
       "   'R2': -2.375736182257942}],\n",
       " [{'epochs': 30, 'layer_count': 1, 'node_number': 50, 'dropout': 0.5},\n",
       "  {'RMSE': 322.5339717265704,\n",
       "   'MAE': 278.5223531446596,\n",
       "   'R2': -2.394378891834706}]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluations on Modo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aadac311cef64e6aaa9ba9284dd9703c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=48.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Train for 50 steps, validate for 50 steps\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "50/50 [==============================] - 20s 403ms/step - loss: 27.7333 - rmse: 39.0025 - val_loss: 31.9094 - val_rmse: 39.5464\n",
      "Epoch 2/20\n",
      "50/50 [==============================] - 13s 253ms/step - loss: 19.9862 - rmse: 31.1699 - val_loss: 33.2806 - val_rmse: 40.8856\n",
      "Epoch 3/20\n",
      "50/50 [==============================] - 13s 251ms/step - loss: 16.3877 - rmse: 28.6879 - val_loss: 17.0891 - val_rmse: 23.2675\n",
      "Epoch 4/20\n",
      "50/50 [==============================] - 11s 224ms/step - loss: 13.5137 - rmse: 26.3941 - val_loss: 19.9522 - val_rmse: 26.1082\n",
      "Epoch 5/20\n",
      "50/50 [==============================] - 11s 214ms/step - loss: 11.9810 - rmse: 25.1765 - val_loss: 14.9616 - val_rmse: 20.7518\n",
      "Epoch 6/20\n",
      "50/50 [==============================] - 11s 224ms/step - loss: 10.7354 - rmse: 24.0703 - val_loss: 16.8574 - val_rmse: 22.9561\n",
      "Epoch 7/20\n",
      "50/50 [==============================] - 11s 220ms/step - loss: 10.0270 - rmse: 23.5015 - val_loss: 16.3506 - val_rmse: 22.2929\n",
      "Epoch 8/20\n",
      "50/50 [==============================] - 11s 221ms/step - loss: 9.4813 - rmse: 23.0526 - val_loss: 10.9214 - val_rmse: 16.1193\n",
      "Epoch 9/20\n",
      "50/50 [==============================] - 11s 220ms/step - loss: 9.0155 - rmse: 22.6677 - val_loss: 10.4668 - val_rmse: 15.6320\n",
      "Epoch 10/20\n",
      "50/50 [==============================] - 11s 220ms/step - loss: 8.7391 - rmse: 22.4526 - val_loss: 10.1280 - val_rmse: 15.3792\n",
      "Epoch 11/20\n",
      "50/50 [==============================] - 11s 214ms/step - loss: 8.3853 - rmse: 22.1854 - val_loss: 11.7740 - val_rmse: 16.7144\n",
      "Epoch 12/20\n",
      "50/50 [==============================] - 11s 220ms/step - loss: 8.1354 - rmse: 21.9902 - val_loss: 11.3095 - val_rmse: 16.4034\n",
      "Epoch 13/20\n",
      "50/50 [==============================] - 11s 221ms/step - loss: 7.9227 - rmse: 21.8740 - val_loss: 9.6409 - val_rmse: 14.5927\n",
      "Epoch 14/20\n",
      "50/50 [==============================] - 11s 219ms/step - loss: 7.6765 - rmse: 21.7045 - val_loss: 11.5782 - val_rmse: 16.4213\n",
      "Epoch 15/20\n",
      "50/50 [==============================] - 11s 214ms/step - loss: 7.5465 - rmse: 21.5883 - val_loss: 11.0016 - val_rmse: 16.2466\n",
      "Epoch 16/20\n",
      "50/50 [==============================] - 11s 220ms/step - loss: 7.3283 - rmse: 21.4288 - val_loss: 12.4284 - val_rmse: 17.5639\n",
      "Epoch 17/20\n",
      "50/50 [==============================] - 11s 224ms/step - loss: 7.2289 - rmse: 21.3098 - val_loss: 11.0389 - val_rmse: 16.3670\n",
      "Epoch 18/20\n",
      "50/50 [==============================] - 11s 226ms/step - loss: 7.0174 - rmse: 21.1607 - val_loss: 10.9937 - val_rmse: 16.0578\n",
      "Epoch 19/20\n",
      "50/50 [==============================] - 13s 251ms/step - loss: 6.8720 - rmse: 20.9928 - val_loss: 11.4355 - val_rmse: 16.6673\n",
      "Epoch 20/20\n",
      "50/50 [==============================] - 12s 238ms/step - loss: 6.6967 - rmse: 20.8741 - val_loss: 9.7200 - val_rmse: 14.8739\n",
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Train for 50 steps, validate for 50 steps\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "50/50 [==============================] - 17s 344ms/step - loss: 30.4106 - rmse: 41.9434 - val_loss: 25.8291 - val_rmse: 32.7350\n",
      "Epoch 2/20\n",
      "50/50 [==============================] - 12s 238ms/step - loss: 19.3523 - rmse: 30.8096 - val_loss: 25.2000 - val_rmse: 31.6933\n",
      "Epoch 3/20\n",
      "50/50 [==============================] - 13s 251ms/step - loss: 14.8640 - rmse: 27.6064 - val_loss: 11.1194 - val_rmse: 15.4720\n",
      "Epoch 4/20\n",
      "50/50 [==============================] - 11s 226ms/step - loss: 12.3431 - rmse: 25.5985 - val_loss: 10.2367 - val_rmse: 13.9867\n",
      "Epoch 5/20\n",
      "50/50 [==============================] - 11s 222ms/step - loss: 10.6853 - rmse: 24.2317 - val_loss: 10.7137 - val_rmse: 15.1554\n",
      "Epoch 6/20\n",
      "50/50 [==============================] - 11s 222ms/step - loss: 9.9101 - rmse: 23.6132 - val_loss: 13.5753 - val_rmse: 18.9113\n",
      "Epoch 7/20\n",
      "50/50 [==============================] - 11s 221ms/step - loss: 9.3299 - rmse: 23.1692 - val_loss: 9.0647 - val_rmse: 13.3933\n",
      "Epoch 8/20\n",
      "50/50 [==============================] - 11s 225ms/step - loss: 8.9656 - rmse: 22.8932 - val_loss: 12.0306 - val_rmse: 16.2600\n",
      "Epoch 9/20\n",
      "50/50 [==============================] - 11s 226ms/step - loss: 8.6648 - rmse: 22.6322 - val_loss: 10.1508 - val_rmse: 14.9584\n",
      "Epoch 10/20\n",
      "50/50 [==============================] - 11s 219ms/step - loss: 8.3629 - rmse: 22.4075 - val_loss: 8.8418 - val_rmse: 13.2184\n",
      "Epoch 11/20\n",
      "50/50 [==============================] - 11s 223ms/step - loss: 8.1479 - rmse: 22.2201 - val_loss: 11.6734 - val_rmse: 16.6916\n",
      "Epoch 12/20\n",
      "50/50 [==============================] - 11s 226ms/step - loss: 7.8751 - rmse: 22.0085 - val_loss: 9.7153 - val_rmse: 14.3782\n",
      "Epoch 13/20\n",
      "50/50 [==============================] - 11s 221ms/step - loss: 7.6804 - rmse: 21.8149 - val_loss: 11.3266 - val_rmse: 15.8514\n",
      "Epoch 14/20\n",
      "50/50 [==============================] - 11s 221ms/step - loss: 7.4607 - rmse: 21.6563 - val_loss: 10.5356 - val_rmse: 14.6005\n",
      "Epoch 15/20\n",
      "50/50 [==============================] - 11s 224ms/step - loss: 7.2295 - rmse: 21.4045 - val_loss: 10.9103 - val_rmse: 15.7121\n",
      "Epoch 16/20\n",
      "50/50 [==============================] - 11s 221ms/step - loss: 7.1225 - rmse: 21.2683 - val_loss: 9.5961 - val_rmse: 13.6729\n",
      "Epoch 17/20\n",
      "50/50 [==============================] - 11s 216ms/step - loss: 6.9240 - rmse: 21.1218 - val_loss: 8.9954 - val_rmse: 13.7419\n",
      "Epoch 18/20\n",
      "50/50 [==============================] - 11s 228ms/step - loss: 6.7572 - rmse: 20.9476 - val_loss: 8.7675 - val_rmse: 13.2228\n",
      "Epoch 19/20\n",
      "50/50 [==============================] - 12s 241ms/step - loss: 6.6023 - rmse: 20.8205 - val_loss: 10.3944 - val_rmse: 15.2798\n",
      "Epoch 20/20\n",
      "50/50 [==============================] - 13s 266ms/step - loss: 6.4544 - rmse: 20.6394 - val_loss: 8.9990 - val_rmse: 13.7630\n",
      "Train for 50 steps, validate for 50 steps\n",
      "Epoch 1/20\n",
      "50/50 [==============================] - 21s 419ms/step - loss: 46.3934 - rmse: 60.0927 - val_loss: 35.1050 - val_rmse: 43.1950\n",
      "Epoch 2/20\n",
      "50/50 [==============================] - 16s 312ms/step - loss: 25.8086 - rmse: 36.6335 - val_loss: 20.6291 - val_rmse: 26.4376\n",
      "Epoch 3/20\n",
      "50/50 [==============================] - 15s 291ms/step - loss: 23.2322 - rmse: 33.9986 - val_loss: 20.3813 - val_rmse: 26.1249\n",
      "Epoch 4/20\n",
      "50/50 [==============================] - 14s 287ms/step - loss: 19.1047 - rmse: 30.4947 - val_loss: 15.1024 - val_rmse: 20.1352\n",
      "Epoch 5/20\n",
      "50/50 [==============================] - 15s 293ms/step - loss: 16.3405 - rmse: 28.7279 - val_loss: 12.7544 - val_rmse: 17.5220\n",
      "Epoch 6/20\n",
      "50/50 [==============================] - 15s 292ms/step - loss: 13.6222 - rmse: 26.5607 - val_loss: 13.1557 - val_rmse: 18.0733\n",
      "Epoch 7/20\n",
      "50/50 [==============================] - 15s 295ms/step - loss: 11.9661 - rmse: 25.0887 - val_loss: 18.4650 - val_rmse: 24.7736\n",
      "Epoch 8/20\n",
      "50/50 [==============================] - 14s 287ms/step - loss: 10.9584 - rmse: 24.2444 - val_loss: 12.1876 - val_rmse: 17.0476\n",
      "Epoch 9/20\n",
      "50/50 [==============================] - 14s 286ms/step - loss: 10.3681 - rmse: 23.7999 - val_loss: 11.5178 - val_rmse: 16.5661\n",
      "Epoch 10/20\n",
      "50/50 [==============================] - 15s 291ms/step - loss: 9.7786 - rmse: 23.3804 - val_loss: 11.9510 - val_rmse: 17.0710\n",
      "Epoch 11/20\n",
      "50/50 [==============================] - 14s 289ms/step - loss: 9.4235 - rmse: 23.1220 - val_loss: 10.9876 - val_rmse: 15.6738\n",
      "Epoch 12/20\n",
      "50/50 [==============================] - 15s 294ms/step - loss: 9.0576 - rmse: 22.9018 - val_loss: 10.9648 - val_rmse: 15.4073\n",
      "Epoch 13/20\n",
      "50/50 [==============================] - 15s 290ms/step - loss: 8.7463 - rmse: 22.6011 - val_loss: 9.8896 - val_rmse: 14.3891\n",
      "Epoch 14/20\n",
      "50/50 [==============================] - 15s 297ms/step - loss: 8.5278 - rmse: 22.4337 - val_loss: 10.1175 - val_rmse: 14.9028\n",
      "Epoch 15/20\n",
      "50/50 [==============================] - 14s 289ms/step - loss: 8.3061 - rmse: 22.2254 - val_loss: 12.2133 - val_rmse: 17.2164\n",
      "Epoch 16/20\n",
      "50/50 [==============================] - 14s 288ms/step - loss: 8.1041 - rmse: 22.0403 - val_loss: 11.0010 - val_rmse: 15.7739\n",
      "Epoch 17/20\n",
      "50/50 [==============================] - 14s 284ms/step - loss: 7.8612 - rmse: 21.8003 - val_loss: 10.4170 - val_rmse: 15.4501\n",
      "Epoch 18/20\n",
      "50/50 [==============================] - 14s 281ms/step - loss: 7.6705 - rmse: 21.6504 - val_loss: 10.4084 - val_rmse: 15.2082\n",
      "Epoch 19/20\n",
      "50/50 [==============================] - 15s 292ms/step - loss: 7.4559 - rmse: 21.4467 - val_loss: 10.5672 - val_rmse: 15.8749\n",
      "Epoch 20/20\n",
      "50/50 [==============================] - 15s 290ms/step - loss: 7.2885 - rmse: 21.2214 - val_loss: 10.1023 - val_rmse: 15.3027\n",
      "Train for 50 steps, validate for 50 steps\n",
      "Epoch 1/20\n",
      "50/50 [==============================] - 22s 435ms/step - loss: 10134.3662 - rmse: 13188.3301 - val_loss: 1046.8116 - val_rmse: 1285.8396\n",
      "Epoch 2/20\n",
      "50/50 [==============================] - 16s 326ms/step - loss: 2278.3954 - rmse: 2813.0679 - val_loss: 1233.7852 - val_rmse: 1566.8079\n",
      "Epoch 3/20\n",
      "50/50 [==============================] - 17s 337ms/step - loss: 360.0416 - rmse: 469.5666 - val_loss: 111.9856 - val_rmse: 134.7602\n",
      "Epoch 4/20\n",
      "50/50 [==============================] - 17s 336ms/step - loss: 88.8202 - rmse: 110.7591 - val_loss: 31.0059 - val_rmse: 38.5935\n",
      "Epoch 5/20\n",
      "50/50 [==============================] - 17s 338ms/step - loss: 23.0683 - rmse: 34.1286 - val_loss: 35.6346 - val_rmse: 43.6779\n",
      "Epoch 6/20\n",
      "50/50 [==============================] - 17s 336ms/step - loss: 19.9742 - rmse: 31.6875 - val_loss: 28.9298 - val_rmse: 36.0003\n",
      "Epoch 7/20\n",
      "50/50 [==============================] - 17s 337ms/step - loss: 17.4280 - rmse: 29.6774 - val_loss: 19.9077 - val_rmse: 25.4998\n",
      "Epoch 8/20\n",
      "50/50 [==============================] - 17s 336ms/step - loss: 14.6346 - rmse: 27.5809 - val_loss: 15.8627 - val_rmse: 20.5820\n",
      "Epoch 9/20\n",
      "50/50 [==============================] - 17s 349ms/step - loss: 12.6257 - rmse: 25.9290 - val_loss: 14.2193 - val_rmse: 18.7117\n",
      "Epoch 10/20\n",
      "50/50 [==============================] - 17s 349ms/step - loss: 11.2547 - rmse: 24.6834 - val_loss: 11.7129 - val_rmse: 15.8688\n",
      "Epoch 11/20\n",
      "50/50 [==============================] - 17s 344ms/step - loss: 10.2948 - rmse: 23.8879 - val_loss: 12.5189 - val_rmse: 17.3023\n",
      "Epoch 12/20\n",
      "50/50 [==============================] - 17s 338ms/step - loss: 9.6788 - rmse: 23.3082 - val_loss: 16.3845 - val_rmse: 21.9474\n",
      "Epoch 13/20\n",
      "50/50 [==============================] - 17s 338ms/step - loss: 9.1803 - rmse: 22.9619 - val_loss: 11.9287 - val_rmse: 16.4160\n",
      "Epoch 14/20\n",
      "50/50 [==============================] - 17s 340ms/step - loss: 8.8509 - rmse: 22.6874 - val_loss: 13.8375 - val_rmse: 18.8286\n",
      "Epoch 15/20\n",
      "50/50 [==============================] - 17s 340ms/step - loss: 8.4068 - rmse: 22.3365 - val_loss: 11.6879 - val_rmse: 16.2552\n",
      "Epoch 16/20\n",
      "50/50 [==============================] - 17s 338ms/step - loss: 8.2658 - rmse: 22.1596 - val_loss: 11.2982 - val_rmse: 16.6467\n",
      "Epoch 17/20\n",
      "50/50 [==============================] - 17s 340ms/step - loss: 7.9785 - rmse: 21.9029 - val_loss: 13.2131 - val_rmse: 18.4772\n",
      "Epoch 18/20\n",
      "50/50 [==============================] - 17s 339ms/step - loss: 7.7502 - rmse: 21.6928 - val_loss: 11.1567 - val_rmse: 16.1216\n",
      "Epoch 19/20\n",
      "50/50 [==============================] - 17s 339ms/step - loss: 7.4656 - rmse: 21.4270 - val_loss: 10.6075 - val_rmse: 15.6822\n",
      "Epoch 20/20\n",
      "50/50 [==============================] - 17s 338ms/step - loss: 7.3392 - rmse: 21.3306 - val_loss: 10.0920 - val_rmse: 14.8645\n",
      "Train for 50 steps, validate for 50 steps\n",
      "Epoch 1/20\n",
      "50/50 [==============================] - 29s 589ms/step - loss: 9870.1713 - rmse: 15607.2139 - val_loss: 907.1932 - val_rmse: 1064.7917\n",
      "Epoch 2/20\n",
      "50/50 [==============================] - 24s 470ms/step - loss: 1213.1909 - rmse: 1470.7137 - val_loss: 186.0076 - val_rmse: 220.7881\n",
      "Epoch 3/20\n",
      "50/50 [==============================] - 24s 477ms/step - loss: 172.7938 - rmse: 210.9625 - val_loss: 25.5095 - val_rmse: 31.6872\n",
      "Epoch 4/20\n",
      "50/50 [==============================] - 23s 465ms/step - loss: 22.0614 - rmse: 32.6796 - val_loss: 19.9010 - val_rmse: 25.0212\n",
      "Epoch 5/20\n",
      "50/50 [==============================] - 24s 473ms/step - loss: 19.0897 - rmse: 30.4821 - val_loss: 22.0027 - val_rmse: 27.8247\n",
      "Epoch 6/20\n",
      "50/50 [==============================] - 24s 470ms/step - loss: 20.9420 - rmse: 33.3374 - val_loss: 13.8786 - val_rmse: 18.0165\n",
      "Epoch 7/20\n",
      "50/50 [==============================] - 24s 474ms/step - loss: 17.0579 - rmse: 29.3694 - val_loss: 19.5082 - val_rmse: 25.2175\n",
      "Epoch 8/20\n",
      "50/50 [==============================] - 24s 487ms/step - loss: 15.8550 - rmse: 28.4055 - val_loss: 19.3855 - val_rmse: 25.1725\n",
      "Epoch 9/20\n",
      "50/50 [==============================] - 24s 477ms/step - loss: 13.7966 - rmse: 26.7045 - val_loss: 17.7226 - val_rmse: 23.2894\n",
      "Epoch 10/20\n",
      "50/50 [==============================] - 24s 476ms/step - loss: 12.0783 - rmse: 25.1784 - val_loss: 11.7601 - val_rmse: 16.6521\n",
      "Epoch 11/20\n",
      "50/50 [==============================] - 24s 483ms/step - loss: 11.1925 - rmse: 24.3137 - val_loss: 10.2445 - val_rmse: 14.7282\n",
      "Epoch 12/20\n",
      "50/50 [==============================] - 25s 510ms/step - loss: 10.4032 - rmse: 23.7241 - val_loss: 10.1646 - val_rmse: 14.4650\n",
      "Epoch 13/20\n",
      "50/50 [==============================] - 25s 493ms/step - loss: 9.8810 - rmse: 23.2681 - val_loss: 12.7909 - val_rmse: 17.9351\n",
      "Epoch 14/20\n",
      "50/50 [==============================] - 24s 478ms/step - loss: 9.3498 - rmse: 22.9285 - val_loss: 9.9240 - val_rmse: 14.1274\n",
      "Epoch 15/20\n",
      "50/50 [==============================] - 25s 492ms/step - loss: 9.0312 - rmse: 22.6836 - val_loss: 12.2045 - val_rmse: 17.0751\n",
      "Epoch 16/20\n",
      "50/50 [==============================] - 24s 484ms/step - loss: 8.8682 - rmse: 22.5505 - val_loss: 9.6732 - val_rmse: 14.0569\n",
      "Epoch 17/20\n",
      "50/50 [==============================] - 24s 486ms/step - loss: 8.4528 - rmse: 22.2209 - val_loss: 13.1700 - val_rmse: 18.3291\n",
      "Epoch 18/20\n",
      "50/50 [==============================] - 24s 484ms/step - loss: 8.2468 - rmse: 22.0374 - val_loss: 11.4086 - val_rmse: 16.0601\n",
      "Epoch 19/20\n",
      "50/50 [==============================] - 26s 513ms/step - loss: 8.0301 - rmse: 21.8242 - val_loss: 10.2717 - val_rmse: 15.5173\n",
      "Epoch 20/20\n",
      "50/50 [==============================] - 24s 481ms/step - loss: 7.8425 - rmse: 21.6718 - val_loss: 11.6501 - val_rmse: 16.8873\n",
      "Train for 50 steps, validate for 50 steps\n",
      "Epoch 1/20\n",
      "50/50 [==============================] - 29s 587ms/step - loss: 40.4693 - rmse: 55.1674 - val_loss: 28.5550 - val_rmse: 35.9129\n",
      "Epoch 2/20\n",
      "50/50 [==============================] - 24s 480ms/step - loss: 20.6897 - rmse: 32.3137 - val_loss: 32.7121 - val_rmse: 40.3251\n",
      "Epoch 3/20\n",
      "50/50 [==============================] - 24s 475ms/step - loss: 19.1410 - rmse: 31.4805 - val_loss: 23.1445 - val_rmse: 29.5963\n",
      "Epoch 4/20\n",
      "50/50 [==============================] - 24s 483ms/step - loss: 15.0788 - rmse: 27.9321 - val_loss: 11.5571 - val_rmse: 15.9879\n",
      "Epoch 5/20\n",
      "50/50 [==============================] - 23s 469ms/step - loss: 12.4829 - rmse: 25.6340 - val_loss: 12.4220 - val_rmse: 17.4716\n",
      "Epoch 6/20\n",
      "50/50 [==============================] - 24s 481ms/step - loss: 10.9588 - rmse: 24.3626 - val_loss: 13.2546 - val_rmse: 18.2754\n",
      "Epoch 7/20\n",
      "50/50 [==============================] - 26s 521ms/step - loss: 10.2452 - rmse: 23.7284 - val_loss: 12.0176 - val_rmse: 16.4547\n",
      "Epoch 8/20\n",
      "50/50 [==============================] - 27s 537ms/step - loss: 9.5744 - rmse: 23.2098 - val_loss: 10.3302 - val_rmse: 15.3134\n",
      "Epoch 9/20\n",
      "50/50 [==============================] - 24s 487ms/step - loss: 9.1767 - rmse: 22.8842 - val_loss: 9.0099 - val_rmse: 13.5963\n",
      "Epoch 10/20\n",
      "50/50 [==============================] - 24s 476ms/step - loss: 8.7881 - rmse: 22.5606 - val_loss: 9.6752 - val_rmse: 14.4231\n",
      "Epoch 11/20\n",
      "50/50 [==============================] - 24s 471ms/step - loss: 8.4868 - rmse: 22.3124 - val_loss: 11.1742 - val_rmse: 16.5500\n",
      "Epoch 12/20\n",
      "50/50 [==============================] - 23s 463ms/step - loss: 8.1631 - rmse: 22.0573 - val_loss: 10.8482 - val_rmse: 15.2220\n",
      "Epoch 13/20\n",
      "50/50 [==============================] - 23s 465ms/step - loss: 7.9683 - rmse: 21.8925 - val_loss: 9.2365 - val_rmse: 13.7555\n",
      "Epoch 14/20\n",
      "50/50 [==============================] - 23s 465ms/step - loss: 7.6930 - rmse: 21.6165 - val_loss: 9.3771 - val_rmse: 14.1909\n",
      "Epoch 15/20\n",
      "50/50 [==============================] - 23s 461ms/step - loss: 7.3810 - rmse: 21.3228 - val_loss: 11.7964 - val_rmse: 16.7298\n",
      "Epoch 16/20\n",
      "50/50 [==============================] - 23s 468ms/step - loss: 7.1301 - rmse: 21.0876 - val_loss: 11.0342 - val_rmse: 15.6425\n",
      "Epoch 17/20\n",
      "50/50 [==============================] - 24s 474ms/step - loss: 6.9470 - rmse: 20.8126 - val_loss: 12.3306 - val_rmse: 16.9602\n",
      "Epoch 18/20\n",
      "50/50 [==============================] - 24s 474ms/step - loss: 6.8161 - rmse: 20.4990 - val_loss: 9.2252 - val_rmse: 14.2014\n",
      "Epoch 19/20\n",
      "50/50 [==============================] - 23s 466ms/step - loss: 6.5141 - rmse: 20.0659 - val_loss: 10.4321 - val_rmse: 15.5964\n",
      "Epoch 20/20\n",
      "50/50 [==============================] - 23s 469ms/step - loss: 6.3014 - rmse: 19.7002 - val_loss: 9.3728 - val_rmse: 14.2674\n",
      "Train for 50 steps, validate for 50 steps\n",
      "Epoch 1/20\n",
      "50/50 [==============================] - 27s 547ms/step - loss: 629.7514 - rmse: 859.1531 - val_loss: 87.7671 - val_rmse: 123.3496\n",
      "Epoch 2/20\n",
      "50/50 [==============================] - 21s 418ms/step - loss: 69.1125 - rmse: 94.8371 - val_loss: 27.5588 - val_rmse: 34.4102\n",
      "Epoch 3/20\n",
      "50/50 [==============================] - 21s 421ms/step - loss: 23.2732 - rmse: 34.4477 - val_loss: 21.5801 - val_rmse: 27.6793\n",
      "Epoch 4/20\n",
      "50/50 [==============================] - 21s 421ms/step - loss: 24.4766 - rmse: 36.1222 - val_loss: 30.0031 - val_rmse: 37.2137\n",
      "Epoch 5/20\n",
      "50/50 [==============================] - 21s 421ms/step - loss: 20.2760 - rmse: 31.7800 - val_loss: 19.8246 - val_rmse: 26.2437\n",
      "Epoch 6/20\n",
      "50/50 [==============================] - 21s 419ms/step - loss: 17.3261 - rmse: 29.6465 - val_loss: 17.3809 - val_rmse: 22.7553\n",
      "Epoch 7/20\n",
      "50/50 [==============================] - 21s 419ms/step - loss: 13.9950 - rmse: 26.9880 - val_loss: 14.7212 - val_rmse: 19.9456\n",
      "Epoch 8/20\n",
      "50/50 [==============================] - 21s 430ms/step - loss: 12.1664 - rmse: 25.3895 - val_loss: 12.7940 - val_rmse: 16.7473\n",
      "Epoch 9/20\n",
      "50/50 [==============================] - 21s 420ms/step - loss: 11.1055 - rmse: 24.4365 - val_loss: 11.7181 - val_rmse: 16.5500\n",
      "Epoch 10/20\n",
      "50/50 [==============================] - 21s 422ms/step - loss: 10.3136 - rmse: 23.8315 - val_loss: 10.2704 - val_rmse: 14.7201\n",
      "Epoch 11/20\n",
      "50/50 [==============================] - 21s 423ms/step - loss: 9.8544 - rmse: 23.4062 - val_loss: 11.3561 - val_rmse: 15.8931\n",
      "Epoch 12/20\n",
      "50/50 [==============================] - 21s 420ms/step - loss: 9.4851 - rmse: 23.1594 - val_loss: 9.6594 - val_rmse: 14.1060\n",
      "Epoch 13/20\n",
      "50/50 [==============================] - 21s 420ms/step - loss: 8.9574 - rmse: 22.7286 - val_loss: 13.4450 - val_rmse: 18.5050\n",
      "Epoch 14/20\n",
      "50/50 [==============================] - 21s 420ms/step - loss: 8.8297 - rmse: 22.6063 - val_loss: 11.2981 - val_rmse: 15.9674\n",
      "Epoch 15/20\n",
      "50/50 [==============================] - 21s 419ms/step - loss: 8.6893 - rmse: 22.7241 - val_loss: 9.6298 - val_rmse: 14.2856\n",
      "Epoch 16/20\n",
      "50/50 [==============================] - 21s 415ms/step - loss: 8.3079 - rmse: 22.1785 - val_loss: 10.3553 - val_rmse: 15.6401\n",
      "Epoch 17/20\n",
      "50/50 [==============================] - 21s 421ms/step - loss: 8.0693 - rmse: 21.9953 - val_loss: 11.7395 - val_rmse: 17.2830\n",
      "Epoch 18/20\n",
      "50/50 [==============================] - 21s 428ms/step - loss: 7.8794 - rmse: 21.7907 - val_loss: 11.4792 - val_rmse: 16.0517\n",
      "Epoch 19/20\n",
      "50/50 [==============================] - 21s 418ms/step - loss: 7.6848 - rmse: 21.6707 - val_loss: 9.6475 - val_rmse: 14.6696\n",
      "Epoch 20/20\n",
      "50/50 [==============================] - 21s 420ms/step - loss: 7.4646 - rmse: 21.4692 - val_loss: 9.5978 - val_rmse: 14.4976\n",
      "Train for 50 steps, validate for 50 steps\n",
      "Epoch 1/20\n",
      "50/50 [==============================] - 28s 560ms/step - loss: 28.8911 - rmse: 40.5433 - val_loss: 34.8698 - val_rmse: 42.8386\n",
      "Epoch 2/20\n",
      "50/50 [==============================] - 22s 433ms/step - loss: 22.5120 - rmse: 33.6902 - val_loss: 20.4924 - val_rmse: 26.7082\n",
      "Epoch 3/20\n",
      "50/50 [==============================] - 22s 433ms/step - loss: 17.4057 - rmse: 29.4149 - val_loss: 18.8175 - val_rmse: 25.3729\n",
      "Epoch 4/20\n",
      "50/50 [==============================] - 26s 514ms/step - loss: 14.3697 - rmse: 27.2029 - val_loss: 16.4241 - val_rmse: 22.3843\n",
      "Epoch 5/20\n",
      "50/50 [==============================] - 31s 614ms/step - loss: 12.6298 - rmse: 25.8148 - val_loss: 16.8138 - val_rmse: 23.2224\n",
      "Epoch 6/20\n",
      "50/50 [==============================] - 27s 539ms/step - loss: 11.4459 - rmse: 24.8204 - val_loss: 10.6513 - val_rmse: 15.3060\n",
      "Epoch 7/20\n",
      "50/50 [==============================] - 24s 476ms/step - loss: 10.8791 - rmse: 24.2202 - val_loss: 10.2961 - val_rmse: 14.6605\n",
      "Epoch 8/20\n",
      "50/50 [==============================] - 25s 509ms/step - loss: 10.0977 - rmse: 23.6178 - val_loss: 14.3321 - val_rmse: 19.5057\n",
      "Epoch 9/20\n",
      "50/50 [==============================] - 29s 575ms/step - loss: 9.6895 - rmse: 23.3394 - val_loss: 12.8192 - val_rmse: 17.6594\n",
      "Epoch 10/20\n",
      "50/50 [==============================] - 24s 474ms/step - loss: 9.2875 - rmse: 23.0355 - val_loss: 14.1497 - val_rmse: 19.7091\n",
      "Epoch 11/20\n",
      "50/50 [==============================] - 23s 450ms/step - loss: 9.0290 - rmse: 22.8602 - val_loss: 11.1911 - val_rmse: 16.3746\n",
      "Epoch 12/20\n",
      "50/50 [==============================] - 37s 744ms/step - loss: 8.7842 - rmse: 22.7288 - val_loss: 11.1646 - val_rmse: 16.0261\n",
      "Epoch 13/20\n",
      "50/50 [==============================] - 52s 1s/step - loss: 8.5987 - rmse: 22.5559 - val_loss: 9.2262 - val_rmse: 13.6701\n",
      "Epoch 14/20\n",
      "50/50 [==============================] - 28s 558ms/step - loss: 8.3148 - rmse: 22.3762 - val_loss: 11.5070 - val_rmse: 16.7475\n",
      "Epoch 15/20\n",
      "50/50 [==============================] - 28s 561ms/step - loss: 8.1635 - rmse: 22.2527 - val_loss: 13.6271 - val_rmse: 19.0725\n",
      "Epoch 16/20\n",
      "50/50 [==============================] - 28s 557ms/step - loss: 7.9588 - rmse: 22.1022 - val_loss: 11.1881 - val_rmse: 15.6817\n",
      "Epoch 17/20\n",
      "50/50 [==============================] - 28s 566ms/step - loss: 7.7645 - rmse: 21.9392 - val_loss: 10.0867 - val_rmse: 15.2581\n",
      "Epoch 18/20\n",
      "50/50 [==============================] - 28s 558ms/step - loss: 7.6750 - rmse: 21.8566 - val_loss: 9.1410 - val_rmse: 13.9301\n",
      "Epoch 19/20\n",
      "50/50 [==============================] - 26s 522ms/step - loss: 7.4897 - rmse: 21.6768 - val_loss: 11.1879 - val_rmse: 16.0829\n",
      "Epoch 20/20\n",
      "50/50 [==============================] - 46s 920ms/step - loss: 7.3442 - rmse: 21.5330 - val_loss: 8.6328 - val_rmse: 12.8249\n",
      "Train for 50 steps, validate for 50 steps\n",
      "Epoch 1/20\n",
      "50/50 [==============================] - 58s 1s/step - loss: 267.6491 - rmse: 328.9843 - val_loss: 23.4867 - val_rmse: 28.4690\n",
      "Epoch 2/20\n",
      "50/50 [==============================] - 37s 749ms/step - loss: 24.3968 - rmse: 34.0968 - val_loss: 23.4744 - val_rmse: 28.8251\n",
      "Epoch 3/20\n",
      "50/50 [==============================] - 34s 689ms/step - loss: 26.2183 - rmse: 36.8440 - val_loss: 25.9657 - val_rmse: 32.9535\n",
      "Epoch 4/20\n",
      "50/50 [==============================] - 37s 742ms/step - loss: 21.6784 - rmse: 32.7543 - val_loss: 22.2987 - val_rmse: 28.5859\n",
      "Epoch 5/20\n",
      "50/50 [==============================] - 35s 705ms/step - loss: 21.3595 - rmse: 33.0196 - val_loss: 17.5941 - val_rmse: 23.5370\n",
      "Epoch 6/20\n",
      "50/50 [==============================] - 32s 647ms/step - loss: 18.3246 - rmse: 30.4773 - val_loss: 15.9240 - val_rmse: 21.3537\n",
      "Epoch 7/20\n",
      "50/50 [==============================] - 28s 562ms/step - loss: 14.4005 - rmse: 27.0960 - val_loss: 17.8596 - val_rmse: 25.5149\n",
      "Epoch 8/20\n",
      "50/50 [==============================] - 28s 558ms/step - loss: 12.9529 - rmse: 26.0091 - val_loss: 11.4701 - val_rmse: 15.9985\n",
      "Epoch 9/20\n",
      "50/50 [==============================] - 34s 688ms/step - loss: 11.5698 - rmse: 24.7246 - val_loss: 11.5808 - val_rmse: 16.3843\n",
      "Epoch 10/20\n",
      "50/50 [==============================] - 32s 642ms/step - loss: 10.5562 - rmse: 23.9530 - val_loss: 12.3719 - val_rmse: 17.2109\n",
      "Epoch 11/20\n",
      "50/50 [==============================] - 29s 584ms/step - loss: 10.1118 - rmse: 23.6241 - val_loss: 14.3177 - val_rmse: 19.5673\n",
      "Epoch 12/20\n",
      "50/50 [==============================] - 30s 596ms/step - loss: 9.6262 - rmse: 23.2373 - val_loss: 14.4867 - val_rmse: 19.6789\n",
      "Epoch 13/20\n",
      "50/50 [==============================] - 27s 539ms/step - loss: 9.2314 - rmse: 22.9633 - val_loss: 9.8479 - val_rmse: 14.7207\n",
      "Epoch 14/20\n",
      "50/50 [==============================] - 28s 566ms/step - loss: 8.9642 - rmse: 22.7344 - val_loss: 9.4522 - val_rmse: 14.3021\n",
      "Epoch 15/20\n",
      "50/50 [==============================] - 31s 612ms/step - loss: 8.6546 - rmse: 22.5187 - val_loss: 9.1558 - val_rmse: 13.6465\n",
      "Epoch 16/20\n",
      "50/50 [==============================] - 33s 653ms/step - loss: 8.3507 - rmse: 22.2980 - val_loss: 10.4619 - val_rmse: 15.3986\n",
      "Epoch 17/20\n",
      "50/50 [==============================] - 29s 589ms/step - loss: 8.2239 - rmse: 22.1682 - val_loss: 12.4669 - val_rmse: 17.9383\n",
      "Epoch 18/20\n",
      "50/50 [==============================] - 29s 575ms/step - loss: 7.9588 - rmse: 21.9087 - val_loss: 11.8489 - val_rmse: 17.5840\n",
      "Epoch 19/20\n",
      "50/50 [==============================] - 34s 676ms/step - loss: 7.7870 - rmse: 21.8748 - val_loss: 11.3089 - val_rmse: 16.4329\n",
      "Epoch 20/20\n",
      "50/50 [==============================] - 31s 627ms/step - loss: 7.5800 - rmse: 21.6716 - val_loss: 11.8284 - val_rmse: 17.3675\n",
      "Train for 50 steps, validate for 50 steps\n",
      "Epoch 1/20\n",
      "50/50 [==============================] - 39s 780ms/step - loss: 260.6938 - rmse: 380.9547 - val_loss: 28.8961 - val_rmse: 36.4828\n",
      "Epoch 2/20\n",
      "50/50 [==============================] - 29s 578ms/step - loss: 26.9109 - rmse: 37.8153 - val_loss: 26.4068 - val_rmse: 33.4010\n",
      "Epoch 3/20\n",
      "50/50 [==============================] - 31s 626ms/step - loss: 23.6524 - rmse: 34.8863 - val_loss: 34.2483 - val_rmse: 42.1301\n",
      "Epoch 4/20\n",
      "50/50 [==============================] - 30s 603ms/step - loss: 39.3531 - rmse: 52.4965 - val_loss: 35.9923 - val_rmse: 44.0051\n",
      "Epoch 5/20\n",
      "50/50 [==============================] - 30s 600ms/step - loss: 33.5932 - rmse: 45.1211 - val_loss: 34.9887 - val_rmse: 43.1243\n",
      "Epoch 6/20\n",
      "50/50 [==============================] - 32s 641ms/step - loss: 23.4581 - rmse: 33.8446 - val_loss: 25.9163 - val_rmse: 32.2856\n",
      "Epoch 7/20\n",
      "50/50 [==============================] - 32s 633ms/step - loss: 21.3134 - rmse: 32.0710 - val_loss: 28.0653 - val_rmse: 35.1675\n",
      "Epoch 8/20\n",
      "50/50 [==============================] - 32s 642ms/step - loss: 16.7867 - rmse: 28.8174 - val_loss: 18.4515 - val_rmse: 24.6040\n",
      "Epoch 9/20\n",
      "50/50 [==============================] - 31s 627ms/step - loss: 14.2207 - rmse: 27.1127 - val_loss: 11.5128 - val_rmse: 16.0589\n",
      "Epoch 10/20\n",
      "50/50 [==============================] - 34s 686ms/step - loss: 12.1729 - rmse: 25.4598 - val_loss: 12.4553 - val_rmse: 17.2878\n",
      "Epoch 11/20\n",
      "50/50 [==============================] - 36s 716ms/step - loss: 11.1654 - rmse: 24.5162 - val_loss: 12.1707 - val_rmse: 16.3918\n",
      "Epoch 12/20\n",
      "50/50 [==============================] - 31s 614ms/step - loss: 10.4909 - rmse: 23.9555 - val_loss: 17.6732 - val_rmse: 23.5727\n",
      "Epoch 13/20\n",
      "50/50 [==============================] - 34s 681ms/step - loss: 9.8955 - rmse: 23.4950 - val_loss: 10.7054 - val_rmse: 15.0869\n",
      "Epoch 14/20\n",
      "50/50 [==============================] - 29s 580ms/step - loss: 9.4171 - rmse: 23.1815 - val_loss: 13.6644 - val_rmse: 18.9412\n",
      "Epoch 15/20\n",
      "50/50 [==============================] - 30s 592ms/step - loss: 9.0357 - rmse: 22.9346 - val_loss: 9.3273 - val_rmse: 13.5787\n",
      "Epoch 16/20\n",
      "50/50 [==============================] - 28s 562ms/step - loss: 8.7828 - rmse: 22.6960 - val_loss: 13.7901 - val_rmse: 18.8036\n",
      "Epoch 17/20\n",
      "50/50 [==============================] - 27s 547ms/step - loss: 8.4540 - rmse: 22.4085 - val_loss: 9.9201 - val_rmse: 14.2079\n",
      "Epoch 18/20\n",
      "50/50 [==============================] - 28s 558ms/step - loss: 8.2440 - rmse: 22.2180 - val_loss: 11.3490 - val_rmse: 16.2573\n",
      "Epoch 19/20\n",
      "50/50 [==============================] - 28s 553ms/step - loss: 8.0246 - rmse: 21.9799 - val_loss: 8.6709 - val_rmse: 13.1683\n",
      "Epoch 20/20\n",
      "50/50 [==============================] - 30s 605ms/step - loss: 7.8327 - rmse: 21.7680 - val_loss: 13.1249 - val_rmse: 18.3368\n",
      "Train for 50 steps, validate for 50 steps\n",
      "Epoch 1/20\n",
      "50/50 [==============================] - 50s 1s/step - loss: 9866.3119 - rmse: 12105.5654 - val_loss: 102.8045 - val_rmse: 121.8190\n",
      "Epoch 2/20\n",
      "50/50 [==============================] - 41s 829ms/step - loss: 660.9938 - rmse: 936.8405 - val_loss: 23.1683 - val_rmse: 28.5981\n",
      "Epoch 3/20\n",
      "50/50 [==============================] - 46s 924ms/step - loss: 123.3819 - rmse: 173.2942 - val_loss: 1415.6699 - val_rmse: 1978.1818\n",
      "Epoch 4/20\n",
      "50/50 [==============================] - 43s 869ms/step - loss: 106.1109 - rmse: 145.6590 - val_loss: 20.3090 - val_rmse: 26.0040\n",
      "Epoch 5/20\n",
      "50/50 [==============================] - 47s 935ms/step - loss: 18.5987 - rmse: 30.5865 - val_loss: 21.5466 - val_rmse: 27.6223\n",
      "Epoch 6/20\n",
      "50/50 [==============================] - 39s 782ms/step - loss: 16.8790 - rmse: 29.2255 - val_loss: 14.3874 - val_rmse: 18.5533\n",
      "Epoch 7/20\n",
      "50/50 [==============================] - 38s 769ms/step - loss: 15.1188 - rmse: 27.9095 - val_loss: 9.9900 - val_rmse: 13.8582\n",
      "Epoch 8/20\n",
      "50/50 [==============================] - 48s 957ms/step - loss: 13.3129 - rmse: 26.5104 - val_loss: 10.5579 - val_rmse: 14.3429\n",
      "Epoch 9/20\n",
      "50/50 [==============================] - 46s 912ms/step - loss: 11.7654 - rmse: 25.0383 - val_loss: 14.6447 - val_rmse: 19.6559\n",
      "Epoch 10/20\n",
      "50/50 [==============================] - 42s 842ms/step - loss: 10.3856 - rmse: 23.7871 - val_loss: 10.5694 - val_rmse: 15.1906\n",
      "Epoch 11/20\n",
      "50/50 [==============================] - 44s 888ms/step - loss: 9.6833 - rmse: 23.0915 - val_loss: 8.5159 - val_rmse: 12.4007\n",
      "Epoch 12/20\n",
      "50/50 [==============================] - 43s 859ms/step - loss: 9.1564 - rmse: 22.6026 - val_loss: 9.7137 - val_rmse: 14.6092\n",
      "Epoch 13/20\n",
      "50/50 [==============================] - 43s 855ms/step - loss: 8.7783 - rmse: 22.2369 - val_loss: 11.4067 - val_rmse: 15.3754\n",
      "Epoch 14/20\n",
      "50/50 [==============================] - 43s 853ms/step - loss: 8.4870 - rmse: 21.9207 - val_loss: 9.8216 - val_rmse: 15.0592\n",
      "Epoch 15/20\n",
      "50/50 [==============================] - 43s 864ms/step - loss: 8.1235 - rmse: 21.5773 - val_loss: 10.5816 - val_rmse: 14.8513\n",
      "Epoch 16/20\n",
      "50/50 [==============================] - 46s 927ms/step - loss: 7.8816 - rmse: 21.4136 - val_loss: 11.3284 - val_rmse: 16.1573\n",
      "Epoch 17/20\n",
      "50/50 [==============================] - 43s 869ms/step - loss: 7.7217 - rmse: 21.1414 - val_loss: 9.1458 - val_rmse: 14.0128\n",
      "Epoch 18/20\n",
      "50/50 [==============================] - 48s 956ms/step - loss: 7.3553 - rmse: 20.7183 - val_loss: 9.4410 - val_rmse: 14.6070\n",
      "Epoch 19/20\n",
      "50/50 [==============================] - 41s 822ms/step - loss: 7.1699 - rmse: 20.3282 - val_loss: 10.0465 - val_rmse: 15.4751\n",
      "Epoch 20/20\n",
      "50/50 [==============================] - 36s 725ms/step - loss: 6.9155 - rmse: 19.8130 - val_loss: 8.9375 - val_rmse: 13.5344\n",
      "Train for 50 steps, validate for 50 steps\n",
      "Epoch 1/20\n",
      "50/50 [==============================] - 45s 896ms/step - loss: 6686.0304 - rmse: 8539.0479 - val_loss: 393.6501 - val_rmse: 501.5670\n",
      "Epoch 2/20\n",
      "50/50 [==============================] - 39s 778ms/step - loss: 573.9198 - rmse: 702.4487 - val_loss: 356.6560 - val_rmse: 501.6596\n",
      "Epoch 3/20\n",
      "50/50 [==============================] - 40s 803ms/step - loss: 373.2935 - rmse: 471.7595 - val_loss: 56.4208 - val_rmse: 71.9431\n",
      "Epoch 4/20\n",
      "50/50 [==============================] - 40s 804ms/step - loss: 57.7250 - rmse: 79.0858 - val_loss: 27.3065 - val_rmse: 35.0841\n",
      "Epoch 5/20\n",
      "50/50 [==============================] - 41s 812ms/step - loss: 20.7784 - rmse: 32.2799 - val_loss: 22.5705 - val_rmse: 29.7075\n",
      "Epoch 6/20\n",
      "50/50 [==============================] - 40s 800ms/step - loss: 18.5265 - rmse: 30.7321 - val_loss: 26.6144 - val_rmse: 33.4495\n",
      "Epoch 7/20\n",
      "50/50 [==============================] - 39s 787ms/step - loss: 16.1256 - rmse: 28.7767 - val_loss: 19.2649 - val_rmse: 26.3915\n",
      "Epoch 8/20\n",
      "50/50 [==============================] - 40s 795ms/step - loss: 14.0213 - rmse: 27.0944 - val_loss: 14.1466 - val_rmse: 19.8091\n",
      "Epoch 9/20\n",
      "50/50 [==============================] - 40s 808ms/step - loss: 11.8844 - rmse: 25.1850 - val_loss: 10.2546 - val_rmse: 14.7654\n",
      "Epoch 10/20\n",
      "50/50 [==============================] - 40s 807ms/step - loss: 10.8231 - rmse: 24.2121 - val_loss: 12.2967 - val_rmse: 17.5961\n",
      "Epoch 11/20\n",
      "50/50 [==============================] - 41s 812ms/step - loss: 10.0926 - rmse: 23.6086 - val_loss: 11.9781 - val_rmse: 17.4618\n",
      "Epoch 12/20\n",
      "50/50 [==============================] - 40s 797ms/step - loss: 9.5430 - rmse: 23.2506 - val_loss: 8.9070 - val_rmse: 13.0125\n",
      "Epoch 13/20\n",
      "50/50 [==============================] - 41s 812ms/step - loss: 9.1179 - rmse: 22.8881 - val_loss: 10.1496 - val_rmse: 14.8657\n",
      "Epoch 14/20\n",
      "50/50 [==============================] - 40s 800ms/step - loss: 8.8166 - rmse: 22.6617 - val_loss: 9.8263 - val_rmse: 14.0732\n",
      "Epoch 15/20\n",
      "50/50 [==============================] - 40s 805ms/step - loss: 8.4392 - rmse: 22.4061 - val_loss: 8.6048 - val_rmse: 12.8808\n",
      "Epoch 16/20\n",
      "50/50 [==============================] - 41s 818ms/step - loss: 8.1743 - rmse: 22.1581 - val_loss: 11.7296 - val_rmse: 16.3392\n",
      "Epoch 17/20\n",
      "50/50 [==============================] - 41s 817ms/step - loss: 7.9063 - rmse: 21.9649 - val_loss: 15.8196 - val_rmse: 22.2002\n",
      "Epoch 18/20\n",
      "50/50 [==============================] - 40s 809ms/step - loss: 7.7702 - rmse: 21.8810 - val_loss: 9.3840 - val_rmse: 14.4623\n",
      "Epoch 19/20\n",
      "50/50 [==============================] - 40s 810ms/step - loss: 7.5153 - rmse: 21.6658 - val_loss: 11.3714 - val_rmse: 16.5646\n",
      "Epoch 20/20\n",
      "50/50 [==============================] - 41s 819ms/step - loss: 7.3566 - rmse: 21.5133 - val_loss: 10.2647 - val_rmse: 14.7911\n",
      "Train for 50 steps, validate for 50 steps\n",
      "Epoch 1/20\n",
      "50/50 [==============================] - 45s 895ms/step - loss: 27.7849 - rmse: 38.9426 - val_loss: 24.3056 - val_rmse: 31.2718\n",
      "Epoch 2/20\n",
      "50/50 [==============================] - 37s 736ms/step - loss: 20.2400 - rmse: 31.8575 - val_loss: 27.0635 - val_rmse: 34.6141\n",
      "Epoch 3/20\n",
      "50/50 [==============================] - 37s 738ms/step - loss: 18.0576 - rmse: 30.1756 - val_loss: 13.0601 - val_rmse: 17.8427\n",
      "Epoch 4/20\n",
      "50/50 [==============================] - 37s 741ms/step - loss: 15.3467 - rmse: 27.9763 - val_loss: 19.2537 - val_rmse: 26.3567\n",
      "Epoch 5/20\n",
      "50/50 [==============================] - 37s 743ms/step - loss: 12.4638 - rmse: 25.5634 - val_loss: 16.2880 - val_rmse: 22.7449\n",
      "Epoch 6/20\n",
      "50/50 [==============================] - 37s 745ms/step - loss: 11.3139 - rmse: 24.6031 - val_loss: 11.6541 - val_rmse: 16.9499\n",
      "Epoch 7/20\n",
      "50/50 [==============================] - 37s 741ms/step - loss: 10.2887 - rmse: 23.7625 - val_loss: 13.0751 - val_rmse: 18.5504\n",
      "Epoch 8/20\n",
      "50/50 [==============================] - 37s 738ms/step - loss: 9.8073 - rmse: 23.3614 - val_loss: 13.7564 - val_rmse: 19.0330\n",
      "Epoch 9/20\n",
      "50/50 [==============================] - 37s 748ms/step - loss: 9.2281 - rmse: 22.9566 - val_loss: 11.8439 - val_rmse: 16.9565\n",
      "Epoch 10/20\n",
      "50/50 [==============================] - 37s 738ms/step - loss: 8.8648 - rmse: 22.6559 - val_loss: 10.7364 - val_rmse: 15.8445\n",
      "Epoch 11/20\n",
      "50/50 [==============================] - 37s 736ms/step - loss: 8.6180 - rmse: 22.4547 - val_loss: 11.8896 - val_rmse: 16.6468\n",
      "Epoch 12/20\n",
      "50/50 [==============================] - 37s 743ms/step - loss: 8.2508 - rmse: 22.1918 - val_loss: 12.4501 - val_rmse: 17.0475\n",
      "Epoch 13/20\n",
      "50/50 [==============================] - 37s 737ms/step - loss: 8.1397 - rmse: 22.1200 - val_loss: 9.4735 - val_rmse: 14.1534\n",
      "Epoch 14/20\n",
      "50/50 [==============================] - 37s 741ms/step - loss: 7.7956 - rmse: 21.8426 - val_loss: 8.8859 - val_rmse: 13.3335\n",
      "Epoch 15/20\n",
      "50/50 [==============================] - 37s 748ms/step - loss: 7.5736 - rmse: 21.6058 - val_loss: 10.7922 - val_rmse: 15.5628\n",
      "Epoch 16/20\n",
      "50/50 [==============================] - 37s 744ms/step - loss: 7.3966 - rmse: 21.4878 - val_loss: 9.6332 - val_rmse: 15.0193\n",
      "Epoch 17/20\n",
      "50/50 [==============================] - 37s 748ms/step - loss: 7.1605 - rmse: 21.3024 - val_loss: 10.5659 - val_rmse: 15.6405\n",
      "Epoch 18/20\n",
      "50/50 [==============================] - 37s 748ms/step - loss: 6.9811 - rmse: 21.1301 - val_loss: 8.9941 - val_rmse: 13.6211\n",
      "Epoch 19/20\n",
      "50/50 [==============================] - 37s 745ms/step - loss: 6.7586 - rmse: 20.9255 - val_loss: 9.5922 - val_rmse: 14.6709\n",
      "Epoch 20/20\n",
      "50/50 [==============================] - 37s 748ms/step - loss: 6.5903 - rmse: 20.7441 - val_loss: 9.6591 - val_rmse: 15.2038\n",
      "Train for 50 steps, validate for 50 steps\n",
      "Epoch 1/20\n",
      "50/50 [==============================] - 45s 900ms/step - loss: 30.8543 - rmse: 43.6666 - val_loss: 31.6427 - val_rmse: 39.3961\n",
      "Epoch 2/20\n",
      "50/50 [==============================] - 37s 738ms/step - loss: 23.1630 - rmse: 34.7237 - val_loss: 34.2693 - val_rmse: 42.1776\n",
      "Epoch 3/20\n",
      "50/50 [==============================] - 37s 733ms/step - loss: 21.2015 - rmse: 33.1332 - val_loss: 26.3517 - val_rmse: 33.4072\n",
      "Epoch 4/20\n",
      "50/50 [==============================] - 38s 759ms/step - loss: 17.5286 - rmse: 29.9079 - val_loss: 15.8003 - val_rmse: 22.1818\n",
      "Epoch 5/20\n",
      "50/50 [==============================] - 38s 750ms/step - loss: 14.6791 - rmse: 27.6977 - val_loss: 16.2447 - val_rmse: 22.3779\n",
      "Epoch 6/20\n",
      "50/50 [==============================] - 37s 743ms/step - loss: 12.9675 - rmse: 26.1483 - val_loss: 15.6624 - val_rmse: 21.0295\n",
      "Epoch 7/20\n",
      "50/50 [==============================] - 37s 741ms/step - loss: 11.4584 - rmse: 24.7177 - val_loss: 10.9725 - val_rmse: 15.5590\n",
      "Epoch 8/20\n",
      "50/50 [==============================] - 38s 762ms/step - loss: 10.6093 - rmse: 23.9668 - val_loss: 11.9560 - val_rmse: 16.9624\n",
      "Epoch 9/20\n",
      "50/50 [==============================] - 37s 736ms/step - loss: 9.9737 - rmse: 23.5051 - val_loss: 12.6831 - val_rmse: 18.0830\n",
      "Epoch 10/20\n",
      "50/50 [==============================] - 44s 887ms/step - loss: 9.4015 - rmse: 23.0459 - val_loss: 11.4628 - val_rmse: 16.3842\n",
      "Epoch 11/20\n",
      "50/50 [==============================] - 43s 853ms/step - loss: 9.1135 - rmse: 22.8399 - val_loss: 11.4329 - val_rmse: 15.9436\n",
      "Epoch 12/20\n",
      "50/50 [==============================] - 37s 730ms/step - loss: 8.8930 - rmse: 22.6234 - val_loss: 10.6699 - val_rmse: 15.7269\n",
      "Epoch 13/20\n",
      "50/50 [==============================] - 37s 744ms/step - loss: 8.5190 - rmse: 22.3966 - val_loss: 9.7174 - val_rmse: 14.2098\n",
      "Epoch 14/20\n",
      "50/50 [==============================] - 37s 737ms/step - loss: 8.4321 - rmse: 22.2349 - val_loss: 14.2207 - val_rmse: 19.9890\n",
      "Epoch 15/20\n",
      "50/50 [==============================] - 37s 733ms/step - loss: 8.2009 - rmse: 22.0606 - val_loss: 9.4975 - val_rmse: 14.1117\n",
      "Epoch 16/20\n",
      "50/50 [==============================] - 37s 739ms/step - loss: 7.9542 - rmse: 21.8449 - val_loss: 12.1116 - val_rmse: 17.4745\n",
      "Epoch 17/20\n",
      "50/50 [==============================] - 37s 733ms/step - loss: 7.8027 - rmse: 21.7191 - val_loss: 10.0745 - val_rmse: 14.3845\n",
      "Epoch 18/20\n",
      "50/50 [==============================] - 37s 735ms/step - loss: 7.6207 - rmse: 21.4718 - val_loss: 9.5913 - val_rmse: 14.1592\n",
      "Epoch 19/20\n",
      "50/50 [==============================] - 37s 738ms/step - loss: 7.4254 - rmse: 21.3793 - val_loss: 9.9521 - val_rmse: 14.1647\n",
      "Epoch 20/20\n",
      "50/50 [==============================] - 36s 724ms/step - loss: 7.2627 - rmse: 21.1252 - val_loss: 9.2279 - val_rmse: 13.5367\n",
      "Train for 50 steps, validate for 50 steps\n",
      "Epoch 1/20\n",
      "50/50 [==============================] - 45s 909ms/step - loss: 42.4440 - rmse: 55.3948 - val_loss: 32.4618 - val_rmse: 40.4606\n",
      "Epoch 2/20\n",
      "50/50 [==============================] - 37s 741ms/step - loss: 31.1239 - rmse: 42.3453 - val_loss: 29.6905 - val_rmse: 37.0774\n",
      "Epoch 3/20\n",
      "50/50 [==============================] - 41s 813ms/step - loss: 26.4578 - rmse: 36.9267 - val_loss: 27.5805 - val_rmse: 34.2776\n",
      "Epoch 4/20\n",
      "50/50 [==============================] - 37s 746ms/step - loss: 22.8560 - rmse: 33.1332 - val_loss: 18.7533 - val_rmse: 23.2050\n",
      "Epoch 5/20\n",
      "50/50 [==============================] - 37s 744ms/step - loss: 21.7059 - rmse: 32.9502 - val_loss: 31.7945 - val_rmse: 39.5026\n",
      "Epoch 6/20\n",
      "50/50 [==============================] - 37s 747ms/step - loss: 17.1507 - rmse: 29.4053 - val_loss: 15.0137 - val_rmse: 20.1152\n",
      "Epoch 7/20\n",
      "50/50 [==============================] - 38s 755ms/step - loss: 12.8068 - rmse: 25.8474 - val_loss: 13.9081 - val_rmse: 18.6981\n",
      "Epoch 8/20\n",
      "50/50 [==============================] - 37s 741ms/step - loss: 11.6592 - rmse: 24.8965 - val_loss: 9.7752 - val_rmse: 13.3728\n",
      "Epoch 9/20\n",
      "50/50 [==============================] - 37s 750ms/step - loss: 10.6446 - rmse: 24.0893 - val_loss: 10.5794 - val_rmse: 15.0687\n",
      "Epoch 10/20\n",
      "50/50 [==============================] - 37s 743ms/step - loss: 10.1626 - rmse: 23.7833 - val_loss: 11.3700 - val_rmse: 15.7400\n",
      "Epoch 11/20\n",
      "50/50 [==============================] - 37s 750ms/step - loss: 9.5266 - rmse: 23.2872 - val_loss: 14.1327 - val_rmse: 19.4390\n",
      "Epoch 12/20\n",
      "50/50 [==============================] - 37s 750ms/step - loss: 9.2920 - rmse: 23.0512 - val_loss: 11.6054 - val_rmse: 16.4012\n",
      "Epoch 13/20\n",
      "50/50 [==============================] - 37s 749ms/step - loss: 9.0136 - rmse: 22.8397 - val_loss: 9.6430 - val_rmse: 13.8001\n",
      "Epoch 14/20\n",
      "50/50 [==============================] - 37s 746ms/step - loss: 8.6889 - rmse: 22.5914 - val_loss: 12.1829 - val_rmse: 17.4164\n",
      "Epoch 15/20\n",
      "50/50 [==============================] - 37s 746ms/step - loss: 8.5442 - rmse: 22.4591 - val_loss: 10.1397 - val_rmse: 15.1306\n",
      "Epoch 16/20\n",
      "50/50 [==============================] - 37s 743ms/step - loss: 8.3351 - rmse: 22.2502 - val_loss: 10.1115 - val_rmse: 14.7182\n",
      "Epoch 17/20\n",
      "50/50 [==============================] - 37s 744ms/step - loss: 8.1064 - rmse: 22.0375 - val_loss: 10.6186 - val_rmse: 15.7038\n",
      "Epoch 18/20\n",
      "50/50 [==============================] - 37s 748ms/step - loss: 7.9314 - rmse: 21.8767 - val_loss: 12.2835 - val_rmse: 17.8845\n",
      "Epoch 19/20\n",
      "50/50 [==============================] - 37s 750ms/step - loss: 7.8133 - rmse: 21.7482 - val_loss: 9.8234 - val_rmse: 14.4252\n",
      "Epoch 20/20\n",
      "50/50 [==============================] - 37s 744ms/step - loss: 7.5940 - rmse: 21.5360 - val_loss: 11.3312 - val_rmse: 16.4444\n",
      "Train for 50 steps, validate for 50 steps\n",
      "Epoch 1/20\n",
      "50/50 [==============================] - 46s 927ms/step - loss: 2442.5311 - rmse: 3444.4285 - val_loss: 435.1043 - val_rmse: 577.7149\n",
      "Epoch 2/20\n",
      "50/50 [==============================] - 41s 820ms/step - loss: 587.5327 - rmse: 773.6273 - val_loss: 147.9560 - val_rmse: 182.9662\n",
      "Epoch 3/20\n",
      "50/50 [==============================] - 41s 830ms/step - loss: 144.0513 - rmse: 190.1668 - val_loss: 37.0170 - val_rmse: 46.2624\n",
      "Epoch 4/20\n",
      "50/50 [==============================] - 41s 830ms/step - loss: 32.8130 - rmse: 45.3303 - val_loss: 30.1233 - val_rmse: 37.5861\n",
      "Epoch 5/20\n",
      "50/50 [==============================] - 42s 847ms/step - loss: 22.7227 - rmse: 33.6108 - val_loss: 36.2084 - val_rmse: 44.1764\n",
      "Epoch 6/20\n",
      "50/50 [==============================] - 42s 832ms/step - loss: 28.6449 - rmse: 39.9978 - val_loss: 24.8840 - val_rmse: 30.8482\n",
      "Epoch 7/20\n",
      "50/50 [==============================] - 42s 839ms/step - loss: 21.2992 - rmse: 32.6921 - val_loss: 18.7947 - val_rmse: 23.4879\n",
      "Epoch 8/20\n",
      "50/50 [==============================] - 42s 844ms/step - loss: 18.2209 - rmse: 30.1850 - val_loss: 15.1669 - val_rmse: 19.7706\n",
      "Epoch 9/20\n",
      "50/50 [==============================] - 42s 847ms/step - loss: 14.0613 - rmse: 27.0578 - val_loss: 11.4264 - val_rmse: 15.7306\n",
      "Epoch 10/20\n",
      "50/50 [==============================] - 43s 859ms/step - loss: 12.0646 - rmse: 25.3736 - val_loss: 10.6484 - val_rmse: 14.9263\n",
      "Epoch 11/20\n",
      "50/50 [==============================] - 43s 854ms/step - loss: 10.7597 - rmse: 24.2529 - val_loss: 10.0866 - val_rmse: 14.6045\n",
      "Epoch 12/20\n",
      "50/50 [==============================] - 42s 850ms/step - loss: 10.0656 - rmse: 23.6554 - val_loss: 9.3396 - val_rmse: 13.1814\n",
      "Epoch 13/20\n",
      "50/50 [==============================] - 43s 866ms/step - loss: 9.5314 - rmse: 23.2235 - val_loss: 11.2972 - val_rmse: 15.8537\n",
      "Epoch 14/20\n",
      "50/50 [==============================] - 43s 861ms/step - loss: 9.0240 - rmse: 22.8036 - val_loss: 8.2465 - val_rmse: 12.0619\n",
      "Epoch 15/20\n",
      "50/50 [==============================] - 44s 879ms/step - loss: 8.7347 - rmse: 22.5317 - val_loss: 11.4275 - val_rmse: 16.0586\n",
      "Epoch 16/20\n",
      "50/50 [==============================] - 44s 871ms/step - loss: 8.5342 - rmse: 22.3518 - val_loss: 9.4812 - val_rmse: 13.9179\n",
      "Epoch 17/20\n",
      "50/50 [==============================] - 43s 867ms/step - loss: 8.2516 - rmse: 22.0895 - val_loss: 9.3162 - val_rmse: 13.6802\n",
      "Epoch 18/20\n",
      "50/50 [==============================] - 43s 859ms/step - loss: 8.0434 - rmse: 21.8929 - val_loss: 12.4563 - val_rmse: 17.1685\n",
      "Epoch 19/20\n",
      "50/50 [==============================] - 43s 865ms/step - loss: 7.8571 - rmse: 21.6913 - val_loss: 8.9927 - val_rmse: 13.3251\n",
      "Epoch 20/20\n",
      "50/50 [==============================] - 43s 867ms/step - loss: 7.6766 - rmse: 21.5371 - val_loss: 8.8460 - val_rmse: 13.4963\n",
      "Train for 50 steps, validate for 50 steps\n",
      "Epoch 1/20\n",
      "50/50 [==============================] - 64s 1s/step - loss: 27306.3459 - rmse: 33958.3711 - val_loss: 3225.4980 - val_rmse: 4435.1255\n",
      "Epoch 2/20\n",
      "50/50 [==============================] - 67s 1s/step - loss: 6281.1402 - rmse: 8387.4463 - val_loss: 1350.1035 - val_rmse: 2066.5625\n",
      "Epoch 3/20\n",
      "50/50 [==============================] - 62s 1s/step - loss: 1576.1403 - rmse: 2029.2612 - val_loss: 458.3977 - val_rmse: 562.4811\n",
      "Epoch 4/20\n",
      "50/50 [==============================] - 58s 1s/step - loss: 268.7417 - rmse: 343.9719 - val_loss: 22.8889 - val_rmse: 28.4004\n",
      "Epoch 5/20\n",
      "50/50 [==============================] - 58s 1s/step - loss: 21.6830 - rmse: 32.6010 - val_loss: 21.9491 - val_rmse: 28.3591\n",
      "Epoch 6/20\n",
      "50/50 [==============================] - 59s 1s/step - loss: 20.9966 - rmse: 32.3359 - val_loss: 16.3700 - val_rmse: 21.6987\n",
      "Epoch 7/20\n",
      "50/50 [==============================] - 58s 1s/step - loss: 21.4595 - rmse: 35.3279 - val_loss: 19.2724 - val_rmse: 25.2441\n",
      "Epoch 8/20\n",
      "50/50 [==============================] - 59s 1s/step - loss: 17.0233 - rmse: 29.4056 - val_loss: 22.5958 - val_rmse: 29.1493\n",
      "Epoch 9/20\n",
      "50/50 [==============================] - 58s 1s/step - loss: 15.4046 - rmse: 28.2651 - val_loss: 10.8672 - val_rmse: 15.0418\n",
      "Epoch 10/20\n",
      "50/50 [==============================] - 59s 1s/step - loss: 12.9087 - rmse: 26.1957 - val_loss: 13.1657 - val_rmse: 17.9524\n",
      "Epoch 11/20\n",
      "50/50 [==============================] - 60s 1s/step - loss: 11.8522 - rmse: 25.1272 - val_loss: 9.8007 - val_rmse: 14.1997\n",
      "Epoch 12/20\n",
      "50/50 [==============================] - 59s 1s/step - loss: 10.6353 - rmse: 24.1493 - val_loss: 13.4636 - val_rmse: 18.3611\n",
      "Epoch 13/20\n",
      "50/50 [==============================] - 59s 1s/step - loss: 10.2874 - rmse: 23.8118 - val_loss: 10.0566 - val_rmse: 14.9267\n",
      "Epoch 14/20\n",
      "50/50 [==============================] - 59s 1s/step - loss: 9.5160 - rmse: 23.2500 - val_loss: 9.7631 - val_rmse: 14.3521\n",
      "Epoch 15/20\n",
      "50/50 [==============================] - 59s 1s/step - loss: 9.2614 - rmse: 23.0076 - val_loss: 10.3845 - val_rmse: 14.5798\n",
      "Epoch 16/20\n",
      "50/50 [==============================] - 60s 1s/step - loss: 8.8814 - rmse: 22.7354 - val_loss: 9.4179 - val_rmse: 13.9191\n",
      "Epoch 17/20\n",
      "50/50 [==============================] - 59s 1s/step - loss: 8.5657 - rmse: 22.4425 - val_loss: 11.2661 - val_rmse: 16.0045\n",
      "Epoch 18/20\n",
      "50/50 [==============================] - 59s 1s/step - loss: 8.3398 - rmse: 22.2342 - val_loss: 10.9170 - val_rmse: 16.4650\n",
      "Epoch 19/20\n",
      "50/50 [==============================] - 61s 1s/step - loss: 8.1067 - rmse: 21.9673 - val_loss: 10.3379 - val_rmse: 15.1931\n",
      "Epoch 20/20\n",
      "50/50 [==============================] - 59s 1s/step - loss: 7.8480 - rmse: 21.7394 - val_loss: 10.0772 - val_rmse: 15.2297\n",
      "Train for 50 steps, validate for 50 steps\n",
      "Epoch 1/20\n",
      "50/50 [==============================] - 69s 1s/step - loss: 14067.0773 - rmse: 17286.8008 - val_loss: 739.9832 - val_rmse: 901.0628\n",
      "Epoch 2/20\n",
      "50/50 [==============================] - 60s 1s/step - loss: 1210.1037 - rmse: 1510.0663 - val_loss: 918.3933 - val_rmse: 1126.8595\n",
      "Epoch 3/20\n",
      "50/50 [==============================] - 63s 1s/step - loss: 1378.6673 - rmse: 1825.1327 - val_loss: 285.6627 - val_rmse: 415.4862\n",
      "Epoch 4/20\n",
      "50/50 [==============================] - 61s 1s/step - loss: 1668.1812 - rmse: 2139.3574 - val_loss: 893.3375 - val_rmse: 1218.3389\n",
      "Epoch 5/20\n",
      "50/50 [==============================] - 63s 1s/step - loss: 431.6343 - rmse: 553.4369 - val_loss: 38.9310 - val_rmse: 46.6042\n",
      "Epoch 6/20\n",
      "50/50 [==============================] - 61s 1s/step - loss: 35.4505 - rmse: 48.5915 - val_loss: 33.2495 - val_rmse: 41.2375\n",
      "Epoch 7/20\n",
      "50/50 [==============================] - 62s 1s/step - loss: 50.7351 - rmse: 84.1851 - val_loss: 29.9003 - val_rmse: 37.4962\n",
      "Epoch 8/20\n",
      "50/50 [==============================] - 61s 1s/step - loss: 18.1578 - rmse: 30.6841 - val_loss: 26.0849 - val_rmse: 32.4659\n",
      "Epoch 9/20\n",
      "50/50 [==============================] - 62s 1s/step - loss: 17.7569 - rmse: 30.3095 - val_loss: 24.2095 - val_rmse: 30.9048\n",
      "Epoch 10/20\n",
      "50/50 [==============================] - 65s 1s/step - loss: 17.0306 - rmse: 29.8088 - val_loss: 22.1818 - val_rmse: 28.3781\n",
      "Epoch 11/20\n",
      "50/50 [==============================] - 64s 1s/step - loss: 15.1117 - rmse: 28.0858 - val_loss: 26.8040 - val_rmse: 33.5905\n",
      "Epoch 12/20\n",
      "50/50 [==============================] - 63s 1s/step - loss: 13.4300 - rmse: 26.7339 - val_loss: 13.8081 - val_rmse: 18.3241\n",
      "Epoch 13/20\n",
      "50/50 [==============================] - 64s 1s/step - loss: 11.7474 - rmse: 25.2513 - val_loss: 11.3351 - val_rmse: 15.8350\n",
      "Epoch 14/20\n",
      "50/50 [==============================] - 64s 1s/step - loss: 10.8140 - rmse: 24.2771 - val_loss: 11.0832 - val_rmse: 15.8764\n",
      "Epoch 15/20\n",
      "50/50 [==============================] - 64s 1s/step - loss: 10.0994 - rmse: 23.5952 - val_loss: 13.0481 - val_rmse: 18.0542\n",
      "Epoch 16/20\n",
      "50/50 [==============================] - 63s 1s/step - loss: 9.5926 - rmse: 23.2117 - val_loss: 9.8866 - val_rmse: 14.2685\n",
      "Epoch 17/20\n",
      "50/50 [==============================] - 64s 1s/step - loss: 9.1944 - rmse: 22.8900 - val_loss: 11.4377 - val_rmse: 16.0540\n",
      "Epoch 18/20\n",
      "50/50 [==============================] - 64s 1s/step - loss: 8.9561 - rmse: 22.6953 - val_loss: 10.5133 - val_rmse: 14.9390\n",
      "Epoch 19/20\n",
      "50/50 [==============================] - 63s 1s/step - loss: 8.5192 - rmse: 22.3826 - val_loss: 11.3929 - val_rmse: 16.3879\n",
      "Epoch 20/20\n",
      "50/50 [==============================] - 64s 1s/step - loss: 8.2991 - rmse: 22.1954 - val_loss: 10.5957 - val_rmse: 15.4434\n",
      "Train for 50 steps, validate for 50 steps\n",
      "Epoch 1/20\n",
      "50/50 [==============================] - 63s 1s/step - loss: 38.0055 - rmse: 50.2842 - val_loss: 24.5688 - val_rmse: 30.2313\n",
      "Epoch 2/20\n",
      "50/50 [==============================] - 53s 1s/step - loss: 26.1465 - rmse: 36.5943 - val_loss: 34.1119 - val_rmse: 42.2867\n",
      "Epoch 3/20\n",
      "50/50 [==============================] - 53s 1s/step - loss: 23.3952 - rmse: 33.7591 - val_loss: 19.9308 - val_rmse: 24.6566\n",
      "Epoch 4/20\n",
      "50/50 [==============================] - 53s 1s/step - loss: 19.4533 - rmse: 30.8632 - val_loss: 16.6515 - val_rmse: 22.1927\n",
      "Epoch 5/20\n",
      "50/50 [==============================] - 53s 1s/step - loss: 15.0256 - rmse: 27.5486 - val_loss: 17.2917 - val_rmse: 23.1047\n",
      "Epoch 6/20\n",
      "50/50 [==============================] - 53s 1s/step - loss: 13.1784 - rmse: 26.4122 - val_loss: 15.1404 - val_rmse: 20.4753\n",
      "Epoch 7/20\n",
      "50/50 [==============================] - 53s 1s/step - loss: 11.8032 - rmse: 24.9509 - val_loss: 14.4064 - val_rmse: 19.8204\n",
      "Epoch 8/20\n",
      "50/50 [==============================] - 52s 1s/step - loss: 11.0069 - rmse: 24.3988 - val_loss: 9.4713 - val_rmse: 13.5204\n",
      "Epoch 9/20\n",
      "50/50 [==============================] - 53s 1s/step - loss: 10.3946 - rmse: 23.9811 - val_loss: 9.6837 - val_rmse: 13.4137\n",
      "Epoch 10/20\n",
      "50/50 [==============================] - 53s 1s/step - loss: 10.2340 - rmse: 23.8195 - val_loss: 10.0339 - val_rmse: 14.3904\n",
      "Epoch 11/20\n",
      "50/50 [==============================] - 53s 1s/step - loss: 9.5547 - rmse: 23.3495 - val_loss: 9.3825 - val_rmse: 13.0882\n",
      "Epoch 12/20\n",
      "50/50 [==============================] - 53s 1s/step - loss: 9.1878 - rmse: 23.0429 - val_loss: 10.7852 - val_rmse: 15.4348\n",
      "Epoch 13/20\n",
      "50/50 [==============================] - 53s 1s/step - loss: 9.1816 - rmse: 22.9572 - val_loss: 9.2125 - val_rmse: 13.4993\n",
      "Epoch 14/20\n",
      "50/50 [==============================] - 53s 1s/step - loss: 8.5931 - rmse: 22.5302 - val_loss: 11.0096 - val_rmse: 15.4558\n",
      "Epoch 15/20\n",
      "50/50 [==============================] - 53s 1s/step - loss: 8.5450 - rmse: 22.4122 - val_loss: 10.1149 - val_rmse: 14.7907\n",
      "Epoch 16/20\n",
      "50/50 [==============================] - 63s 1s/step - loss: 8.2997 - rmse: 22.2015 - val_loss: 9.5061 - val_rmse: 14.0448\n",
      "Epoch 17/20\n",
      "50/50 [==============================] - 98s 2s/step - loss: 8.0915 - rmse: 21.9651 - val_loss: 8.7040 - val_rmse: 12.8272\n",
      "Epoch 18/20\n",
      "50/50 [==============================] - 110s 2s/step - loss: 7.9128 - rmse: 21.7894 - val_loss: 10.6164 - val_rmse: 15.4530\n",
      "Epoch 19/20\n",
      "50/50 [==============================] - 102s 2s/step - loss: 7.6767 - rmse: 21.5724 - val_loss: 10.2121 - val_rmse: 14.9285\n",
      "Epoch 20/20\n",
      "50/50 [==============================] - 86s 2s/step - loss: 7.6261 - rmse: 21.5501 - val_loss: 9.3066 - val_rmse: 13.7115\n",
      "Train for 50 steps, validate for 50 steps\n",
      "Epoch 1/20\n",
      "50/50 [==============================] - 115s 2s/step - loss: 870.1720 - rmse: 1134.3633 - val_loss: 321.3122 - val_rmse: 400.8445\n",
      "Epoch 2/20\n",
      "50/50 [==============================] - 86s 2s/step - loss: 120.3540 - rmse: 156.3954 - val_loss: 42.0351 - val_rmse: 51.0636\n",
      "Epoch 3/20\n",
      "50/50 [==============================] - 86s 2s/step - loss: 135.7886 - rmse: 173.7638 - val_loss: 100.9468 - val_rmse: 121.9611\n",
      "Epoch 4/20\n",
      "50/50 [==============================] - 87s 2s/step - loss: 80.0697 - rmse: 106.6374 - val_loss: 177.4720 - val_rmse: 227.9141\n",
      "Epoch 5/20\n",
      "50/50 [==============================] - 102s 2s/step - loss: 198.5615 - rmse: 273.5142 - val_loss: 191.1290 - val_rmse: 252.0107\n",
      "Epoch 6/20\n",
      "50/50 [==============================] - 107s 2s/step - loss: 228.3423 - rmse: 304.2566 - val_loss: 35.3813 - val_rmse: 43.3728\n",
      "Epoch 7/20\n",
      "50/50 [==============================] - 89s 2s/step - loss: 40.7517 - rmse: 56.2947 - val_loss: 43.5171 - val_rmse: 52.7061\n",
      "Epoch 8/20\n",
      "50/50 [==============================] - 88s 2s/step - loss: 54.7355 - rmse: 76.8034 - val_loss: 34.4772 - val_rmse: 42.6730\n",
      "Epoch 9/20\n",
      "50/50 [==============================] - 92s 2s/step - loss: 26.6800 - rmse: 38.5362 - val_loss: 29.2593 - val_rmse: 36.8049\n",
      "Epoch 10/20\n",
      "50/50 [==============================] - 104s 2s/step - loss: 33.6090 - rmse: 45.7604 - val_loss: 28.9137 - val_rmse: 35.8513\n",
      "Epoch 11/20\n",
      "50/50 [==============================] - 88s 2s/step - loss: 24.0330 - rmse: 33.8984 - val_loss: 21.5575 - val_rmse: 24.9313\n",
      "Epoch 12/20\n",
      "50/50 [==============================] - 89s 2s/step - loss: 22.7528 - rmse: 33.1343 - val_loss: 18.1171 - val_rmse: 22.4084\n",
      "Epoch 13/20\n",
      "50/50 [==============================] - 91s 2s/step - loss: 18.7484 - rmse: 30.5960 - val_loss: 17.8844 - val_rmse: 23.0668\n",
      "Epoch 14/20\n",
      "50/50 [==============================] - 88s 2s/step - loss: 15.0212 - rmse: 27.6588 - val_loss: 11.9625 - val_rmse: 16.3236\n",
      "Epoch 15/20\n",
      "50/50 [==============================] - 92s 2s/step - loss: 13.2017 - rmse: 26.1842 - val_loss: 12.3831 - val_rmse: 17.2025\n",
      "Epoch 16/20\n",
      "50/50 [==============================] - 90s 2s/step - loss: 11.9555 - rmse: 25.1072 - val_loss: 9.7630 - val_rmse: 13.2728\n",
      "Epoch 17/20\n",
      "50/50 [==============================] - 82s 2s/step - loss: 11.0108 - rmse: 24.3876 - val_loss: 9.2552 - val_rmse: 13.0868\n",
      "Epoch 18/20\n",
      "50/50 [==============================] - 88s 2s/step - loss: 10.5113 - rmse: 23.9994 - val_loss: 9.7870 - val_rmse: 13.7619\n",
      "Epoch 19/20\n",
      "50/50 [==============================] - 89s 2s/step - loss: 9.9742 - rmse: 23.5423 - val_loss: 10.4578 - val_rmse: 14.8155\n",
      "Epoch 20/20\n",
      "50/50 [==============================] - 87s 2s/step - loss: 9.4728 - rmse: 23.1302 - val_loss: 12.4619 - val_rmse: 17.2725\n",
      "Train for 50 steps, validate for 50 steps\n",
      "Epoch 1/20\n",
      "50/50 [==============================] - 115s 2s/step - loss: 41.6302 - rmse: 55.0994 - val_loss: 26.6323 - val_rmse: 32.5870\n",
      "Epoch 2/20\n",
      "50/50 [==============================] - 96s 2s/step - loss: 31.7938 - rmse: 43.0687 - val_loss: 24.4471 - val_rmse: 29.2640\n",
      "Epoch 3/20\n",
      "50/50 [==============================] - 97s 2s/step - loss: 24.8916 - rmse: 34.6989 - val_loss: 25.6858 - val_rmse: 31.3925\n",
      "Epoch 4/20\n",
      "50/50 [==============================] - 97s 2s/step - loss: 24.1144 - rmse: 36.0264 - val_loss: 18.1349 - val_rmse: 23.9449\n",
      "Epoch 5/20\n",
      "50/50 [==============================] - 63s 1s/step - loss: 17.8137 - rmse: 29.9757 - val_loss: 13.6530 - val_rmse: 17.6207\n",
      "Epoch 6/20\n",
      "50/50 [==============================] - 59s 1s/step - loss: 15.0042 - rmse: 28.0286 - val_loss: 11.6148 - val_rmse: 16.8348\n",
      "Epoch 7/20\n",
      "50/50 [==============================] - 59s 1s/step - loss: 13.9536 - rmse: 27.2970 - val_loss: 9.9966 - val_rmse: 13.8991\n",
      "Epoch 8/20\n",
      "50/50 [==============================] - 59s 1s/step - loss: 11.5063 - rmse: 24.8160 - val_loss: 11.6286 - val_rmse: 16.1980\n",
      "Epoch 9/20\n",
      "50/50 [==============================] - 59s 1s/step - loss: 10.8325 - rmse: 24.6443 - val_loss: 10.2187 - val_rmse: 14.4224\n",
      "Epoch 10/20\n",
      "50/50 [==============================] - 59s 1s/step - loss: 10.1314 - rmse: 23.8263 - val_loss: 10.3649 - val_rmse: 14.8881\n",
      "Epoch 11/20\n",
      "50/50 [==============================] - 59s 1s/step - loss: 9.7761 - rmse: 23.5106 - val_loss: 9.1512 - val_rmse: 13.3466\n",
      "Epoch 12/20\n",
      "50/50 [==============================] - 59s 1s/step - loss: 9.3526 - rmse: 23.1434 - val_loss: 11.1817 - val_rmse: 16.2971\n",
      "Epoch 13/20\n",
      "50/50 [==============================] - 59s 1s/step - loss: 9.0659 - rmse: 22.8596 - val_loss: 12.7227 - val_rmse: 17.9350\n",
      "Epoch 14/20\n",
      "50/50 [==============================] - 59s 1s/step - loss: 8.8041 - rmse: 22.5853 - val_loss: 9.5497 - val_rmse: 14.2297\n",
      "Epoch 15/20\n",
      "50/50 [==============================] - 59s 1s/step - loss: 8.6000 - rmse: 22.3875 - val_loss: 11.5872 - val_rmse: 16.7254\n",
      "Epoch 16/20\n",
      "50/50 [==============================] - 59s 1s/step - loss: 8.3528 - rmse: 22.1123 - val_loss: 10.0998 - val_rmse: 14.3750\n",
      "Epoch 17/20\n",
      "50/50 [==============================] - 60s 1s/step - loss: 8.1345 - rmse: 21.9690 - val_loss: 12.1351 - val_rmse: 17.3892\n",
      "Epoch 18/20\n",
      "50/50 [==============================] - 59s 1s/step - loss: 7.9806 - rmse: 21.7664 - val_loss: 10.5951 - val_rmse: 16.0984\n",
      "Epoch 19/20\n",
      "50/50 [==============================] - 59s 1s/step - loss: 7.8488 - rmse: 21.6489 - val_loss: 10.5821 - val_rmse: 15.7072\n",
      "Epoch 20/20\n",
      "50/50 [==============================] - 59s 1s/step - loss: 7.6597 - rmse: 21.3933 - val_loss: 10.1133 - val_rmse: 14.3921\n",
      "Train for 50 steps, validate for 50 steps\n",
      "Epoch 1/20\n",
      "50/50 [==============================] - 77s 2s/step - loss: 864.9150 - rmse: 1177.9272 - val_loss: 61.9905 - val_rmse: 88.2898\n",
      "Epoch 2/20\n",
      "50/50 [==============================] - 70s 1s/step - loss: 126.2990 - rmse: 184.2095 - val_loss: 34.3515 - val_rmse: 41.9524\n",
      "Epoch 3/20\n",
      "50/50 [==============================] - 71s 1s/step - loss: 316.5061 - rmse: 428.9630 - val_loss: 554.0637 - val_rmse: 666.8168\n",
      "Epoch 4/20\n",
      "50/50 [==============================] - 72s 1s/step - loss: 473.9600 - rmse: 617.6815 - val_loss: 36.7764 - val_rmse: 45.2074\n",
      "Epoch 5/20\n",
      "50/50 [==============================] - 73s 1s/step - loss: 41.6490 - rmse: 54.9140 - val_loss: 25.3494 - val_rmse: 30.2310\n",
      "Epoch 6/20\n",
      "50/50 [==============================] - 73s 1s/step - loss: 51.4931 - rmse: 70.8548 - val_loss: 30.1008 - val_rmse: 37.4133\n",
      "Epoch 7/20\n",
      "50/50 [==============================] - 74s 1s/step - loss: 26.6063 - rmse: 36.4244 - val_loss: 36.2173 - val_rmse: 43.7846\n",
      "Epoch 8/20\n",
      "50/50 [==============================] - 73s 1s/step - loss: 27.2835 - rmse: 38.6420 - val_loss: 29.1299 - val_rmse: 36.6113\n",
      "Epoch 9/20\n",
      "50/50 [==============================] - 74s 1s/step - loss: 34.5740 - rmse: 46.3922 - val_loss: 28.5270 - val_rmse: 35.2803\n",
      "Epoch 10/20\n",
      "50/50 [==============================] - 75s 1s/step - loss: 24.0234 - rmse: 34.1580 - val_loss: 32.7378 - val_rmse: 40.8617\n",
      "Epoch 11/20\n",
      "50/50 [==============================] - 74s 1s/step - loss: 22.0173 - rmse: 33.3800 - val_loss: 26.4803 - val_rmse: 33.1873\n",
      "Epoch 12/20\n",
      "50/50 [==============================] - 74s 1s/step - loss: 17.1924 - rmse: 29.5332 - val_loss: 19.2311 - val_rmse: 25.2722\n",
      "Epoch 13/20\n",
      "50/50 [==============================] - 72s 1s/step - loss: 14.6003 - rmse: 27.6613 - val_loss: 11.9671 - val_rmse: 15.8615\n",
      "Epoch 14/20\n",
      "50/50 [==============================] - 73s 1s/step - loss: 13.0210 - rmse: 26.3325 - val_loss: 13.5234 - val_rmse: 18.3257\n",
      "Epoch 15/20\n",
      "50/50 [==============================] - 73s 1s/step - loss: 11.6317 - rmse: 25.0719 - val_loss: 11.7996 - val_rmse: 16.2628\n",
      "Epoch 16/20\n",
      "50/50 [==============================] - 72s 1s/step - loss: 10.5992 - rmse: 24.1052 - val_loss: 12.1347 - val_rmse: 16.7825\n",
      "Epoch 17/20\n",
      "50/50 [==============================] - 72s 1s/step - loss: 9.9244 - rmse: 23.5581 - val_loss: 12.8170 - val_rmse: 17.9297\n",
      "Epoch 18/20\n",
      "50/50 [==============================] - 73s 1s/step - loss: 9.4843 - rmse: 23.2098 - val_loss: 12.5770 - val_rmse: 17.3830\n",
      "Epoch 19/20\n",
      "50/50 [==============================] - 72s 1s/step - loss: 9.2569 - rmse: 22.9410 - val_loss: 11.6848 - val_rmse: 16.2629\n",
      "Epoch 20/20\n",
      "50/50 [==============================] - 73s 1s/step - loss: 8.8013 - rmse: 22.6247 - val_loss: 9.8885 - val_rmse: 14.0888\n",
      "Train for 50 steps, validate for 50 steps\n",
      "Epoch 1/20\n",
      "50/50 [==============================] - 164s 3s/step - loss: 11067.2185 - rmse: 14257.9834 - val_loss: 1345.5298 - val_rmse: 1904.5496\n",
      "Epoch 2/20\n",
      "50/50 [==============================] - 159s 3s/step - loss: 2525.7986 - rmse: 3113.3950 - val_loss: 12308.8145 - val_rmse: 15025.8115\n",
      "Epoch 3/20\n",
      "50/50 [==============================] - 160s 3s/step - loss: 5364.0275 - rmse: 6863.2837 - val_loss: 2719.6843 - val_rmse: 3248.8918\n",
      "Epoch 4/20\n",
      "50/50 [==============================] - 161s 3s/step - loss: 2439.9008 - rmse: 3131.0762 - val_loss: 312.7130 - val_rmse: 424.8789\n",
      "Epoch 5/20\n",
      "50/50 [==============================] - 158s 3s/step - loss: 839.1405 - rmse: 1078.4819 - val_loss: 4034.5981 - val_rmse: 5856.9692\n",
      "Epoch 6/20\n",
      "50/50 [==============================] - 200s 4s/step - loss: 2858.8144 - rmse: 3924.9675 - val_loss: 121.9424 - val_rmse: 169.3545\n",
      "Epoch 7/20\n",
      "50/50 [==============================] - 171s 3s/step - loss: 610.1365 - rmse: 901.6136 - val_loss: 36.1298 - val_rmse: 44.2314\n",
      "Epoch 8/20\n",
      "50/50 [==============================] - 175s 4s/step - loss: 1576.3995 - rmse: 2294.0828 - val_loss: 34.4851 - val_rmse: 42.6024\n",
      "Epoch 9/20\n",
      "50/50 [==============================] - 172s 3s/step - loss: 54.2823 - rmse: 74.6804 - val_loss: 47.3736 - val_rmse: 67.4503\n",
      "Epoch 10/20\n",
      "50/50 [==============================] - 209s 4s/step - loss: 35.7303 - rmse: 50.1100 - val_loss: 22.6121 - val_rmse: 27.6775\n",
      "Epoch 11/20\n",
      "50/50 [==============================] - 117s 2s/step - loss: 27.8842 - rmse: 38.6310 - val_loss: 28.2374 - val_rmse: 34.9602\n",
      "Epoch 12/20\n",
      "50/50 [==============================] - 160s 3s/step - loss: 27.5223 - rmse: 38.0374 - val_loss: 22.3354 - val_rmse: 26.7170\n",
      "Epoch 13/20\n",
      "50/50 [==============================] - 153s 3s/step - loss: 25.4557 - rmse: 35.7669 - val_loss: 18.7002 - val_rmse: 22.2930\n",
      "Epoch 14/20\n",
      "50/50 [==============================] - 126s 3s/step - loss: 21.5828 - rmse: 32.9158 - val_loss: 14.1912 - val_rmse: 17.6364\n",
      "Epoch 15/20\n",
      "50/50 [==============================] - 151s 3s/step - loss: 17.0218 - rmse: 29.3769 - val_loss: 19.6348 - val_rmse: 26.0007\n",
      "Epoch 16/20\n",
      "50/50 [==============================] - 154s 3s/step - loss: 13.9593 - rmse: 26.6429 - val_loss: 20.5495 - val_rmse: 31.6346\n",
      "Epoch 17/20\n",
      "50/50 [==============================] - 164s 3s/step - loss: 12.3415 - rmse: 25.4479 - val_loss: 11.1645 - val_rmse: 15.6475\n",
      "Epoch 18/20\n",
      "50/50 [==============================] - 135s 3s/step - loss: 11.1796 - rmse: 24.5275 - val_loss: 9.1259 - val_rmse: 12.9615\n",
      "Epoch 19/20\n",
      "50/50 [==============================] - 134s 3s/step - loss: 10.5814 - rmse: 24.0525 - val_loss: 15.6485 - val_rmse: 21.4550\n",
      "Epoch 20/20\n",
      "50/50 [==============================] - 156s 3s/step - loss: 10.1304 - rmse: 23.7111 - val_loss: 8.6444 - val_rmse: 12.4206\n",
      "Train for 50 steps, validate for 50 steps\n",
      "Epoch 1/20\n",
      "50/50 [==============================] - 201s 4s/step - loss: 26206.0415 - rmse: 34292.4844 - val_loss: 13190.2500 - val_rmse: 17293.2539\n",
      "Epoch 2/20\n",
      "50/50 [==============================] - 181s 4s/step - loss: 13124.9667 - rmse: 17384.8711 - val_loss: 4812.0801 - val_rmse: 6125.7817\n",
      "Epoch 3/20\n",
      "50/50 [==============================] - 195s 4s/step - loss: 4413.7883 - rmse: 5462.9785 - val_loss: 1277.4836 - val_rmse: 1628.0493\n",
      "Epoch 4/20\n",
      "50/50 [==============================] - 207s 4s/step - loss: 1698.2526 - rmse: 2249.3450 - val_loss: 156.6586 - val_rmse: 191.9541\n",
      "Epoch 5/20\n",
      "50/50 [==============================] - 187s 4s/step - loss: 157.4195 - rmse: 210.0605 - val_loss: 26.5426 - val_rmse: 34.0570\n",
      "Epoch 6/20\n",
      "50/50 [==============================] - 126s 3s/step - loss: 24.2089 - rmse: 35.6526 - val_loss: 28.1921 - val_rmse: 35.9413\n",
      "Epoch 7/20\n",
      "50/50 [==============================] - 124s 2s/step - loss: 24.8137 - rmse: 36.8726 - val_loss: 35.6212 - val_rmse: 43.5937\n",
      "Epoch 8/20\n",
      "50/50 [==============================] - 133s 3s/step - loss: 23.6369 - rmse: 34.9933 - val_loss: 28.8391 - val_rmse: 36.0250\n",
      "Epoch 9/20\n",
      "50/50 [==============================] - 125s 3s/step - loss: 21.7357 - rmse: 33.3907 - val_loss: 25.4741 - val_rmse: 31.3422\n",
      "Epoch 10/20\n",
      "50/50 [==============================] - 126s 3s/step - loss: 16.0186 - rmse: 28.4169 - val_loss: 16.8254 - val_rmse: 21.9766\n",
      "Epoch 11/20\n",
      "50/50 [==============================] - 126s 3s/step - loss: 13.6242 - rmse: 26.6710 - val_loss: 12.7116 - val_rmse: 17.3803\n",
      "Epoch 12/20\n",
      "50/50 [==============================] - 123s 2s/step - loss: 11.4926 - rmse: 24.7981 - val_loss: 11.7043 - val_rmse: 16.2557\n",
      "Epoch 13/20\n",
      "50/50 [==============================] - 126s 3s/step - loss: 10.4767 - rmse: 23.8223 - val_loss: 11.2141 - val_rmse: 16.0336\n",
      "Epoch 14/20\n",
      "50/50 [==============================] - 125s 3s/step - loss: 9.8110 - rmse: 23.3298 - val_loss: 11.9528 - val_rmse: 16.5737\n",
      "Epoch 15/20\n",
      "50/50 [==============================] - 124s 2s/step - loss: 9.3714 - rmse: 23.0123 - val_loss: 9.3817 - val_rmse: 13.4652\n",
      "Epoch 16/20\n",
      "50/50 [==============================] - 126s 3s/step - loss: 9.0791 - rmse: 22.7966 - val_loss: 8.4390 - val_rmse: 12.0348\n",
      "Epoch 17/20\n",
      "50/50 [==============================] - 128s 3s/step - loss: 8.6632 - rmse: 22.4551 - val_loss: 9.2552 - val_rmse: 13.7953\n",
      "Epoch 18/20\n",
      "50/50 [==============================] - 128s 3s/step - loss: 8.3949 - rmse: 22.2386 - val_loss: 8.7953 - val_rmse: 13.4869\n",
      "Epoch 19/20\n",
      "50/50 [==============================] - 126s 3s/step - loss: 8.0570 - rmse: 21.9345 - val_loss: 9.1298 - val_rmse: 13.8421\n",
      "Epoch 20/20\n",
      "50/50 [==============================] - 158s 3s/step - loss: 7.8169 - rmse: 21.7866 - val_loss: 10.8256 - val_rmse: 16.1274\n",
      "Train for 50 steps, validate for 50 steps\n",
      "Epoch 1/30\n",
      "50/50 [==============================] - 65s 1s/step - loss: 27.8281 - rmse: 40.4942 - val_loss: 15.4571 - val_rmse: 20.5582\n",
      "Epoch 2/30\n",
      "50/50 [==============================] - 56s 1s/step - loss: 17.2862 - rmse: 29.2714 - val_loss: 20.3793 - val_rmse: 26.3990\n",
      "Epoch 3/30\n",
      "50/50 [==============================] - 55s 1s/step - loss: 14.0599 - rmse: 26.9515 - val_loss: 12.6019 - val_rmse: 17.4383\n",
      "Epoch 4/30\n",
      "50/50 [==============================] - 54s 1s/step - loss: 12.0358 - rmse: 25.3918 - val_loss: 10.6545 - val_rmse: 15.4879\n",
      "Epoch 5/30\n",
      "50/50 [==============================] - 57s 1s/step - loss: 10.8394 - rmse: 24.3407 - val_loss: 9.8383 - val_rmse: 14.4311\n",
      "Epoch 6/30\n",
      "50/50 [==============================] - 56s 1s/step - loss: 10.0118 - rmse: 23.7009 - val_loss: 11.4302 - val_rmse: 17.2647\n",
      "Epoch 7/30\n",
      "50/50 [==============================] - 55s 1s/step - loss: 9.5093 - rmse: 23.2926 - val_loss: 12.4575 - val_rmse: 17.4574\n",
      "Epoch 8/30\n",
      "50/50 [==============================] - 57s 1s/step - loss: 9.1218 - rmse: 22.9712 - val_loss: 10.2703 - val_rmse: 15.1816\n",
      "Epoch 9/30\n",
      "50/50 [==============================] - 56s 1s/step - loss: 8.8052 - rmse: 22.7106 - val_loss: 11.6920 - val_rmse: 16.8409\n",
      "Epoch 10/30\n",
      "50/50 [==============================] - 59s 1s/step - loss: 8.4609 - rmse: 22.4007 - val_loss: 12.7714 - val_rmse: 18.4038\n",
      "Epoch 11/30\n",
      "50/50 [==============================] - 66s 1s/step - loss: 8.2008 - rmse: 22.1889 - val_loss: 10.9066 - val_rmse: 16.3746\n",
      "Epoch 12/30\n",
      "50/50 [==============================] - 56s 1s/step - loss: 7.9751 - rmse: 21.9785 - val_loss: 10.7456 - val_rmse: 16.2727\n",
      "Epoch 13/30\n",
      "50/50 [==============================] - 56s 1s/step - loss: 7.6838 - rmse: 21.7526 - val_loss: 9.3889 - val_rmse: 14.2592\n",
      "Epoch 14/30\n",
      "50/50 [==============================] - 50s 1s/step - loss: 7.5660 - rmse: 21.6637 - val_loss: 10.1258 - val_rmse: 15.4771\n",
      "Epoch 15/30\n",
      "50/50 [==============================] - 54s 1s/step - loss: 7.2161 - rmse: 21.4021 - val_loss: 11.5939 - val_rmse: 16.4216\n",
      "Epoch 16/30\n",
      "50/50 [==============================] - 55s 1s/step - loss: 7.1669 - rmse: 21.2966 - val_loss: 9.3309 - val_rmse: 14.4184\n",
      "Epoch 17/30\n",
      "50/50 [==============================] - 54s 1s/step - loss: 6.8857 - rmse: 21.1407 - val_loss: 10.5316 - val_rmse: 15.6340\n",
      "Epoch 18/30\n",
      "50/50 [==============================] - 57s 1s/step - loss: 6.7907 - rmse: 21.0115 - val_loss: 10.0843 - val_rmse: 15.2546\n",
      "Epoch 19/30\n",
      "50/50 [==============================] - 55s 1s/step - loss: 6.5983 - rmse: 20.8889 - val_loss: 10.1581 - val_rmse: 15.5414\n",
      "Epoch 20/30\n",
      "50/50 [==============================] - 57s 1s/step - loss: 6.4405 - rmse: 20.7360 - val_loss: 9.9524 - val_rmse: 15.3172\n",
      "Epoch 21/30\n",
      "50/50 [==============================] - 57s 1s/step - loss: 6.3468 - rmse: 20.6940 - val_loss: 9.5075 - val_rmse: 14.7210\n",
      "Epoch 22/30\n",
      "50/50 [==============================] - 56s 1s/step - loss: 6.1292 - rmse: 20.4219 - val_loss: 9.6352 - val_rmse: 14.4535\n",
      "Epoch 23/30\n",
      "50/50 [==============================] - 58s 1s/step - loss: 6.0343 - rmse: 20.2689 - val_loss: 9.0626 - val_rmse: 13.5703\n",
      "Epoch 24/30\n",
      "50/50 [==============================] - 56s 1s/step - loss: 5.8583 - rmse: 20.0378 - val_loss: 9.8025 - val_rmse: 14.9468\n",
      "Epoch 25/30\n",
      "50/50 [==============================] - 56s 1s/step - loss: 5.7731 - rmse: 19.8486 - val_loss: 9.2370 - val_rmse: 13.8424\n",
      "Epoch 26/30\n",
      "50/50 [==============================] - 57s 1s/step - loss: 5.5698 - rmse: 19.6329 - val_loss: 9.6740 - val_rmse: 14.2542\n",
      "Epoch 27/30\n",
      "50/50 [==============================] - 57s 1s/step - loss: 5.4883 - rmse: 19.3087 - val_loss: 9.6733 - val_rmse: 14.5390\n",
      "Epoch 28/30\n",
      "50/50 [==============================] - 61s 1s/step - loss: 5.3753 - rmse: 19.0221 - val_loss: 9.3597 - val_rmse: 14.1024\n",
      "Epoch 29/30\n",
      "50/50 [==============================] - 50s 1s/step - loss: 5.2208 - rmse: 18.4651 - val_loss: 9.8205 - val_rmse: 14.8290\n",
      "Epoch 30/30\n",
      "50/50 [==============================] - 49s 984ms/step - loss: 5.0444 - rmse: 17.8827 - val_loss: 9.9551 - val_rmse: 15.0257\n",
      "Train for 50 steps, validate for 50 steps\n",
      "Epoch 1/30\n",
      "50/50 [==============================] - 66s 1s/step - loss: 38.2496 - rmse: 50.5413 - val_loss: 34.5768 - val_rmse: 42.7191\n",
      "Epoch 2/30\n",
      "50/50 [==============================] - 57s 1s/step - loss: 23.9602 - rmse: 34.4796 - val_loss: 26.4961 - val_rmse: 33.7179\n",
      "Epoch 3/30\n",
      "50/50 [==============================] - 59s 1s/step - loss: 19.9378 - rmse: 30.8737 - val_loss: 27.3716 - val_rmse: 34.8202\n",
      "Epoch 4/30\n",
      "50/50 [==============================] - 55s 1s/step - loss: 16.2329 - rmse: 28.3720 - val_loss: 19.8854 - val_rmse: 26.8829\n",
      "Epoch 5/30\n",
      "50/50 [==============================] - 67s 1s/step - loss: 13.1918 - rmse: 26.2178 - val_loss: 12.4860 - val_rmse: 17.4002\n",
      "Epoch 6/30\n",
      "50/50 [==============================] - 45s 909ms/step - loss: 11.5021 - rmse: 24.7627 - val_loss: 14.8648 - val_rmse: 20.2941\n",
      "Epoch 7/30\n",
      "50/50 [==============================] - 46s 919ms/step - loss: 10.4495 - rmse: 23.9118 - val_loss: 12.0472 - val_rmse: 16.7470\n",
      "Epoch 8/30\n",
      "50/50 [==============================] - 47s 933ms/step - loss: 9.9037 - rmse: 23.5072 - val_loss: 14.1450 - val_rmse: 19.0289\n",
      "Epoch 9/30\n",
      "50/50 [==============================] - 49s 982ms/step - loss: 9.4026 - rmse: 23.1426 - val_loss: 13.5864 - val_rmse: 18.8132\n",
      "Epoch 10/30\n",
      "50/50 [==============================] - 65s 1s/step - loss: 9.0544 - rmse: 22.9155 - val_loss: 13.2601 - val_rmse: 18.6421\n",
      "Epoch 11/30\n",
      "50/50 [==============================] - 75s 2s/step - loss: 8.8013 - rmse: 22.7595 - val_loss: 11.8127 - val_rmse: 16.7463\n",
      "Epoch 12/30\n",
      "50/50 [==============================] - 54s 1s/step - loss: 8.5200 - rmse: 22.5516 - val_loss: 11.5356 - val_rmse: 16.5976\n",
      "Epoch 13/30\n",
      "50/50 [==============================] - 55s 1s/step - loss: 8.2215 - rmse: 22.3341 - val_loss: 11.0439 - val_rmse: 16.2485\n",
      "Epoch 14/30\n",
      "50/50 [==============================] - 53s 1s/step - loss: 8.0036 - rmse: 22.1728 - val_loss: 11.3267 - val_rmse: 15.8133\n",
      "Epoch 15/30\n",
      "50/50 [==============================] - 53s 1s/step - loss: 7.9106 - rmse: 22.0433 - val_loss: 9.9583 - val_rmse: 14.6556\n",
      "Epoch 16/30\n",
      "50/50 [==============================] - 54s 1s/step - loss: 7.6600 - rmse: 21.8740 - val_loss: 9.3974 - val_rmse: 14.3312\n",
      "Epoch 17/30\n",
      "50/50 [==============================] - 54s 1s/step - loss: 7.4434 - rmse: 21.7474 - val_loss: 9.2553 - val_rmse: 13.5870\n",
      "Epoch 18/30\n",
      "50/50 [==============================] - 52s 1s/step - loss: 7.3241 - rmse: 21.6145 - val_loss: 9.1430 - val_rmse: 13.3090\n",
      "Epoch 19/30\n",
      "50/50 [==============================] - 48s 956ms/step - loss: 7.1249 - rmse: 21.5135 - val_loss: 10.4019 - val_rmse: 15.5936\n",
      "Epoch 20/30\n",
      "50/50 [==============================] - 48s 960ms/step - loss: 7.0182 - rmse: 21.3750 - val_loss: 10.4907 - val_rmse: 15.5466\n",
      "Epoch 21/30\n",
      "50/50 [==============================] - 47s 931ms/step - loss: 6.8602 - rmse: 21.2644 - val_loss: 9.3059 - val_rmse: 14.3859\n",
      "Epoch 22/30\n",
      "50/50 [==============================] - 48s 969ms/step - loss: 6.7501 - rmse: 21.2008 - val_loss: 9.5498 - val_rmse: 14.0582\n",
      "Epoch 23/30\n",
      "50/50 [==============================] - 48s 960ms/step - loss: 6.6236 - rmse: 21.1024 - val_loss: 9.0520 - val_rmse: 13.9801\n",
      "Epoch 24/30\n",
      "50/50 [==============================] - 47s 947ms/step - loss: 6.5056 - rmse: 20.9768 - val_loss: 10.0419 - val_rmse: 15.1696\n",
      "Epoch 25/30\n",
      "50/50 [==============================] - 48s 963ms/step - loss: 6.4064 - rmse: 20.8890 - val_loss: 9.2540 - val_rmse: 13.7087\n",
      "Epoch 26/30\n",
      "50/50 [==============================] - 48s 969ms/step - loss: 6.2971 - rmse: 20.7733 - val_loss: 9.5390 - val_rmse: 13.6157\n",
      "Epoch 27/30\n",
      "50/50 [==============================] - 49s 979ms/step - loss: 6.1502 - rmse: 20.7126 - val_loss: 10.4522 - val_rmse: 15.3897\n",
      "Epoch 28/30\n",
      "50/50 [==============================] - 55s 1s/step - loss: 6.0161 - rmse: 20.5571 - val_loss: 10.0113 - val_rmse: 15.1058\n",
      "Epoch 29/30\n",
      "50/50 [==============================] - 54s 1s/step - loss: 5.9399 - rmse: 20.4816 - val_loss: 10.6203 - val_rmse: 15.2902\n",
      "Epoch 30/30\n",
      "50/50 [==============================] - 55s 1s/step - loss: 5.8366 - rmse: 20.4130 - val_loss: 9.2051 - val_rmse: 14.0715\n",
      "Train for 50 steps, validate for 50 steps\n",
      "Epoch 1/30\n",
      "50/50 [==============================] - 70s 1s/step - loss: 9485.5104 - rmse: 13027.3975 - val_loss: 5459.5771 - val_rmse: 7877.9087\n",
      "Epoch 2/30\n",
      "50/50 [==============================] - 61s 1s/step - loss: 1235.4550 - rmse: 1640.7867 - val_loss: 648.8221 - val_rmse: 723.3321\n",
      "Epoch 3/30\n",
      "50/50 [==============================] - 61s 1s/step - loss: 1911.1768 - rmse: 2520.5740 - val_loss: 533.2083 - val_rmse: 1027.0457\n",
      "Epoch 4/30\n",
      "50/50 [==============================] - 66s 1s/step - loss: 348.8972 - rmse: 441.4824 - val_loss: 41.5999 - val_rmse: 51.2490\n",
      "Epoch 5/30\n",
      "50/50 [==============================] - 79s 2s/step - loss: 33.5388 - rmse: 45.4452 - val_loss: 24.9041 - val_rmse: 31.4628\n",
      "Epoch 6/30\n",
      "50/50 [==============================] - 85s 2s/step - loss: 22.9166 - rmse: 34.2618 - val_loss: 18.7068 - val_rmse: 24.4795\n",
      "Epoch 7/30\n",
      "50/50 [==============================] - 66s 1s/step - loss: 19.5117 - rmse: 31.4595 - val_loss: 17.1930 - val_rmse: 23.0392\n",
      "Epoch 8/30\n",
      "50/50 [==============================] - 67s 1s/step - loss: 15.8819 - rmse: 28.4335 - val_loss: 14.7539 - val_rmse: 20.3742\n",
      "Epoch 9/30\n",
      "50/50 [==============================] - 66s 1s/step - loss: 13.2418 - rmse: 26.3817 - val_loss: 10.4630 - val_rmse: 14.2669\n",
      "Epoch 10/30\n",
      "50/50 [==============================] - 67s 1s/step - loss: 11.6623 - rmse: 25.1497 - val_loss: 9.7562 - val_rmse: 14.1750\n",
      "Epoch 11/30\n",
      "50/50 [==============================] - 63s 1s/step - loss: 10.7737 - rmse: 24.3999 - val_loss: 9.5168 - val_rmse: 13.6752\n",
      "Epoch 12/30\n",
      "50/50 [==============================] - 69s 1s/step - loss: 10.0226 - rmse: 23.7742 - val_loss: 11.1978 - val_rmse: 16.3334\n",
      "Epoch 13/30\n",
      "50/50 [==============================] - 65s 1s/step - loss: 9.6162 - rmse: 23.4198 - val_loss: 9.8599 - val_rmse: 14.8759\n",
      "Epoch 14/30\n",
      "50/50 [==============================] - 66s 1s/step - loss: 9.1658 - rmse: 23.0283 - val_loss: 8.3974 - val_rmse: 12.6801\n",
      "Epoch 15/30\n",
      "50/50 [==============================] - 73s 1s/step - loss: 8.7903 - rmse: 22.6685 - val_loss: 9.2095 - val_rmse: 14.0544\n",
      "Epoch 16/30\n",
      "50/50 [==============================] - 72s 1s/step - loss: 8.5529 - rmse: 22.4718 - val_loss: 10.0563 - val_rmse: 14.3997\n",
      "Epoch 17/30\n",
      "50/50 [==============================] - 78s 2s/step - loss: 8.2524 - rmse: 22.2256 - val_loss: 9.0029 - val_rmse: 13.5169\n",
      "Epoch 18/30\n",
      "50/50 [==============================] - 68s 1s/step - loss: 7.9506 - rmse: 21.9661 - val_loss: 10.1800 - val_rmse: 15.1017\n",
      "Epoch 19/30\n",
      "50/50 [==============================] - 74s 1s/step - loss: 7.8450 - rmse: 21.8479 - val_loss: 10.0301 - val_rmse: 14.7117\n",
      "Epoch 20/30\n",
      "50/50 [==============================] - 73s 1s/step - loss: 7.5950 - rmse: 21.6789 - val_loss: 8.7741 - val_rmse: 13.0352\n",
      "Epoch 21/30\n",
      "50/50 [==============================] - 74s 1s/step - loss: 7.3827 - rmse: 21.4831 - val_loss: 9.3467 - val_rmse: 13.5730\n",
      "Epoch 22/30\n",
      "50/50 [==============================] - 73s 1s/step - loss: 7.2570 - rmse: 21.3088 - val_loss: 9.0440 - val_rmse: 13.1792\n",
      "Epoch 23/30\n",
      "50/50 [==============================] - 72s 1s/step - loss: 7.1493 - rmse: 21.1568 - val_loss: 9.5812 - val_rmse: 13.7812\n",
      "Epoch 24/30\n",
      "50/50 [==============================] - 72s 1s/step - loss: 6.8868 - rmse: 20.8470 - val_loss: 9.7471 - val_rmse: 13.9958\n",
      "Epoch 25/30\n",
      "50/50 [==============================] - 71s 1s/step - loss: 6.7402 - rmse: 20.7200 - val_loss: 8.7079 - val_rmse: 13.2953\n",
      "Epoch 26/30\n",
      "50/50 [==============================] - 74s 1s/step - loss: 6.6727 - rmse: 20.3624 - val_loss: 8.6426 - val_rmse: 13.4943\n",
      "Epoch 27/30\n",
      "50/50 [==============================] - 60s 1s/step - loss: 6.3702 - rmse: 19.2938 - val_loss: 9.1025 - val_rmse: 13.5690\n",
      "Epoch 28/30\n",
      "50/50 [==============================] - 58s 1s/step - loss: 6.2328 - rmse: 18.9784 - val_loss: 9.0647 - val_rmse: 13.3110\n",
      "Epoch 29/30\n",
      "50/50 [==============================] - 66s 1s/step - loss: 5.9445 - rmse: 17.8022 - val_loss: 9.9513 - val_rmse: 14.6517\n",
      "Epoch 30/30\n",
      "50/50 [==============================] - 60s 1s/step - loss: 5.7670 - rmse: 17.3029 - val_loss: 9.5490 - val_rmse: 14.1826\n",
      "Train for 50 steps, validate for 50 steps\n",
      "Epoch 1/30\n",
      "50/50 [==============================] - 68s 1s/step - loss: 30.8509 - rmse: 43.2785 - val_loss: 18.0074 - val_rmse: 23.9362\n",
      "Epoch 2/30\n",
      "50/50 [==============================] - 60s 1s/step - loss: 22.5684 - rmse: 33.7084 - val_loss: 17.7210 - val_rmse: 23.7896\n",
      "Epoch 3/30\n",
      "50/50 [==============================] - 63s 1s/step - loss: 17.2780 - rmse: 29.4461 - val_loss: 21.4036 - val_rmse: 27.7877\n",
      "Epoch 4/30\n",
      "50/50 [==============================] - 61s 1s/step - loss: 13.4240 - rmse: 26.5000 - val_loss: 11.9583 - val_rmse: 16.6221\n",
      "Epoch 5/30\n",
      "50/50 [==============================] - 72s 1s/step - loss: 11.5670 - rmse: 24.8759 - val_loss: 11.9888 - val_rmse: 16.8753\n",
      "Epoch 6/30\n",
      "50/50 [==============================] - 78s 2s/step - loss: 10.6281 - rmse: 24.0590 - val_loss: 15.3147 - val_rmse: 20.7437\n",
      "Epoch 7/30\n",
      "50/50 [==============================] - 78s 2s/step - loss: 9.9771 - rmse: 23.5585 - val_loss: 14.3165 - val_rmse: 20.3280\n",
      "Epoch 8/30\n",
      "50/50 [==============================] - 60s 1s/step - loss: 9.3880 - rmse: 23.1545 - val_loss: 12.9671 - val_rmse: 18.2921\n",
      "Epoch 9/30\n",
      "50/50 [==============================] - 54s 1s/step - loss: 9.0520 - rmse: 22.8693 - val_loss: 13.3628 - val_rmse: 19.0120\n",
      "Epoch 10/30\n",
      "50/50 [==============================] - 54s 1s/step - loss: 8.6933 - rmse: 22.6030 - val_loss: 9.9143 - val_rmse: 14.5469\n",
      "Epoch 11/30\n",
      "50/50 [==============================] - 53s 1s/step - loss: 8.3542 - rmse: 22.3165 - val_loss: 14.6958 - val_rmse: 20.5064\n",
      "Epoch 12/30\n",
      "50/50 [==============================] - 53s 1s/step - loss: 8.1856 - rmse: 22.1983 - val_loss: 9.5529 - val_rmse: 14.1863\n",
      "Epoch 13/30\n",
      "50/50 [==============================] - 54s 1s/step - loss: 7.9113 - rmse: 21.9451 - val_loss: 12.8121 - val_rmse: 18.0731\n",
      "Epoch 14/30\n",
      "50/50 [==============================] - 55s 1s/step - loss: 7.6849 - rmse: 21.7378 - val_loss: 11.1404 - val_rmse: 17.0341\n",
      "Epoch 15/30\n",
      "50/50 [==============================] - 54s 1s/step - loss: 7.4571 - rmse: 21.6008 - val_loss: 11.7056 - val_rmse: 17.1188\n",
      "Epoch 16/30\n",
      "50/50 [==============================] - 54s 1s/step - loss: 7.2676 - rmse: 21.4152 - val_loss: 9.5825 - val_rmse: 14.4652\n",
      "Epoch 17/30\n",
      "50/50 [==============================] - 54s 1s/step - loss: 7.1492 - rmse: 21.2597 - val_loss: 9.8150 - val_rmse: 15.1419\n",
      "Epoch 18/30\n",
      "50/50 [==============================] - 54s 1s/step - loss: 6.9573 - rmse: 21.0787 - val_loss: 11.0975 - val_rmse: 16.3187\n",
      "Epoch 19/30\n",
      "50/50 [==============================] - 54s 1s/step - loss: 6.8008 - rmse: 20.8726 - val_loss: 10.2610 - val_rmse: 15.7257\n",
      "Epoch 20/30\n",
      "50/50 [==============================] - 54s 1s/step - loss: 6.5987 - rmse: 20.6660 - val_loss: 11.8476 - val_rmse: 17.2629\n",
      "Epoch 21/30\n",
      "50/50 [==============================] - 54s 1s/step - loss: 6.4841 - rmse: 20.5371 - val_loss: 9.2612 - val_rmse: 14.0646\n",
      "Epoch 22/30\n",
      "50/50 [==============================] - 54s 1s/step - loss: 6.3498 - rmse: 20.2803 - val_loss: 9.8907 - val_rmse: 15.1265\n",
      "Epoch 23/30\n",
      "50/50 [==============================] - 55s 1s/step - loss: 6.1948 - rmse: 19.9240 - val_loss: 10.5443 - val_rmse: 15.7549\n",
      "Epoch 24/30\n",
      "50/50 [==============================] - 54s 1s/step - loss: 6.0329 - rmse: 19.3946 - val_loss: 9.9393 - val_rmse: 15.3445\n",
      "Epoch 25/30\n",
      "50/50 [==============================] - 54s 1s/step - loss: 5.8776 - rmse: 19.2400 - val_loss: 11.1697 - val_rmse: 16.6111\n",
      "Epoch 26/30\n",
      "50/50 [==============================] - 55s 1s/step - loss: 5.7812 - rmse: 19.1478 - val_loss: 8.8953 - val_rmse: 13.5369\n",
      "Epoch 27/30\n",
      "50/50 [==============================] - 54s 1s/step - loss: 5.5789 - rmse: 18.4467 - val_loss: 11.1515 - val_rmse: 16.4915\n",
      "Epoch 28/30\n",
      "50/50 [==============================] - 54s 1s/step - loss: 5.4298 - rmse: 18.2578 - val_loss: 10.2295 - val_rmse: 15.2692\n",
      "Epoch 29/30\n",
      "50/50 [==============================] - 54s 1s/step - loss: 5.3552 - rmse: 18.1902 - val_loss: 10.3767 - val_rmse: 15.8813\n",
      "Epoch 30/30\n",
      "50/50 [==============================] - 54s 1s/step - loss: 5.2881 - rmse: 18.6502 - val_loss: 9.8906 - val_rmse: 15.1120\n",
      "Train for 50 steps, validate for 50 steps\n",
      "Epoch 1/30\n",
      "50/50 [==============================] - 74s 1s/step - loss: 3504.1532 - rmse: 4966.1270 - val_loss: 186.8581 - val_rmse: 311.7274\n",
      "Epoch 2/30\n",
      "50/50 [==============================] - 63s 1s/step - loss: 28.3866 - rmse: 43.2425 - val_loss: 23.3742 - val_rmse: 29.8529\n",
      "Epoch 3/30\n",
      "50/50 [==============================] - 63s 1s/step - loss: 19.5612 - rmse: 31.2023 - val_loss: 15.7191 - val_rmse: 20.5519\n",
      "Epoch 4/30\n",
      "50/50 [==============================] - 64s 1s/step - loss: 17.2653 - rmse: 29.7265 - val_loss: 19.2304 - val_rmse: 26.2301\n",
      "Epoch 5/30\n",
      "50/50 [==============================] - 62s 1s/step - loss: 15.7905 - rmse: 28.5057 - val_loss: 13.9154 - val_rmse: 19.4085\n",
      "Epoch 6/30\n",
      "50/50 [==============================] - 62s 1s/step - loss: 13.3531 - rmse: 26.5177 - val_loss: 12.0413 - val_rmse: 17.1048\n",
      "Epoch 7/30\n",
      "50/50 [==============================] - 63s 1s/step - loss: 11.4869 - rmse: 24.9388 - val_loss: 10.3965 - val_rmse: 15.1802\n",
      "Epoch 8/30\n",
      "50/50 [==============================] - 63s 1s/step - loss: 10.4603 - rmse: 24.0601 - val_loss: 11.7363 - val_rmse: 16.7225\n",
      "Epoch 9/30\n",
      "50/50 [==============================] - 62s 1s/step - loss: 9.8369 - rmse: 23.5686 - val_loss: 9.1132 - val_rmse: 13.5885\n",
      "Epoch 10/30\n",
      "50/50 [==============================] - 61s 1s/step - loss: 9.3701 - rmse: 23.1520 - val_loss: 11.5194 - val_rmse: 16.3364\n",
      "Epoch 11/30\n",
      "50/50 [==============================] - 59s 1s/step - loss: 8.9716 - rmse: 22.8109 - val_loss: 12.6542 - val_rmse: 17.8378\n",
      "Epoch 12/30\n",
      "50/50 [==============================] - 60s 1s/step - loss: 8.5944 - rmse: 22.4739 - val_loss: 10.5357 - val_rmse: 15.6251\n",
      "Epoch 13/30\n",
      "50/50 [==============================] - 60s 1s/step - loss: 8.3569 - rmse: 22.2284 - val_loss: 9.5150 - val_rmse: 14.6832\n",
      "Epoch 14/30\n",
      "50/50 [==============================] - 60s 1s/step - loss: 8.0459 - rmse: 21.9998 - val_loss: 10.6812 - val_rmse: 15.5646\n",
      "Epoch 15/30\n",
      "50/50 [==============================] - 60s 1s/step - loss: 7.8285 - rmse: 21.8163 - val_loss: 11.2690 - val_rmse: 16.6417\n",
      "Epoch 16/30\n",
      "50/50 [==============================] - 60s 1s/step - loss: 7.5850 - rmse: 21.5905 - val_loss: 10.3609 - val_rmse: 15.2476\n",
      "Epoch 17/30\n",
      "50/50 [==============================] - 59s 1s/step - loss: 7.4034 - rmse: 21.4336 - val_loss: 8.8055 - val_rmse: 13.6187\n",
      "Epoch 18/30\n",
      "50/50 [==============================] - 60s 1s/step - loss: 7.2244 - rmse: 21.2340 - val_loss: 9.8181 - val_rmse: 14.5324\n",
      "Epoch 19/30\n",
      "50/50 [==============================] - 60s 1s/step - loss: 6.9428 - rmse: 20.9351 - val_loss: 11.0450 - val_rmse: 16.6107\n",
      "Epoch 20/30\n",
      "50/50 [==============================] - 59s 1s/step - loss: 6.8732 - rmse: 20.7440 - val_loss: 9.6865 - val_rmse: 14.5883\n",
      "Epoch 21/30\n",
      "50/50 [==============================] - 60s 1s/step - loss: 6.7078 - rmse: 20.4595 - val_loss: 11.0011 - val_rmse: 16.2264\n",
      "Epoch 22/30\n",
      "50/50 [==============================] - 60s 1s/step - loss: 6.5038 - rmse: 20.0015 - val_loss: 10.2145 - val_rmse: 15.2224\n",
      "Epoch 23/30\n",
      "50/50 [==============================] - 60s 1s/step - loss: 6.2974 - rmse: 19.6280 - val_loss: 9.0535 - val_rmse: 13.9634\n",
      "Epoch 24/30\n",
      "50/50 [==============================] - 60s 1s/step - loss: 6.2030 - rmse: 18.9959 - val_loss: 9.1158 - val_rmse: 14.2582\n",
      "Epoch 25/30\n",
      "50/50 [==============================] - 60s 1s/step - loss: 6.0086 - rmse: 18.7271 - val_loss: 10.8411 - val_rmse: 16.0609\n",
      "Epoch 26/30\n",
      "50/50 [==============================] - 61s 1s/step - loss: 5.8272 - rmse: 17.3651 - val_loss: 9.9520 - val_rmse: 15.0871\n",
      "Epoch 27/30\n",
      "50/50 [==============================] - 60s 1s/step - loss: 5.5815 - rmse: 16.9624 - val_loss: 9.8769 - val_rmse: 15.4015\n",
      "Epoch 28/30\n",
      "50/50 [==============================] - 59s 1s/step - loss: 5.4696 - rmse: 16.4303 - val_loss: 9.0861 - val_rmse: 14.0898\n",
      "Epoch 29/30\n",
      "50/50 [==============================] - 60s 1s/step - loss: 5.1697 - rmse: 15.1663 - val_loss: 9.7343 - val_rmse: 14.3718\n",
      "Epoch 30/30\n",
      "50/50 [==============================] - 60s 1s/step - loss: 5.1087 - rmse: 15.0369 - val_loss: 9.5835 - val_rmse: 15.1597\n",
      "Train for 50 steps, validate for 50 steps\n",
      "Epoch 1/30\n",
      "50/50 [==============================] - 59s 1s/step - loss: 3549.0461 - rmse: 4556.9277 - val_loss: 190.0635 - val_rmse: 212.4313\n",
      "Epoch 2/30\n",
      "50/50 [==============================] - 53s 1s/step - loss: 109.5753 - rmse: 128.8818 - val_loss: 28.8993 - val_rmse: 35.2434\n",
      "Epoch 3/30\n",
      "50/50 [==============================] - 52s 1s/step - loss: 24.0455 - rmse: 34.7883 - val_loss: 30.1730 - val_rmse: 37.6464\n",
      "Epoch 4/30\n",
      "50/50 [==============================] - 55s 1s/step - loss: 20.3688 - rmse: 31.9583 - val_loss: 25.0884 - val_rmse: 31.3566\n",
      "Epoch 5/30\n",
      "50/50 [==============================] - 54s 1s/step - loss: 17.2410 - rmse: 29.5882 - val_loss: 28.5911 - val_rmse: 35.2186\n",
      "Epoch 6/30\n",
      "50/50 [==============================] - 53s 1s/step - loss: 14.6045 - rmse: 27.4777 - val_loss: 14.6395 - val_rmse: 19.8846\n",
      "Epoch 7/30\n",
      "50/50 [==============================] - 53s 1s/step - loss: 12.2070 - rmse: 25.6624 - val_loss: 17.4997 - val_rmse: 23.0403\n",
      "Epoch 8/30\n",
      "50/50 [==============================] - 52s 1s/step - loss: 11.0730 - rmse: 24.7004 - val_loss: 17.9449 - val_rmse: 23.2926\n",
      "Epoch 9/30\n",
      "50/50 [==============================] - 52s 1s/step - loss: 10.2952 - rmse: 24.0470 - val_loss: 17.9533 - val_rmse: 23.9436\n",
      "Epoch 10/30\n",
      "50/50 [==============================] - 52s 1s/step - loss: 9.5468 - rmse: 23.4151 - val_loss: 10.4348 - val_rmse: 15.5247\n",
      "Epoch 11/30\n",
      "50/50 [==============================] - 52s 1s/step - loss: 9.1826 - rmse: 23.0473 - val_loss: 14.5799 - val_rmse: 19.6582\n",
      "Epoch 12/30\n",
      "50/50 [==============================] - 53s 1s/step - loss: 8.8172 - rmse: 22.6749 - val_loss: 9.9784 - val_rmse: 14.9747\n",
      "Epoch 13/30\n",
      "50/50 [==============================] - 53s 1s/step - loss: 8.5138 - rmse: 22.4396 - val_loss: 11.1514 - val_rmse: 15.9241\n",
      "Epoch 14/30\n",
      "50/50 [==============================] - 52s 1s/step - loss: 8.1917 - rmse: 22.1676 - val_loss: 14.1139 - val_rmse: 19.0438\n",
      "Epoch 15/30\n",
      "50/50 [==============================] - 52s 1s/step - loss: 7.9949 - rmse: 22.0033 - val_loss: 11.6109 - val_rmse: 16.5087\n",
      "Epoch 16/30\n",
      "50/50 [==============================] - 53s 1s/step - loss: 7.6824 - rmse: 21.7156 - val_loss: 12.5971 - val_rmse: 17.9948\n",
      "Epoch 17/30\n",
      "50/50 [==============================] - 53s 1s/step - loss: 7.5901 - rmse: 21.6085 - val_loss: 11.6566 - val_rmse: 16.5707\n",
      "Epoch 18/30\n",
      "50/50 [==============================] - 52s 1s/step - loss: 7.2506 - rmse: 21.2946 - val_loss: 11.0859 - val_rmse: 15.6206\n",
      "Epoch 19/30\n",
      "50/50 [==============================] - 52s 1s/step - loss: 7.1500 - rmse: 21.1612 - val_loss: 11.3538 - val_rmse: 16.4409\n",
      "Epoch 20/30\n",
      "50/50 [==============================] - 53s 1s/step - loss: 6.9075 - rmse: 20.8455 - val_loss: 10.3120 - val_rmse: 15.5604\n",
      "Epoch 21/30\n",
      "50/50 [==============================] - 52s 1s/step - loss: 6.7203 - rmse: 20.5667 - val_loss: 11.3092 - val_rmse: 16.7518\n",
      "Epoch 22/30\n",
      "50/50 [==============================] - 52s 1s/step - loss: 6.6014 - rmse: 20.3294 - val_loss: 10.8271 - val_rmse: 15.5480\n",
      "Epoch 23/30\n",
      "50/50 [==============================] - 52s 1s/step - loss: 6.3002 - rmse: 19.5236 - val_loss: 9.9912 - val_rmse: 16.0791\n",
      "Epoch 24/30\n",
      "50/50 [==============================] - 53s 1s/step - loss: 6.2050 - rmse: 19.1639 - val_loss: 9.8271 - val_rmse: 14.8066\n",
      "Epoch 25/30\n",
      "50/50 [==============================] - 52s 1s/step - loss: 6.0184 - rmse: 18.9030 - val_loss: 9.6066 - val_rmse: 13.7318\n",
      "Epoch 26/30\n",
      "50/50 [==============================] - 54s 1s/step - loss: 5.7590 - rmse: 18.1450 - val_loss: 9.0242 - val_rmse: 13.2527\n",
      "Epoch 27/30\n",
      "50/50 [==============================] - 55s 1s/step - loss: 5.6488 - rmse: 17.9713 - val_loss: 9.4479 - val_rmse: 14.4799\n",
      "Epoch 28/30\n",
      "50/50 [==============================] - 56s 1s/step - loss: 5.4844 - rmse: 17.6037 - val_loss: 9.0694 - val_rmse: 13.3357\n",
      "Epoch 29/30\n",
      "50/50 [==============================] - 59s 1s/step - loss: 5.3405 - rmse: 17.1621 - val_loss: 9.0799 - val_rmse: 13.6482\n",
      "Epoch 30/30\n",
      "50/50 [==============================] - 51s 1s/step - loss: 5.1183 - rmse: 16.5945 - val_loss: 9.6144 - val_rmse: 14.5965\n",
      "Train for 50 steps, validate for 50 steps\n",
      "Epoch 1/30\n",
      "50/50 [==============================] - 63s 1s/step - loss: 43.1840 - rmse: 56.7579 - val_loss: 31.5394 - val_rmse: 39.4707\n",
      "Epoch 2/30\n",
      "50/50 [==============================] - 55s 1s/step - loss: 25.1193 - rmse: 35.7993 - val_loss: 23.2265 - val_rmse: 29.1470\n",
      "Epoch 3/30\n",
      "50/50 [==============================] - 56s 1s/step - loss: 22.6282 - rmse: 33.1755 - val_loss: 31.3141 - val_rmse: 39.1429\n",
      "Epoch 4/30\n",
      "50/50 [==============================] - 55s 1s/step - loss: 20.5203 - rmse: 31.6265 - val_loss: 22.3179 - val_rmse: 28.0264\n",
      "Epoch 5/30\n",
      "50/50 [==============================] - 56s 1s/step - loss: 17.0532 - rmse: 29.0991 - val_loss: 16.8964 - val_rmse: 22.6128\n",
      "Epoch 6/30\n",
      "50/50 [==============================] - 65s 1s/step - loss: 13.3979 - rmse: 26.3853 - val_loss: 12.0968 - val_rmse: 16.7753\n",
      "Epoch 7/30\n",
      "50/50 [==============================] - 76s 2s/step - loss: 11.5228 - rmse: 24.7465 - val_loss: 16.3903 - val_rmse: 22.1456\n",
      "Epoch 8/30\n",
      "50/50 [==============================] - 65s 1s/step - loss: 10.6179 - rmse: 24.0470 - val_loss: 9.7294 - val_rmse: 13.8089\n",
      "Epoch 9/30\n",
      "50/50 [==============================] - 63s 1s/step - loss: 9.9472 - rmse: 23.5495 - val_loss: 13.7168 - val_rmse: 19.0397\n",
      "Epoch 10/30\n",
      "50/50 [==============================] - 63s 1s/step - loss: 9.4329 - rmse: 23.1837 - val_loss: 12.2438 - val_rmse: 17.2932\n",
      "Epoch 11/30\n",
      "50/50 [==============================] - 64s 1s/step - loss: 9.0834 - rmse: 22.8692 - val_loss: 11.6554 - val_rmse: 16.3920\n",
      "Epoch 12/30\n",
      "50/50 [==============================] - 65s 1s/step - loss: 8.7477 - rmse: 22.5606 - val_loss: 9.7247 - val_rmse: 14.0662\n",
      "Epoch 13/30\n",
      "50/50 [==============================] - 64s 1s/step - loss: 8.5400 - rmse: 22.3608 - val_loss: 11.0982 - val_rmse: 15.9089\n",
      "Epoch 14/30\n",
      "50/50 [==============================] - 63s 1s/step - loss: 8.2830 - rmse: 22.1244 - val_loss: 9.2007 - val_rmse: 13.4216\n",
      "Epoch 15/30\n",
      "50/50 [==============================] - 76s 2s/step - loss: 8.0574 - rmse: 21.9172 - val_loss: 12.2894 - val_rmse: 17.2083\n",
      "Epoch 16/30\n",
      "50/50 [==============================] - 76s 2s/step - loss: 7.8603 - rmse: 21.7220 - val_loss: 11.3392 - val_rmse: 16.0979\n",
      "Epoch 17/30\n",
      "29/50 [================>.............] - ETA: 27s - loss: 7.6758 - rmse: 21.5418"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-d35187cf46f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfeature_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"epochs\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"layer_count\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"node_number\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m120\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m150\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"dropout\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0.7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.8\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodo_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-14-6320d582f9ca>\u001b[0m in \u001b[0;36msearch\u001b[1;34m(self, feature_dict, data, verbose)\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mcurrent_evaluations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpossibilities_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m             \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_lstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m24\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0.6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m             \u001b[0mvalidation_eval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0mcurrent_evaluations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_eval\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-6320d582f9ca>\u001b[0m in \u001b[0;36mrun_lstm\u001b[1;34m(self, data, past_lags, future_steps, splits, node_number, epochs, batch_size, loss, dropout, layer_count, verbose)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         history = model.fit(train, epochs=epochs, steps_per_epoch=50,\n\u001b[1;32m---> 72\u001b[1;33m                             \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m                             )\n\u001b[0;32m     74\u001b[0m         \u001b[0my_hat_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\CarSharingEnv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\CarSharingEnv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\CarSharingEnv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\CarSharingEnv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\CarSharingEnv\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\CarSharingEnv\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    597\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\CarSharingEnv\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\CarSharingEnv\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\CarSharingEnv\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\CarSharingEnv\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\CarSharingEnv\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "feature_dict = {\"epochs\":[30], \"layer_count\":[5, 7], \"node_number\":[100, 150], \"dropout\":[0.7, 0.8]}\n",
    "\n",
    "grid_search.search(feature_dict, modo_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 50 steps, validate for 50 steps\n",
      "Epoch 1/30\n",
      "50/50 [==============================] - 195s 4s/step - loss: 384.0321 - rmse: 509.8246 - val_loss: 40.4084 - val_rmse: 59.7598\n",
      "Epoch 2/30\n",
      "50/50 [==============================] - 160s 3s/step - loss: 32.9628 - rmse: 46.4794 - val_loss: 39.6881 - val_rmse: 46.9302\n",
      "Epoch 3/30\n",
      "50/50 [==============================] - 86s 2s/step - loss: 23.8318 - rmse: 34.3204 - val_loss: 23.4886 - val_rmse: 29.9218\n",
      "Epoch 4/30\n",
      "50/50 [==============================] - 109s 2s/step - loss: 28.1330 - rmse: 39.8971 - val_loss: 24.6535 - val_rmse: 32.1018\n",
      "Epoch 5/30\n",
      "50/50 [==============================] - 110s 2s/step - loss: 26.5411 - rmse: 37.6602 - val_loss: 35.4291 - val_rmse: 43.4910\n",
      "Epoch 6/30\n",
      "50/50 [==============================] - 101s 2s/step - loss: 21.2352 - rmse: 32.6402 - val_loss: 17.4413 - val_rmse: 23.1176\n",
      "Epoch 7/30\n",
      "50/50 [==============================] - 144s 3s/step - loss: 16.8921 - rmse: 28.9768 - val_loss: 26.4167 - val_rmse: 33.4494\n",
      "Epoch 8/30\n",
      "50/50 [==============================] - 103s 2s/step - loss: 13.9240 - rmse: 26.6100 - val_loss: 21.2371 - val_rmse: 27.5127\n",
      "Epoch 9/30\n",
      "50/50 [==============================] - 106s 2s/step - loss: 12.0208 - rmse: 24.9253 - val_loss: 17.6906 - val_rmse: 23.7228\n",
      "Epoch 10/30\n",
      "50/50 [==============================] - 109s 2s/step - loss: 11.1180 - rmse: 24.2743 - val_loss: 16.4080 - val_rmse: 22.2526\n",
      "Epoch 11/30\n",
      "50/50 [==============================] - 101s 2s/step - loss: 10.3954 - rmse: 23.7671 - val_loss: 13.7612 - val_rmse: 19.8187\n",
      "Epoch 12/30\n",
      "50/50 [==============================] - 97s 2s/step - loss: 9.7716 - rmse: 23.3226 - val_loss: 11.4589 - val_rmse: 15.9024\n",
      "Epoch 13/30\n",
      "50/50 [==============================] - 103s 2s/step - loss: 9.3811 - rmse: 22.9844 - val_loss: 11.9781 - val_rmse: 17.2786\n",
      "Epoch 14/30\n",
      "50/50 [==============================] - 99s 2s/step - loss: 9.0617 - rmse: 22.6935 - val_loss: 9.9348 - val_rmse: 14.3456\n",
      "Epoch 15/30\n",
      "50/50 [==============================] - 66s 1s/step - loss: 8.7138 - rmse: 22.4092 - val_loss: 9.5957 - val_rmse: 13.5568\n",
      "Epoch 16/30\n",
      "50/50 [==============================] - 61s 1s/step - loss: 8.4885 - rmse: 22.1789 - val_loss: 11.2872 - val_rmse: 15.8936\n",
      "Epoch 17/30\n",
      "50/50 [==============================] - 98s 2s/step - loss: 8.2160 - rmse: 21.9883 - val_loss: 11.6209 - val_rmse: 16.6136\n",
      "Epoch 18/30\n",
      "50/50 [==============================] - 69s 1s/step - loss: 8.0251 - rmse: 21.7449 - val_loss: 9.4592 - val_rmse: 13.7779\n",
      "Epoch 19/30\n",
      "50/50 [==============================] - 93s 2s/step - loss: 7.7545 - rmse: 21.5641 - val_loss: 9.8880 - val_rmse: 14.4659\n",
      "Epoch 20/30\n",
      "50/50 [==============================] - 111s 2s/step - loss: 7.5946 - rmse: 21.3593 - val_loss: 10.4546 - val_rmse: 14.8669\n",
      "Epoch 21/30\n",
      "50/50 [==============================] - 81s 2s/step - loss: 7.4056 - rmse: 21.2009 - val_loss: 10.2969 - val_rmse: 15.2134\n",
      "Epoch 22/30\n",
      "50/50 [==============================] - 62s 1s/step - loss: 7.2520 - rmse: 21.1544 - val_loss: 9.1053 - val_rmse: 13.0688\n",
      "Epoch 23/30\n",
      "50/50 [==============================] - 64s 1s/step - loss: 7.0936 - rmse: 20.9718 - val_loss: 9.3305 - val_rmse: 13.9207\n",
      "Epoch 24/30\n",
      "50/50 [==============================] - 77s 2s/step - loss: 6.9493 - rmse: 20.8121 - val_loss: 9.9243 - val_rmse: 14.8988\n",
      "Epoch 25/30\n",
      "50/50 [==============================] - 65s 1s/step - loss: 6.7652 - rmse: 20.6456 - val_loss: 9.6887 - val_rmse: 14.7185\n",
      "Epoch 26/30\n",
      "50/50 [==============================] - 89s 2s/step - loss: 6.6722 - rmse: 20.5656 - val_loss: 10.1215 - val_rmse: 15.0259\n",
      "Epoch 27/30\n",
      "50/50 [==============================] - 96s 2s/step - loss: 6.4780 - rmse: 20.4546 - val_loss: 10.0777 - val_rmse: 14.7855\n",
      "Epoch 28/30\n",
      "50/50 [==============================] - 81s 2s/step - loss: 6.4178 - rmse: 20.2933 - val_loss: 9.4655 - val_rmse: 13.9535\n",
      "Epoch 29/30\n",
      "50/50 [==============================] - 126s 3s/step - loss: 6.2782 - rmse: 20.1778 - val_loss: 9.6055 - val_rmse: 13.7691\n",
      "Epoch 30/30\n",
      "50/50 [==============================] - 98s 2s/step - loss: 6.1240 - rmse: 20.0892 - val_loss: 9.7355 - val_rmse: 13.8485\n"
     ]
    }
   ],
   "source": [
    "results = grid_search.run_lstm(modo_data, 24, 12, (0.6, 0.8), node_number=100,\n",
    "                 epochs=30, dropout=0.7, layer_count=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 50 steps, validate for 50 steps\n",
      "Epoch 1/30\n",
      "50/50 [==============================] - 268s 5s/step - loss: 2207.0080 - rmse: 2882.4858 - val_loss: 1218.7455 - val_rmse: 1505.8566\n",
      "Epoch 2/30\n",
      "50/50 [==============================] - 204s 4s/step - loss: 1006.0016 - rmse: 1240.2717 - val_loss: 1660.3737 - val_rmse: 2070.1179\n",
      "Epoch 3/30\n",
      "50/50 [==============================] - 177s 4s/step - loss: 1410.2239 - rmse: 1757.6869 - val_loss: 2112.9944 - val_rmse: 2639.4121\n",
      "Epoch 4/30\n",
      "50/50 [==============================] - 112s 2s/step - loss: 1020.1891 - rmse: 1372.0468 - val_loss: 433.1337 - val_rmse: 598.3810\n",
      "Epoch 5/30\n",
      "50/50 [==============================] - 174s 3s/step - loss: 635.0993 - rmse: 813.4850 - val_loss: 568.2524 - val_rmse: 707.5743\n",
      "Epoch 6/30\n",
      "50/50 [==============================] - 185s 4s/step - loss: 1116.8075 - rmse: 1450.4524 - val_loss: 1941.1669 - val_rmse: 2215.6226\n",
      "Epoch 7/30\n",
      "50/50 [==============================] - 193s 4s/step - loss: 877.6634 - rmse: 1106.9218 - val_loss: 96.1956 - val_rmse: 124.4994\n",
      "Epoch 8/30\n",
      "39/50 [======================>.......] - ETA: 35s - loss: 1117.6306 - rmse: 1408.0957"
     ]
    }
   ],
   "source": [
    "results2 = grid_search.run_lstm(modo_data, 24, 12, (0.6, 0.8), node_number=150,\n",
    "                 epochs=30, dropout=0.8, layer_count=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('CarSharingEnv': conda)",
   "language": "python",
   "name": "python37664bitcarsharingenvcondaf61cd503e3274ce6bd69d58b01a97e08"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
